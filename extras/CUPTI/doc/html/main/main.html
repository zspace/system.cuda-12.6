<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />
<meta content="The API reference guide for CUPTI, the CUDA Profiling Tools Interface." name="description" />
<meta content="User Guide" name="keywords" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>2. Usage &mdash; Cupti 12.6 documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" type="text/css" />
      <link rel="stylesheet" href="../_static/omni-style.css" type="text/css" />
      <link rel="stylesheet" href="../_static/api-styles.css" type="text/css" />
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/mermaid-init.js"></script>
        <script src="../_static/design-tabs.js"></script>
        <script src="../_static/version.js"></script>
        <script src="../_static/social-media.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="3. Library support" href="../library-support/library-support.html" />
    <link rel="prev" title="1. Release Notes" href="../release-notes/release-notes.html" />
 


</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >


<a href="../index.html">
  <img src="../_static/Logo_and_CUDA.png" class="logo" alt="Logo"/>
</a>

<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../index.html">CUPTI</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../overview/overview.html">Overview</a></li>
</ul>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../release-notes/release-notes.html">1. Release Notes</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">2. Usage</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#cupti-compatibility-and-requirements">2.1. CUPTI Compatibility and Requirements</a></li>
<li class="toctree-l2"><a class="reference internal" href="#cupti-initialization">2.2. CUPTI Initialization</a></li>
<li class="toctree-l2"><a class="reference internal" href="#cupti-activity-api">2.3. CUPTI Activity API</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#sass-source-correlation">2.3.1. SASS Source Correlation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#activity-pc-sampling">2.3.2. PC Sampling</a></li>
<li class="toctree-l3"><a class="reference internal" href="#nvlink">2.3.3. NVLink</a></li>
<li class="toctree-l3"><a class="reference internal" href="#openacc">2.3.4. OpenACC</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cuda-graphs">2.3.5. CUDA Graphs</a></li>
<li class="toctree-l3"><a class="reference internal" href="#external-correlation">2.3.6. External Correlation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#dynamic-attach-and-detach">2.3.7. Dynamic Attach and Detach</a></li>
<li class="toctree-l3"><a class="reference internal" href="#device-memory-allocation-source-tracking">2.3.8. Device Memory Allocation Source Tracking</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#cupti-callback-api">2.4. CUPTI Callback API</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#driver-and-runtime-api-callbacks">2.4.1. Driver and Runtime API Callbacks</a></li>
<li class="toctree-l3"><a class="reference internal" href="#resource-callbacks">2.4.2. Resource Callbacks</a></li>
<li class="toctree-l3"><a class="reference internal" href="#synchronization-callbacks">2.4.3. Synchronization Callbacks</a></li>
<li class="toctree-l3"><a class="reference internal" href="#nvidia-tools-extension-callbacks">2.4.4. NVIDIA Tools Extension Callbacks</a></li>
<li class="toctree-l3"><a class="reference internal" href="#state-callbacks">2.4.5. State Callbacks</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#cupti-event-api">2.5. CUPTI Event API</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#collecting-kernel-execution-events">2.5.1. Collecting Kernel Execution Events</a></li>
<li class="toctree-l3"><a class="reference internal" href="#sampling-events">2.5.2. Sampling Events</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#cupti-metric-api">2.6. CUPTI Metric API</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#metrics-reference">2.6.1. Metrics Reference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#metrics-for-capability-5-x">2.6.1.1. Metrics for Capability 5.x</a></li>
<li class="toctree-l4"><a class="reference internal" href="#metrics-for-capability-6-x">2.6.1.2. Metrics for Capability 6.x</a></li>
<li class="toctree-l4"><a class="reference internal" href="#metrics-for-capability-7-0">2.6.1.3. Metrics for Capability 7.0</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#cupti-profiling-api">2.7. CUPTI Profiling API</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#multi-pass-collection">2.7.1. Multi Pass Collection</a></li>
<li class="toctree-l3"><a class="reference internal" href="#range-profiling">2.7.2. Range Profiling</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#auto-range">2.7.2.1. Auto Range</a></li>
<li class="toctree-l4"><a class="reference internal" href="#user-range">2.7.2.2. User Range</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#cupti-profiler-definitions">2.7.3. CUPTI Profiler Definitions</a></li>
<li class="toctree-l3"><a class="reference internal" href="#differences-from-event-and-metric-apis">2.7.4. Differences from event and metric APIs</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#perfworks-metric-api">2.8. Perfworks Metric API</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#derived-metrics">2.8.1. Derived metrics</a></li>
<li class="toctree-l3"><a class="reference internal" href="#raw-metrics">2.8.2. Raw Metrics</a></li>
<li class="toctree-l3"><a class="reference internal" href="#metrics-mapping-table">2.8.3. Metrics Mapping Table</a></li>
<li class="toctree-l3"><a class="reference internal" href="#events-mapping-table">2.8.4. Events Mapping Table</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#migration-to-the-profiling-api">2.9. Migration to the Profiling API</a></li>
<li class="toctree-l2"><a class="reference internal" href="#cupti-pc-sampling-api">2.10. CUPTI PC Sampling API</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#configuration-attributes">2.10.1. Configuration Attributes</a></li>
<li class="toctree-l3"><a class="reference internal" href="#stall-reasons-mapping-table">2.10.2. Stall Reasons Mapping Table</a></li>
<li class="toctree-l3"><a class="reference internal" href="#data-structure-mapping-table">2.10.3. Data Structure Mapping Table</a></li>
<li class="toctree-l3"><a class="reference internal" href="#data-flushing">2.10.4. Data flushing</a></li>
<li class="toctree-l3"><a class="reference internal" href="#pc-sampling-api-source-correlation">2.10.5. SASS Source Correlation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#api-usage">2.10.6. API Usage</a></li>
<li class="toctree-l3"><a class="reference internal" href="#limitations">2.10.7. Limitations</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#cupti-sass-metric-api">2.11. CUPTI SASS Metric API</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#sass-metrics-usage">2.11.1. API usage</a></li>
<li class="toctree-l3"><a class="reference internal" href="#sample-code">2.11.2. Sample code</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#cupti-pm-sampling-api">2.12. CUPTI PM Sampling API</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#pm-sampling-usage">2.12.1. API usage</a></li>
<li class="toctree-l3"><a class="reference internal" href="#pm-sampling-samples">2.12.2. Sample code</a></li>
<li class="toctree-l3"><a class="reference internal" href="#metrics-table">2.12.3. Metrics Table</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#cupti-checkpoint-api">2.13. CUPTI Checkpoint API</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id7">2.13.1. Usage</a></li>
<li class="toctree-l3"><a class="reference internal" href="#restrictions">2.13.2. Restrictions</a></li>
<li class="toctree-l3"><a class="reference internal" href="#examples">2.13.3. Examples</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#cupti-overhead">2.14. CUPTI overhead</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#tracing-overhead">2.14.1. Tracing Overhead</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#execution-overhead">2.14.1.1. Execution overhead</a></li>
<li class="toctree-l4"><a class="reference internal" href="#memory-overhead">2.14.1.2. Memory overhead</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#profiling-overhead">2.14.2. Profiling Overhead</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#reproducibility">2.15. Reproducibility</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#fixed-clock-rate">2.15.1. Fixed Clock Rate</a></li>
<li class="toctree-l3"><a class="reference internal" href="#serialization">2.15.2. Serialization</a></li>
<li class="toctree-l3"><a class="reference internal" href="#other-issues">2.15.3. Other Issues</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#samples">2.16. Samples</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../library-support/library-support.html">3. Library support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../special-configurations/special-configurations.html">4. Special Configurations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/modules.html">5. Modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/data-structures.html">6. Data Structures</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/namespaces.html">7. Namespaces</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../copyright-and-licenses/index.html">Copyright and Licenses</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notices-header/notices-header.html">Notices</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Cupti</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">


<li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
  
<li><span class="section-number">2. </span>Usage</li>

      <li class="wy-breadcrumbs-aside">
      </li>
<li class="wy-breadcrumbs-aside">


  <span>v2024.3.2 |</span>



  <a href="https://developer.nvidia.com/cupti" class="reference external">Archive</a>


  <span>&nbsp;</span>
</li>

  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="usage">
<h1><span class="section-number">2. </span>Usage<a class="headerlink" href="#usage" title="Permalink to this headline"></a></h1>
<section id="cupti-compatibility-and-requirements">
<span id="compatibility-requirements"></span><h2><span class="section-number">2.1. </span>CUPTI Compatibility and Requirements<a class="headerlink" href="#cupti-compatibility-and-requirements" title="Permalink to this headline"></a></h2>
<p>CUPTI, the CUDA Profiling Tools Interface, ensures seamless profiling compatibility for CUDA
applications across various GPU architectures and CUDA driver versions. As part of the CUDA Toolkit,
CUPTI adheres to CUDA Toolkit compatibility requirements with CUDA drivers, which includes support
for Backward, Forward and Enhanced compatibilities. For instance, a profiling tool based on an older
version of CUPTI can still operate with a more recent CUDA driver.</p>
<p>It’s essential to refer to the CUDA Toolkit and <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html#cuda-major-component-versions__table-cuda-toolkit-driver-versions">Compatible Driver Versions table</a>
to determine the minimum CUDA driver version required for each release of CUPTI corresponding to a
CUDA Toolkit release. Attempting to use CUPTI calls with an incompatible CUDA driver version will
result in a <code class="docutils literal notranslate"><span class="pre">CUPTI_ERROR_NOT_INITIALIZED</span></code> error code.</p>
</section>
<section id="cupti-initialization">
<span id="initialization"></span><h2><span class="section-number">2.2. </span>CUPTI Initialization<a class="headerlink" href="#cupti-initialization" title="Permalink to this headline"></a></h2>
<p>CUPTI initialization occurs lazily the first time you invoke any CUPTI function. For the Activity, Event, Metric, and Callback APIs there are no requirements on when this initialization must occur (i.e. you can invoke the first CUPTI function at any point). See the CUPTI Activity API section for more information on CUPTI initialization requirements for the activity API.</p>
<p>It is recommended for CUPTI clients to call the API <code class="docutils literal notranslate"><span class="pre">cuptiSubscribe()</span></code> before starting the profiling session i.e. API <code class="docutils literal notranslate"><span class="pre">cuptiSubscribe()</span></code> should be called before calling any other CUPTI API. This API will return the error code <code class="docutils literal notranslate"><span class="pre">CUPTI_ERROR_MULTIPLE_SUBSCRIBERS_NOT_SUPPORTED</span></code> when another CUPTI client is already subscribed. CUPTI client should error out and not make further CUPTI calls if <code class="docutils literal notranslate"><span class="pre">cuptiSubscribe()</span></code> returns an error. This would prevent multiple CUPTI clients to be active at the same time otherwise those might interfere with the profiling state of each other.</p>
</section>
<section id="cupti-activity-api">
<span id="activity-api"></span><h2><span class="section-number">2.3. </span>CUPTI Activity API<a class="headerlink" href="#cupti-activity-api" title="Permalink to this headline"></a></h2>
<p>The CUPTI Activity API allows you to asynchronously collect a trace of an application’s CPU and GPU CUDA activity. The following terminology is used by the activity API.</p>
<dl class="simple">
<dt>Activity Record</dt><dd><p>CPU and GPU activity is reported in C data structures called activity records. There is a different C structure type for each activity kind (e.g. <code class="docutils literal notranslate"><span class="pre">CUpti_ActivityAPI</span></code>). Records are generically referred to using the <code class="docutils literal notranslate"><span class="pre">CUpti_Activity</span></code> type. This type contains only a field that indicates the kind of the activity record. Using this kind, the object can be cast from the generic <code class="docutils literal notranslate"><span class="pre">CUpti_Activity</span></code> type to the specific type representing the activity. See the <code class="docutils literal notranslate"><span class="pre">printActivity</span></code> function in the <a class="reference external" href="../main/main.html#sample-activity-trace-async">activity_trace_async</a> sample for an example.</p>
</dd>
<dt>Activity Buffer</dt><dd><p>An activity buffer is used to transfer one or more activity records from CUPTI to the client. CUPTI fills activity buffers with activity records as the corresponding activities occur on the CPU and GPU. But CUPTI doesn’t guarantee any ordering of the activities in the activity buffer as activity records for few activity kinds are added lazily. The CUPTI client is responsible for providing empty activity buffers as necessary to ensure that no records are dropped.</p>
</dd>
</dl>
<p>An <em>asynchronous</em> buffering API is implemented by <code class="docutils literal notranslate"><span class="pre">cuptiActivityRegisterCallbacks</span></code> and <code class="docutils literal notranslate"><span class="pre">cuptiActivityFlushAll</span></code>.</p>
<p>It is not required that the activity API be initialized before CUDA initialization. All related activities occurring after initializing the activity API are collected. You can force initialization of the activity API by enabling one or more activity kinds using <code class="docutils literal notranslate"><span class="pre">cuptiActivityEnable</span></code> or <code class="docutils literal notranslate"><span class="pre">cuptiActivityEnableContext</span></code>, as shown in the <code class="docutils literal notranslate"><span class="pre">initTrace</span></code> function of the <a class="reference external" href="../main/main.html#sample-activity-trace-async">activity_trace_async</a> sample. Some activity kinds cannot be directly enabled, see the API documentation for <code class="docutils literal notranslate"><span class="pre">CUpti_ActivityKind</span></code> for details. The functions <code class="docutils literal notranslate"><span class="pre">cuptiActivityEnable</span></code> and <code class="docutils literal notranslate"><span class="pre">cuptiActivityEnableContext</span></code> will return <code class="docutils literal notranslate"><span class="pre">CUPTI_ERROR_NOT_COMPATIBLE</span></code> if the requested activity kind cannot be enabled.</p>
<p>The activity buffer API uses callbacks to request and return buffers of activity records. To use the asynchronous buffering API, you must first register two callbacks using <code class="docutils literal notranslate"><span class="pre">cuptiActivityRegisterCallbacks</span></code>. One of these callbacks will be invoked whenever CUPTI needs an empty activity buffer. The other callback is used to deliver a buffer containing one or more activity records to the client. To minimize profiling overhead the client should return as quickly as possible from these callbacks. Client can pre-allocate a pool of activity buffers and return an empty buffer from the pool when requested by CUPTI. Activity buffer size should be chosen carefully, smaller buffers can result in frequent requests by CUPTI and bigger buffers can delay the automatic delivery of completed activity buffers. For typical workloads, it’s suggested to choose a size between 1 and 10 MB. The functions <code class="docutils literal notranslate"><span class="pre">cuptiActivityGetAttribute</span></code> and <code class="docutils literal notranslate"><span class="pre">cuptiActivitySetAttribute</span></code> can be used to read and write attributes that control how the buffering API behaves. See the API documentation for more information.</p>
<p><strong>Flushing of the activity buffers</strong></p>
<p>CUPTI is expected to deliver the activity buffer automatically as soon as it gets full and all the activity records in it are completed. For performance reasons, CUPTI calls the underlying methods based on certain heuristics, thus it can cause delay in the delivery of the buffer. However client can make a request to deliver the activity buffer/s at any time, and this can be achieved using the APIs <code class="docutils literal notranslate"><span class="pre">cuptiActivityFlushAll</span></code> and <code class="docutils literal notranslate"><span class="pre">cuptiActivityFlushPeriod</span></code>. Behavior of these APIs is as follows:</p>
<ul class="simple">
<li><p>For on-demand flush using the API <code class="docutils literal notranslate"><span class="pre">cuptiActivityFlushAll</span></code> with the flag set as 0, CUPTI returns all the activity buffers which have all the activity records completed, buffers need not to be full though. It doesn’t return buffers which have one or more incomplete records. This flush can be done at a regular interval in a separate thread.</p></li>
<li><p>For on-demand forced flush using the API <code class="docutils literal notranslate"><span class="pre">cuptiActivityFlushAll</span></code> with the flag set as CUPTI_ACTIVITY_FLAG_FLUSH_FORCED, CUPTI returns all the activity buffers including the ones which have one or more incomplete activity records. It’s suggested to do the forced flush before the termination of the profiling session to allow remaining buffers to be delivered.</p></li>
<li><p>For periodic flush using the API <code class="docutils literal notranslate"><span class="pre">cuptiActivityFlushPeriod</span></code>, CUPTI returns only those activity buffers which are full and have all the activity records completed. It’s allowed to use the API <code class="docutils literal notranslate"><span class="pre">cuptiActivityFlushAll</span></code> to flush the buffers on-demand, even when client sets the periodic flush.</p></li>
</ul>
<p>Note that activity record is considered as completed if it has all the information filled up including the timestamps (if any).</p>
<p>The <a class="reference external" href="../main/main.html#sample-activity-trace-async">activity_trace_async</a> sample shows how to use the activity buffer API to collect a trace of CPU and GPU activity for a simple application.</p>
<p><strong>CUPTI Threads</strong></p>
<p>CUPTI creates a worker thread to minimize the perturbance for the application created threads. CUPTI offloads certain operations from the application threads to the worker thread, this incldues synchronization of profiling resources between host and device, delivery of the activity buffers to the client using the buffer completed callback registered in the API <code class="docutils literal notranslate"><span class="pre">cuptiActivityRegisterCallbacks</span></code> etc. To minimize the overhead, CUPTI wakes up the worker thread based on certain heuristics. API <code class="docutils literal notranslate"><span class="pre">cuptiActivityFlushPeriod</span></code> introduced in CUDA 11.1 can be used to control the flush period of the worker thread. This setting overrides the CUPTI heuristics. It’s allowed to use the API <code class="docutils literal notranslate"><span class="pre">cuptiActivityFlushAll</span></code> to flush the data on-demand, even when client sets the periodic flush.</p>
<p>Further, CUPTI creates separate threads when certain activity kinds are enabled. For example, CUPTI creates one thread each for activity kinds <code class="docutils literal notranslate"><span class="pre">CUPTI_ACTIVITY_KIND_UNIFIED_MEMORY_COUNTER</span></code> and <code class="docutils literal notranslate"><span class="pre">CUPTI_ACTIVITY_KIND_ENVIRONMENT</span></code> to collect the information from the backend.</p>
<section id="sass-source-correlation">
<span id="activity-source-correlation"></span><span id="source-correlation"></span><h3><span class="section-number">2.3.1. </span>SASS Source Correlation<a class="headerlink" href="#sass-source-correlation" title="Permalink to this headline"></a></h3>
<p>While high-level languages for GPU programming like CUDA C offer a useful level of abstraction, convenience, and maintainability, they inherently hide some of the details of the execution on the hardware. It is sometimes helpful to analyze performance problems for a kernel at the assembly instruction level. Reading assembly language is tedious and challenging; CUPTI can help you to build the correlation between lines in your high-level source code and the executed assembly instructions.</p>
<p>Building SASS source correlation for a PC can be split into two parts:</p>
<ul class="simple">
<li><p>Correlation of the PC to SASS instruction - subscribe to any one of the <code class="docutils literal notranslate"><span class="pre">CUPTI_CBID_RESOURCE_MODULE_LOADED</span></code>, <code class="docutils literal notranslate"><span class="pre">CUPTI_CBID_RESOURCE_MODULE_UNLOAD_STARTING</span></code>, or <code class="docutils literal notranslate"><span class="pre">CUPTI_CBID_RESOURCE_MODULE_PROFILED</span></code> callbacks. This returns a <code class="docutils literal notranslate"><span class="pre">CUpti_ModuleResourceData</span></code> structure having the CUDA binary. The binary can be disassembled using the nvdisasm utility that comes with the CUDA toolkit. An application can have multiple functions and modules, to uniquely identify there is a <code class="docutils literal notranslate"><span class="pre">functionId</span></code> field in all source level activity records. This uniquely corresponds to a <code class="docutils literal notranslate"><span class="pre">CUPTI_ACTIVITY_KIND_FUNCTION</span></code>, which has the unique module ID and function ID in the module.</p></li>
<li><p>Correlation of the SASS instruction to CUDA source line - every source level activity has a <code class="docutils literal notranslate"><span class="pre">sourceLocatorId</span></code> field which uniquely maps to a record of kind <code class="docutils literal notranslate"><span class="pre">CUPTI_ACTIVITY_KIND_SOURCE_LOCATOR</span></code>, containing the line and file name information. Please note that multiple PCs can correspond to a single source line.</p></li>
</ul>
<p>When any source level activity (global access, branch, PC Sampling, etc.) is enabled, a source locator record is generated for the PCs that have the source level results. The record <code class="docutils literal notranslate"><span class="pre">CUpti_ActivityInstructionCorrelation</span></code> can be used, along with source level activities, to generate SASS assembly instructions to CUDA C source code mapping for all the PCs of the function, and not just the PCs that have the source level results. This can be enabled using the activity kind <code class="docutils literal notranslate"><span class="pre">CUPTI_ACTIVITY_KIND_INSTRUCTION_CORRELATION</span></code>.</p>
<p>The <a class="reference external" href="../main/main.html#sample-sass-source-map">sass_source_map</a> sample shows how to map SASS assembly instructions to CUDA C source.</p>
</section>
<section id="activity-pc-sampling">
<span id="pc-sampling"></span><span id="id1"></span><h3><span class="section-number">2.3.2. </span>PC Sampling<a class="headerlink" href="#activity-pc-sampling" title="Permalink to this headline"></a></h3>
<p>CUPTI supports device-wide sampling of the program counter (PC). The PC Sampling gives the number of samples for each source and assembly line with various stall reasons. Using this information, you can pinpoint portions of your kernel that are introducing latencies and the reason for the latency. Samples are taken in round robin order for all active warps at a fixed number of cycles, regardless of whether the warp is issuing an instruction or not.</p>
<p>Devices with compute capability 6.0 and higher have a new feature that gives latency reasons. The latency samples indicate the reasons for holes in the issue pipeline. While collecting these samples, there is no instruction issued in the respective warp scheduler, hence these give the latency reasons. The latency reasons will be one of the stall reasons listed in the enum <code class="docutils literal notranslate"><span class="pre">CUpti_ActivityPCSamplingStallReason</span></code>, except stall reason <code class="docutils literal notranslate"><span class="pre">CUPTI_ACTIVITY_PC_SAMPLING_STALL_NOT_SELECTED</span></code>.</p>
<p>The activity record <code class="docutils literal notranslate"><span class="pre">CUpti_ActivityPCSampling3</span></code>, enabled using activity kind <code class="docutils literal notranslate"><span class="pre">CUPTI_ACTIVITY_KIND_PC_SAMPLING</span></code>, outputs the stall reason along with PC and other related information. The enum <code class="docutils literal notranslate"><span class="pre">CUpti_ActivityPCSamplingStallReason</span></code> lists all the stall reasons. Sampling period is configurable and can be tuned using API <code class="docutils literal notranslate"><span class="pre">cuptiActivityConfigurePCSampling</span></code>. A wide range of sampling periods, ranging from 2^5 cycles to 2^31 cycles per sample, is supported. This can be controlled through the field <code class="docutils literal notranslate"><span class="pre">samplingPeriod2</span></code> in the PC sampling configuration struct <code class="docutils literal notranslate"><span class="pre">CUpti_ActivityPCSamplingConfig</span></code>. The activity record <code class="docutils literal notranslate"><span class="pre">CUpti_ActivityPCSamplingRecordInfo</span></code> provides the total and dropped samples for each kernel profiled for PC sampling.</p>
<p>This feature is available on devices with compute capability 5.2 and higher, excluding mobile devices. For Pascal and older chips <code class="docutils literal notranslate"><span class="pre">cuptiActivityConfigurePCSampling</span></code> api must be called before enabling activity kind <code class="docutils literal notranslate"><span class="pre">CUPTI_ACTIVITY_KIND_PC_SAMPLING</span></code>, for Volta and newer chips order does not matter. For Volta and newer GPU architectures if <code class="docutils literal notranslate"><span class="pre">cuptiActivityConfigurePCSampling</span></code> API is called in the middle of execution, PC sampling configuration will be updated for subsequent kernel launches. PC sampling can significantly change the overall performance characteristics of the application because all kernel executions are serialized on the GPU.</p>
<p>The <a class="reference external" href="../main/main.html#sample-pc-sampling">pc_sampling</a> sample shows how to use these APIs to collect PC Sampling profiling information for a kernel.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>A new set of PC Sampling APIs was introduced in the CUDA 11.3 release, which supports continuous mode data collection without serializing kernel execution and have a lower runtime overhead. Refer to the section <a class="reference external" href="../main/main.html#cupti-pc-sampling-api">CUPTI PC Sampling API</a> for more details. PC Sampling APIs from the header <code class="docutils literal notranslate"><span class="pre">cupti_activity.h</span></code> would be referred as <em>PC Sampling Activity APIs</em> and APIs from the header <code class="docutils literal notranslate"><span class="pre">cupti_pcsampling.h</span></code> would be referred as <em>PC Sampling APIs</em>.</p>
</div>
</section>
<section id="nvlink">
<span id="activity-nvlink"></span><h3><span class="section-number">2.3.3. </span>NVLink<a class="headerlink" href="#nvlink" title="Permalink to this headline"></a></h3>
<p>NVIDIA NVLink is a high-bandwidth, energy-efficient interconnect that enables fast communication between
the CPU and GPU, and between GPUs. CUPTI provides NVLink topology information and NVLink
transmit/receive throughput metrics.</p>
<p>The activity record <code class="docutils literal notranslate"><span class="pre">CUpti_ActivityNVLink4</span></code>, enabled using activity kind
<code class="docutils literal notranslate"><span class="pre">CUPTI_ACTIVITY_KIND_NVLink</span></code>, outputs NVLink topology information in terms of logical NVLinks. A
logical NVLink is connected between 2 devices, the device can be of type NPU (NVLink Processing Unit),
which can be CPU or GPU. Each device can support up to 18 NVLinks, hence one logical link can comprise
of 1 to 18 physical NVLinks. The field <code class="docutils literal notranslate"><span class="pre">physicalNvLinkCount</span></code> gives the number of physical links in
this logical link. The fields <code class="docutils literal notranslate"><span class="pre">portDev0</span></code> and <code class="docutils literal notranslate"><span class="pre">portDev1</span></code> give information about the slot in which
physical NVLinks are connected for a logical link. This port is the same as the instance of NVLink
metrics profiled from a device. Therefore, port and instance information should be used to correlate the
per-instance metric values with the physical NVLinks, and in turn to the topology. The field <code class="docutils literal notranslate"><span class="pre">flag</span></code>
gives the properties of a logical link, whether the link has access to system memory or peer device
memory, and has capabilities to do system memory or peer memory atomics. The field <code class="docutils literal notranslate"><span class="pre">bandwidth</span></code> gives
the bandwidth of the logical link in kilobytes/sec.</p>
<p>CUPTI provides some metrics for each physical link. Metrics are provided for data transmitted/received,
transmit/receive throughput, and header versus user data overhead for each physical NVLink. These
metrics are also provided per packet type (read/write/ atomics/response) to get more detailed insight in
the NVLink traffic.</p>
<p>This feature is available on devices with compute capability 6.0 and 7.0. For devices with compute
capability 8.0, the NVLink topology information is available but NVLink performance metrics
(<code class="docutils literal notranslate"><span class="pre">nvlrx__*</span></code> and <code class="docutils literal notranslate"><span class="pre">nvltx__*</span></code>) are not supported due to a potential application hang during data
collection.</p>
<p>The <a class="reference external" href="../main/main.html#sample-nvlink-bandwidth">nvlink_bandwidth</a> sample shows how to use these APIs
to collect NVLink metrics and topology, as well as how to correlate metrics with the topology.</p>
</section>
<section id="openacc">
<span id="activity-openacc"></span><h3><span class="section-number">2.3.4. </span>OpenACC<a class="headerlink" href="#openacc" title="Permalink to this headline"></a></h3>
<p>CUPTI supports collecting information for OpenACC applications using the OpenACC tools interface implementation of the PGI runtime. OpenACC profiling is available only on Linux x86_64, IBM POWER and Arm server platform (arm64 SBSA) platforms. This feature also requires PGI runtime version 19.1 or higher.</p>
<p>The activity records <code class="docutils literal notranslate"><span class="pre">CUpti_ActivityOpenAccData</span></code>, <code class="docutils literal notranslate"><span class="pre">CUpti_ActivityOpenAccLaunch</span></code>, and <code class="docutils literal notranslate"><span class="pre">CUpti_ActivityOpenAccOther</span></code> are created, representing the three groups of callback events specified in the OpenACC tools interface. <code class="docutils literal notranslate"><span class="pre">CUPTI_ACTIVITY_KIND_OPENACC_DATA</span></code>, <code class="docutils literal notranslate"><span class="pre">CUPTI_ACTIVITY_KIND_OPENACC_LAUNCH</span></code>, and <code class="docutils literal notranslate"><span class="pre">CUPTI_ACTIVITY_KIND_OPENACC_OTHER</span></code> can be enabled to collect the respective activity records.</p>
<p>Due to the restrictions of the OpenACC tools interface, CUPTI cannot record OpenACC records from within the client application. Instead, a shared library that exports the <code class="docutils literal notranslate"><span class="pre">acc_register_library</span></code> function defined in the OpenACC tools interface specification must be implemented. Parameters passed into this function from the OpenACC runtime can be used to initialize the CUPTI OpenACC measurement using <code class="docutils literal notranslate"><span class="pre">cuptiOpenACCInitialize</span></code>. Before starting the client application, the environment variable <code class="docutils literal notranslate"><span class="pre">ACC_PROFLIB</span></code> must be set to point to this shared library.</p>
<p><code class="docutils literal notranslate"><span class="pre">cuptiOpenACCInitialize</span></code> is defined in <code class="docutils literal notranslate"><span class="pre">cupti_openacc.h</span></code>, which is included by <code class="docutils literal notranslate"><span class="pre">cupti_activity.h</span></code>. Since the CUPTI OpenACC header is only available on supported platforms, CUPTI clients must define <code class="docutils literal notranslate"><span class="pre">CUPTI_OPENACC_SUPPORT</span></code> when compiling.</p>
<p>The <a class="reference external" href="../main/main.html#sample-openacc-trace">openacc_trace</a> sample shows how to use CUPTI APIs for OpenACC data collection.</p>
</section>
<section id="cuda-graphs">
<span id="activity-graphs"></span><h3><span class="section-number">2.3.5. </span>CUDA Graphs<a class="headerlink" href="#cuda-graphs" title="Permalink to this headline"></a></h3>
<p>CUPTI can collect trace of CUDA Graphs applications without breaking driver performance optimizations. CUPTI has added fields <code class="docutils literal notranslate"><span class="pre">graphId</span></code> and <code class="docutils literal notranslate"><span class="pre">graphNodeId</span></code> in the kernel, memcpy and memset activity records to denote the unique ID of the graph and the graph node respectively of the GPU activity. CUPTI issues callbacks for graph operations like graph and graph node creation/destruction/cloning and also for executable graph creation/destruction. The <a class="reference external" href="../main/main.html#sample-cuda-graphs-trace">cuda_graphs_trace</a> sample shows how to collect GPU trace and API trace for CUDA Graphs and how to correlate a graph node launch to the node creation API by using CUPTI callbacks for graph operations.</p>
</section>
<section id="external-correlation">
<span id="activity-ext-correlation"></span><h3><span class="section-number">2.3.6. </span>External Correlation<a class="headerlink" href="#external-correlation" title="Permalink to this headline"></a></h3>
<p>CUPTI supports correlation of CUDA API activity records with external APIs. Such APIs include OpenACC, OpenMP, and MPI. This associates CUPTI correlation IDs with IDs provided by the external API. Both IDs are stored in a new activity record of type <code class="docutils literal notranslate"><span class="pre">CUpti_ActivityExternalCorrelation</span></code>.</p>
<p>CUPTI maintains a stack of external correlation IDs per CPU thread and per <code class="docutils literal notranslate"><span class="pre">CUpti_ExternalCorrelationKind</span></code>. Clients must use <code class="docutils literal notranslate"><span class="pre">cuptiActivityPushExternalCorrelationId</span></code> to push an external ID of a specific kind to this stack and <code class="docutils literal notranslate"><span class="pre">cuptiActivityPopExternalCorrelationId</span></code> to remove the latest ID. If a CUDA API activity record is generated while any <code class="docutils literal notranslate"><span class="pre">CUpti_ExternalCorrelationKind</span></code>-stack on the same CPU thread is non-empty, one <code class="docutils literal notranslate"><span class="pre">CUpti_ActivityExternalCorrelation</span></code> record per <code class="docutils literal notranslate"><span class="pre">CUpti_ExternalCorrelationKind</span></code>-stack is inserted into the activity buffer before the respective CUDA API activity record. The CUPTI client is responsible for tracking passed external API correlation IDs, in order to eventually associate external API calls with CUDA API calls. Along with the activity kind <code class="docutils literal notranslate"><span class="pre">CUPTI_ACTIVITY_KIND_EXTERNAL_CORRELATION</span></code>, it is necessary to enable the CUDA API activity kinds i.e. <code class="docutils literal notranslate"><span class="pre">CUPTI_ACTIVITY_KIND_RUNTIME</span></code> and <code class="docutils literal notranslate"><span class="pre">CUPTI_ACTIVITY_KIND_DRIVER</span></code> to generate external correlation activity records.</p>
<p>If both <code class="docutils literal notranslate"><span class="pre">CUPTI_ACTIVITY_KIND_EXTERNAL_CORRELATION</span></code> and any of <code class="docutils literal notranslate"><span class="pre">CUPTI_ACTIVITY_KIND_OPENACC_*</span></code> activity kinds are enabled, CUPTI will generate external correlation activity records for OpenACC with <code class="docutils literal notranslate"><span class="pre">externalKind</span></code><code class="docutils literal notranslate"><span class="pre">CUPTI_EXTERNAL_CORRELATION_KIND_OPENACC</span></code>.</p>
<p>The <a class="reference external" href="../main/main.html#sample-cupti-external-correlation">cupti_external_correlation</a> sample shows how to use CUPTI APIs for external correlation.</p>
</section>
<section id="dynamic-attach-and-detach">
<span id="activity-dynamic-detach"></span><h3><span class="section-number">2.3.7. </span>Dynamic Attach and Detach<a class="headerlink" href="#dynamic-attach-and-detach" title="Permalink to this headline"></a></h3>
<p>CUPTI provides mechanisms for attaching to or detaching from a running process to support on-demand profiling. CUPTI can be attached by calling any CUPTI API as CUPTI supports lazy initialization. To detach CUPTI, call the API <code class="docutils literal notranslate"><span class="pre">cuptiFinalize()</span></code> which destroys and cleans up all the resources associated with CUPTI in the current process. After CUPTI detaches from the process, the process will keep on running with no CUPTI attached to it. Any subsequent CUPTI API call will reinitialize the CUPTI. You can attach and detach CUPTI any number of times. For safe operation of the API, it is recommended that API <code class="docutils literal notranslate"><span class="pre">cuptiFinalize()</span></code> is invoked from the exit call site of any of the CUDA Driver or Runtime API. Otherwise, CUPTI client needs to make sure that CUDA synchronization and CUPTI activity buffer flush is done before calling the API <code class="docutils literal notranslate"><span class="pre">cuptiFinalize()</span></code>. To understand the need for calling the API <code class="docutils literal notranslate"><span class="pre">cuptiFinalize()</span></code> from specific point/s in the code flow, consider multiple application threads performing various CUDA activities. While one thread is in the middle of the <code class="docutils literal notranslate"><span class="pre">cuptiFinalize()</span></code>, it is quite possible that other threads continue to call into the CUPTI and try to access the state of various objects (device, context, thread state etc) maintained by CUPTI, which might be rendered invalid as part of the <code class="docutils literal notranslate"><span class="pre">cuptiFinalize()</span></code>, thus resulting in the crash. We have to block the other threads until CUPTI teardown is completed via <code class="docutils literal notranslate"><span class="pre">cuptiFinalize()</span></code>. API exit call site is one such location where we can ensure that the work submitted by all the threads has been completed and we can safely teardown CUPTI. <code class="docutils literal notranslate"><span class="pre">cuptiFinalize()</span></code> is a heavy operation as it does context synchronization for all active CUDA contexts and blocks all the application threads until CUPTI teardown is completed. Sample code showing the usage of the API <code class="docutils literal notranslate"><span class="pre">cuptiFinalize()</span></code> in the cupti callback handler code:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="kt">void</span><span class="w"> </span><span class="n">CUPTIAPI</span><span class="w"></span>
<span class="nf">cuptiCallbackHandler</span><span class="p">(</span><span class="kt">void</span><span class="w"> </span><span class="o">*</span><span class="n">userdata</span><span class="p">,</span><span class="w"> </span><span class="n">CUpti_CallbackDomain</span><span class="w"> </span><span class="n">domain</span><span class="p">,</span><span class="w"></span>
<span class="w">    </span><span class="n">CUpti_CallbackId</span><span class="w"> </span><span class="n">cbid</span><span class="p">,</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="o">*</span><span class="n">cbdata</span><span class="p">)</span><span class="w"></span>
<span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="n">CUpti_CallbackData</span><span class="w"> </span><span class="o">*</span><span class="n">cbInfo</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">CUpti_CallbackData</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="n">cbdata</span><span class="p">;</span><span class="w"></span>

<span class="w">    </span><span class="c1">// Take this code path when CUPTI detach is requested</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">detachCupti</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">        </span><span class="k">switch</span><span class="p">(</span><span class="n">domain</span><span class="p">)</span><span class="w"></span>
<span class="w">        </span><span class="p">{</span><span class="w"></span>
<span class="w">        </span><span class="k">case</span><span class="w"> </span><span class="no">CUPTI_CB_DOMAIN_RUNTIME_API</span><span class="p">:</span><span class="w"></span>
<span class="w">        </span><span class="k">case</span><span class="w"> </span><span class="no">CUPTI_CB_DOMAIN_DRIVER_API</span><span class="p">:</span><span class="w"></span>
<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">cbInfo</span><span class="o">-&gt;</span><span class="n">callbackSite</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">CUPTI_API_EXIT</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">                </span><span class="c1">// call the CUPTI detach API</span>
<span class="w">                </span><span class="n">cuptiFinalize</span><span class="p">();</span><span class="w"></span>
<span class="w">            </span><span class="p">}</span><span class="w"></span>
<span class="w">            </span><span class="k">break</span><span class="p">;</span><span class="w"></span>
<span class="w">        </span><span class="k">default</span><span class="o">:</span><span class="w"></span>
<span class="w">            </span><span class="k">break</span><span class="p">;</span><span class="w"></span>
<span class="w">        </span><span class="p">}</span><span class="w"></span>
<span class="w">    </span><span class="p">}</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</pre></div>
</div>
<p>Full code can be found in the sample <a class="reference external" href="../main/main.html#sample-cupti-finalize">cupti_finalize</a>.</p>
</section>
<section id="device-memory-allocation-source-tracking">
<span id="activity-allocation-source-tracking"></span><h3><span class="section-number">2.3.8. </span>Device Memory Allocation Source Tracking<a class="headerlink" href="#device-memory-allocation-source-tracking" title="Permalink to this headline"></a></h3>
<p>CUDA applications utilize various shared libraries such as cuBLAS, cuFFT, cuDNN etc, each serving distinct purposes.
These libraries can be integrated either statically at compile time or loaded dynamically during runtime. In the
case of dynamic loading, CUPTI enables precise attribution of memory allocations to their respective shared libraries.
This can be achieved by calling the <code class="docutils literal notranslate"><span class="pre">cuptiActivityEnableAllocationSource()</span></code> API. The filepath of the responsible
shared object is assigned in the <code class="docutils literal notranslate"><span class="pre">source</span></code> field in the activity record <code class="docutils literal notranslate"><span class="pre">CUpti_ActivityMemory4</span></code> which is enabled using
the activity kind <code class="docutils literal notranslate"><span class="pre">CUPTI_ACTIVITY_KIND_MEMORY2</span></code>. This functionality is currently exclusive to Linux x86_64 platform.
However, if the library is statically linked, the source is identified as the main application executable rather than
the library.</p>
</section>
</section>
<section id="cupti-callback-api">
<span id="callback-api"></span><h2><span class="section-number">2.4. </span>CUPTI Callback API<a class="headerlink" href="#cupti-callback-api" title="Permalink to this headline"></a></h2>
<p>The CUPTI Callback API allows you to register a callback into your own code. Your callback will be invoked when the application being profiled calls a CUDA runtime or driver function, or when certain events occur in the CUDA driver. The following terminology is used by the callback API.</p>
<dl class="simple">
<dt>Callback Domain</dt><dd><p>Callbacks are grouped into domains to make it easier to associate your callback functions with groups of related CUDA functions or events. There are currently four callback domains, as defined by <code class="docutils literal notranslate"><span class="pre">CUpti_CallbackDomain</span></code>: a domain for CUDA runtime functions, a domain for CUDA driver functions, a domain for CUDA resource tracking, and a domain for CUDA synchronization notification.</p>
</dd>
<dt>Callback ID</dt><dd><p>Each callback is given a unique ID within the corresponding callback domain so that you can identify it within your callback function. The CUDA driver API IDs are defined in <code class="docutils literal notranslate"><span class="pre">cupti_driver_cbid.h</span></code> and the CUDA runtime API IDs are defined in <code class="docutils literal notranslate"><span class="pre">cupti_runtime_cbid.h</span></code>. Both of these headers are included for you when you include <code class="docutils literal notranslate"><span class="pre">cupti.h</span></code>. The CUDA resource callback IDs are defined by <code class="docutils literal notranslate"><span class="pre">CUpti_CallbackIdResource</span></code>, and the CUDA synchronization callback IDs are defined by <code class="docutils literal notranslate"><span class="pre">CUpti_CallbackIdSync</span></code>.</p>
</dd>
<dt>Callback Function</dt><dd><p>Your callback function must be of type <code class="docutils literal notranslate"><span class="pre">CUpti_CallbackFunc</span></code>. This function type has two arguments that specify the callback domain and ID so that you know why the callback is occurring. The type also has a <code class="docutils literal notranslate"><span class="pre">cbdata</span></code> argument that is used to pass data specific to the callback.</p>
</dd>
<dt>Subscriber</dt><dd><p>A subscriber is used to associate each of your callback functions with one or more CUDA API functions. There can be at most one subscriber initialized with <code class="docutils literal notranslate"><span class="pre">cuptiSubscribe()</span></code> at any time. Before initializing a new subscriber, the existing subscriber must be finalized with <code class="docutils literal notranslate"><span class="pre">cuptiUnsubscribe()</span></code>.</p>
</dd>
</dl>
<p>Each callback domain is described in detail below. Unless explicitly stated, it is not supported to call any CUDA runtime or driver API from within a callback function. Doing so may cause the application to hang.</p>
<section id="driver-and-runtime-api-callbacks">
<span id="callback-driver-runtime-api-callbacks"></span><h3><span class="section-number">2.4.1. </span>Driver and Runtime API Callbacks<a class="headerlink" href="#driver-and-runtime-api-callbacks" title="Permalink to this headline"></a></h3>
<p>Using the callback API with the <code class="docutils literal notranslate"><span class="pre">CUPTI_CB_DOMAIN_DRIVER_API</span></code> or <code class="docutils literal notranslate"><span class="pre">CUPTI_CB_DOMAIN_RUNTIME_API</span></code> domains, you can associate a callback function with one or more CUDA API functions. When those CUDA functions are invoked in the application, your callback function is invoked as well. For these domains, the <code class="docutils literal notranslate"><span class="pre">cbdata</span></code> argument to your callback function will be of the type <code class="docutils literal notranslate"><span class="pre">CUpti_CallbackData</span></code>.</p>
<p>It is legal to call <code class="docutils literal notranslate"><span class="pre">cudaThreadSynchronize()</span></code>, <code class="docutils literal notranslate"><span class="pre">cudaDeviceSynchronize()</span></code>, <code class="docutils literal notranslate"><span class="pre">cudaStreamSynchronize()</span></code>, <code class="docutils literal notranslate"><span class="pre">cuCtxSynchronize()</span></code>, and <code class="docutils literal notranslate"><span class="pre">cuStreamSynchronize()</span></code> from within a driver or runtime API callback function.</p>
<p>The following code shows a typical sequence used to associate a callback function with one or more CUDA API functions. To simplify the presentation, error checking code has been removed.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>CUpti_SubscriberHandle subscriber;
MyDataStruct *my_data = ...;
...
cuptiSubscribe(&amp;subscriber,
               (CUpti_CallbackFunc)my_callback , my_data);
cuptiEnableDomain(1, subscriber,
                  CUPTI_CB_DOMAIN_RUNTIME_API);
</pre></div>
</div>
<p>First, <code class="docutils literal notranslate"><span class="pre">cuptiSubscribe</span></code> is used to initialize a subscriber with the <code class="docutils literal notranslate"><span class="pre">my_callback</span></code> callback function. Next, <code class="docutils literal notranslate"><span class="pre">cuptiEnableDomain</span></code> is used to associate that callback with all the CUDA runtime API functions. Using this code sequence will cause <code class="docutils literal notranslate"><span class="pre">my_callback</span></code> to be called twice each time any of the CUDA runtime API functions are invoked, once on entry to the CUDA function and once just before exit from the CUDA function. CUPTI callback API functions <code class="docutils literal notranslate"><span class="pre">cuptiEnableCallback</span></code> and <code class="docutils literal notranslate"><span class="pre">cuptiEnableAllDomains</span></code> can also be used to associate CUDA API functions with a callback (see reference below for more information).</p>
<p>The following code shows a typical callback function.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>void CUPTIAPI
my_callback(void *userdata, CUpti_CallbackDomain domain,
            CUpti_CallbackId cbid, const void *cbdata)
{
  const CUpti_CallbackData *cbInfo = (CUpti_CallbackData *)cbdata;
  MyDataStruct *my_data = (MyDataStruct *)userdata;

  if ((domain == CUPTI_CB_DOMAIN_RUNTIME_API) &amp;&amp;
      (cbid == CUPTI_RUNTIME_TRACE_CBID_cudaMemcpy_v3020))  {
    if (cbInfo-&gt;callbackSite == CUPTI_API_ENTER) {
        cudaMemcpy_v3020_params *funcParams =
             (cudaMemcpy_v3020_params *)(cbInfo-&gt;
                 functionParams);

        size_t count = funcParams-&gt;count;
        enum cudaMemcpyKind kind = funcParams-&gt;kind;
        ...
      }
  ...
</pre></div>
</div>
<p>In your callback function, you use the <code class="docutils literal notranslate"><span class="pre">CUpti_CallbackDomain</span></code> and <code class="docutils literal notranslate"><span class="pre">CUpti_CallbackID</span></code> parameters to determine which CUDA API function invocation is causing this callback. In the example above, we are checking for the CUDA runtime <code class="docutils literal notranslate"><span class="pre">cudaMemcpy</span></code> function. The <code class="docutils literal notranslate"><span class="pre">cbdata</span></code> parameter holds a structure of useful information that can be used within the callback. In this case, we use the <code class="docutils literal notranslate"><span class="pre">callbackSite</span></code> member of the structure to detect that the callback is occurring on entry to <code class="docutils literal notranslate"><span class="pre">cudaMemcpy</span></code>, and we use the <code class="docutils literal notranslate"><span class="pre">functionParams</span></code> member to access the parameters that were passed to <code class="docutils literal notranslate"><span class="pre">cudaMemcpy</span></code>. To access the parameters, we first cast <code class="docutils literal notranslate"><span class="pre">functionParams</span></code> to a structure type corresponding to the <code class="docutils literal notranslate"><span class="pre">cudaMemcpy</span></code> function. These parameter structures are contained in <code class="docutils literal notranslate"><span class="pre">generated_cuda_runtime_api_meta.h</span></code>, <code class="docutils literal notranslate"><span class="pre">generated_cuda_meta.h</span></code>, and a number of other files. When possible, these files are included for you by <code class="docutils literal notranslate"><span class="pre">cupti.h</span></code>.</p>
<p>The <strong>callback_event</strong> and <strong>callback_timestamp</strong> samples described on the <a class="reference external" href="../main/main.html#samples">samples page</a> both show how to use the callback API for the driver and runtime API domains.</p>
</section>
<section id="resource-callbacks">
<span id="callback-resource-callbacks"></span><h3><span class="section-number">2.4.2. </span>Resource Callbacks<a class="headerlink" href="#resource-callbacks" title="Permalink to this headline"></a></h3>
<p>Using the callback API with the <code class="docutils literal notranslate"><span class="pre">CUPTI_CB_DOMAIN_RESOURCE</span></code> domain, you can associate a callback function with some CUDA resource creation and destruction events. For example, when a CUDA context is created, your callback function will be invoked with a callback ID equal to <code class="docutils literal notranslate"><span class="pre">CUPTI_CBID_RESOURCE_CONTEXT_CREATED</span></code>. For this domain, the <code class="docutils literal notranslate"><span class="pre">cbdata</span></code> argument to your callback function will be of the type <code class="docutils literal notranslate"><span class="pre">CUpti_ResourceData</span></code>.</p>
<p>Note that APIs <code class="docutils literal notranslate"><span class="pre">cuptiActivityFlush</span></code> and <code class="docutils literal notranslate"><span class="pre">cuptiActivityFlushAll</span></code> will result in deadlock when called from stream destroy starting callback identified using callback ID <code class="docutils literal notranslate"><span class="pre">CUPTI_CBID_RESOURCE_STREAM_DESTROY_STARTING</span></code>.</p>
</section>
<section id="synchronization-callbacks">
<span id="callback-synchronization-callbacks"></span><h3><span class="section-number">2.4.3. </span>Synchronization Callbacks<a class="headerlink" href="#synchronization-callbacks" title="Permalink to this headline"></a></h3>
<p>Using the callback API with the <code class="docutils literal notranslate"><span class="pre">CUPTI_CB_DOMAIN_SYNCHRONIZE</span></code> domain, you can associate a callback function with CUDA context and stream synchronizations. For example, when a CUDA context is synchronized, your callback function will be invoked with a callback ID equal to <code class="docutils literal notranslate"><span class="pre">CUPTI_CBID_SYNCHRONIZE_CONTEXT_SYNCHRONIZED</span></code>. For this domain, the <code class="docutils literal notranslate"><span class="pre">cbdata</span></code> argument to your callback function will be of the type <code class="docutils literal notranslate"><span class="pre">CUpti_SynchronizeData</span></code>.</p>
</section>
<section id="nvidia-tools-extension-callbacks">
<span id="callback-nvtx-callbacks"></span><h3><span class="section-number">2.4.4. </span>NVIDIA Tools Extension Callbacks<a class="headerlink" href="#nvidia-tools-extension-callbacks" title="Permalink to this headline"></a></h3>
<p>Using the callback API with the <code class="docutils literal notranslate"><span class="pre">CUPTI_CB_DOMAIN_NVTX</span></code> domain, you can associate a callback function with NVIDIA Tools Extension (NVTX) API functions. When an NVTX function is invoked in the application, your callback function is invoked as well. For these domains, the <code class="docutils literal notranslate"><span class="pre">cbdata</span></code> argument to your callback function will be of the type <code class="docutils literal notranslate"><span class="pre">CUpti_NvtxData</span></code>.</p>
<p>The NVTX library has its own convention for discovering the profiling library that will provide the implementation of the NVTX callbacks. To receive callbacks, you must set the NVTX environment variables appropriately so that when the application calls an NVTX function, your profiling library receives the callbacks. The following code sequence shows a typical initialization sequence to enable NVTX callbacks and activity records.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="cm">/* Set env so CUPTI-based profiling library loads on first nvtx call. */</span><span class="w"></span>
<span class="kt">char</span><span class="w"> </span><span class="o">*</span><span class="n">inj32_path</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;/path/to/32-bit/version/of/cupti/based/profiling/library&quot;</span><span class="p">;</span><span class="w"></span>
<span class="kt">char</span><span class="w"> </span><span class="o">*</span><span class="n">inj64_path</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;/path/to/64-bit/version/of/cupti/based/profiling/library&quot;</span><span class="p">;</span><span class="w"></span>
<span class="n">setenv</span><span class="p">(</span><span class="s">&quot;NVTX_INJECTION32_PATH&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">inj32_path</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span><span class="w"></span>
<span class="n">setenv</span><span class="p">(</span><span class="s">&quot;NVTX_INJECTION64_PATH&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">inj64_path</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span><span class="w"></span>
</pre></div>
</div>
<p>The following code shows a typical sequence used to associate a callback function with one or more NVTX functions. To simplify the presentation, error checking code has been removed.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>CUpti_SubscriberHandle subscriber;
MyDataStruct *my_data = ...;
...
cuptiSubscribe(&amp;subscriber,
               (CUpti_CallbackFunc)my_callback , my_data);
cuptiEnableDomain(1, subscriber,
                  CUPTI_CB_DOMAIN_NVTX);
</pre></div>
</div>
<p>First, <code class="docutils literal notranslate"><span class="pre">cuptiSubscribe</span></code> is used to initialize a subscriber with the <code class="docutils literal notranslate"><span class="pre">my_callback</span></code> callback function. Next, <code class="docutils literal notranslate"><span class="pre">cuptiEnableDomain</span></code> is used to associate that callback with all the NVTX functions. Using this code sequence will cause <code class="docutils literal notranslate"><span class="pre">my_callback</span></code> to be called once each time any of the NVTX functions are invoked. CUPTI callback API functions <code class="docutils literal notranslate"><span class="pre">cuptiEnableCallback</span></code> and <code class="docutils literal notranslate"><span class="pre">cuptiEnableAllDomains</span></code> can also be used to associate NVTX API functions with a callback (see reference below for more information).</p>
<p>The following code shows a typical callback function.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>void CUPTIAPI
my_callback(void *userdata, CUpti_CallbackDomain domain,
            CUpti_CallbackId cbid, const void *cbdata)
{
  const CUpti_NvtxData *nvtxInfo = (CUpti_NvtxData *)cbdata;
  MyDataStruct *my_data = (MyDataStruct *)userdata;

  if ((domain == CUPTI_CB_DOMAIN_NVTX) &amp;&amp;
      (cbid == CUPTI_CBID_NVTX_nvtxRangeStartEx))  {
    nvtxRangeStartEx_params *params = (nvtxRangeStartEx_params *)nvtxInfo-&gt;
             functionParams;
    nvtxRangeId_t *id = (nvtxRangeId_t *)nvtxInfo-&gt;functionReturnValue;
    ...
  }
  ...
</pre></div>
</div>
<p>In your callback function, you use the <code class="docutils literal notranslate"><span class="pre">CUpti_CallbackDomain</span></code> and <code class="docutils literal notranslate"><span class="pre">CUpti_CallbackID</span></code> parameters to determine which NVTX API function invocation is causing this callback. In the example above, we are checking for the <code class="docutils literal notranslate"><span class="pre">nvtxRangeStartEx</span></code> function. The <code class="docutils literal notranslate"><span class="pre">cbdata</span></code> parameter holds a structure of useful information that can be used within the callback. In this case, we use the <code class="docutils literal notranslate"><span class="pre">functionParams</span></code> member to access the parameters that were passed to <code class="docutils literal notranslate"><span class="pre">nvtxRangeStartEx</span></code>. To access the parameters, we first cast <code class="docutils literal notranslate"><span class="pre">functionParams</span></code> to a structure type corresponding to the <code class="docutils literal notranslate"><span class="pre">nvtxRangeStartEx</span></code> function. These parameter structures are contained in <code class="docutils literal notranslate"><span class="pre">generated_nvtx_meta.h</span></code>. We also use <code class="docutils literal notranslate"><span class="pre">functionReturnValue</span></code> member to access the value returned by <code class="docutils literal notranslate"><span class="pre">nvtxRangeStartEx</span></code>. To access the return value, we first cast <code class="docutils literal notranslate"><span class="pre">functionReturnValue</span></code> to the return type corresponding to the <code class="docutils literal notranslate"><span class="pre">nvtxRangeStartEx</span></code> function. If there is no return value for the NVTX function, <code class="docutils literal notranslate"><span class="pre">functionReturnValue</span></code> is NULL.</p>
<p>The sample <a class="reference external" href="../main/main.html#sample-cupti-nvtx">cupti_nvtx</a> shows the initialization sequence to enable NVTX callbacks and activity records.</p>
<p>If your CUPTI-based profiling library links static CUPTI library, you can define and export your own NvtxInitializeInjection and NvtxInitializeInjection2 functions, which would be called by setting the NVTX environment variables.</p>
<p>If you want CUPTI to handle NVTX calls, these functions should call CUPTI’s corresponding initialization functions, as shown in the example below so that when the application calls a NVTX function, your profiling library receives the callbacks. The following code sequence shows how this can be done to receive callbacks and activity records when linking static CUPTI library.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="cm">/* Set env so CUPTI-based profiling library loads on first nvtx call. */</span><span class="w"></span>
<span class="kt">char</span><span class="w"> </span><span class="o">*</span><span class="n">inj32_path</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;/path/to/32-bit/version/of/cupti/based/profiling/library&quot;</span><span class="p">;</span><span class="w"></span>
<span class="kt">char</span><span class="w"> </span><span class="o">*</span><span class="n">inj64_path</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;/path/to/64-bit/version/of/cupti/based/profiling/library&quot;</span><span class="p">;</span><span class="w"></span>
<span class="n">setenv</span><span class="p">(</span><span class="s">&quot;NVTX_INJECTION32_PATH&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">inj32_path</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span><span class="w"></span>
<span class="n">setenv</span><span class="p">(</span><span class="s">&quot;NVTX_INJECTION64_PATH&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">inj64_path</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span><span class="w"></span>

<span class="cm">/* Extern the CUPTI NVTX initialization APIs. The APIs are thread-safe */</span><span class="w"></span>
<span class="k">extern</span><span class="w"> </span><span class="s">&quot;C&quot;</span><span class="w"> </span><span class="n">CUptiResult</span><span class="w"> </span><span class="n">CUPTIAPI</span><span class="w"> </span><span class="n">cuptiNvtxInitialize</span><span class="p">(</span><span class="kt">void</span><span class="o">*</span><span class="w"> </span><span class="n">pfnGetExportTable</span><span class="p">);</span><span class="w"></span>
<span class="k">extern</span><span class="w"> </span><span class="s">&quot;C&quot;</span><span class="w"> </span><span class="n">CUptiResult</span><span class="w"> </span><span class="n">CUPTIAPI</span><span class="w"> </span><span class="n">cuptiNvtxInitialize2</span><span class="p">(</span><span class="kt">void</span><span class="o">*</span><span class="w"> </span><span class="n">pfnGetExportTable</span><span class="p">);</span><span class="w"></span>

<span class="k">extern</span><span class="w"> </span><span class="s">&quot;C&quot;</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">InitializeInjectionNvtx</span><span class="p">(</span><span class="kt">void</span><span class="o">*</span><span class="w"> </span><span class="n">p</span><span class="p">)</span><span class="w"></span>
<span class="p">{</span><span class="w"></span>
<span class="w">  </span><span class="n">CUptiResult</span><span class="w"> </span><span class="n">res</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cuptiNvtxInitialize</span><span class="p">(</span><span class="n">p</span><span class="p">);</span><span class="w"></span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="p">(</span><span class="n">res</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">CUPTI_SUCCESS</span><span class="p">)</span><span class="w"> </span><span class="o">?</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>

<span class="k">extern</span><span class="w"> </span><span class="s">&quot;C&quot;</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">InitializeInjectionNvtx2</span><span class="p">(</span><span class="kt">void</span><span class="o">*</span><span class="w"> </span><span class="n">p</span><span class="p">)</span><span class="w"></span>
<span class="p">{</span><span class="w"></span>
<span class="w">  </span><span class="n">CUptiResult</span><span class="w"> </span><span class="n">res</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cuptiNvtxInitialize2</span><span class="p">(</span><span class="n">p</span><span class="p">);</span><span class="w"></span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="p">(</span><span class="n">res</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">CUPTI_SUCCESS</span><span class="p">)</span><span class="w"> </span><span class="o">?</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</pre></div>
</div>
<p>Alternatively, if you want to handle NVTX calls directly in your profiling library, you can attach your own callbacks to the NVTX client in these functions.</p>
<p>NVTX v1 and v2 both have the initialization code in a single injection library shared by all users of NVTX in the whole process, so the initialization will happen only once per process. NVTX v3 embeds the initialization code into your own binaries, so if NVTX v3 is in multiple dynamic libraries, each one of those sites will initialize the first time a NVTX call is made from that dynamic library. These first calls could be on different threads. So if you are wiring up your own NVTX handlers, you should ensure that code is thread-safe when called from multiple threads at once.</p>
</section>
<section id="state-callbacks">
<span id="id2"></span><h3><span class="section-number">2.4.5. </span>State Callbacks<a class="headerlink" href="#state-callbacks" title="Permalink to this headline"></a></h3>
<p>Any fatal error encountered by an explicit CUPTI API call is returned by the API itself, whereas errors encountered by CUPTI in the background is returned to the user only during the next explicit CUPTI API call. Using the callback API with the <code class="docutils literal notranslate"><span class="pre">CUPTI_CB_DOMAIN_STATE</span></code> domain, you can associate a callback function with errors in CUPTI, and receive the reported error instantaneously. For example, when a CUPTI runs into a fatal error, your callback function will be invoked with a callback ID equal to <code class="docutils literal notranslate"><span class="pre">CUPTI_CBID_STATE_FATAL_ERROR</span></code>. For this domain, the <code class="docutils literal notranslate"><span class="pre">cbdata</span></code> argument to your callback function will be of the type <code class="docutils literal notranslate"><span class="pre">CUpti_StateData</span></code>.</p>
<p>As part of CUpti_StateData, you can receive the error code of the failure, along with an appropriate error message with possible causes or appropriate links to documentation. The example usage of these callbacks can be found in the CUPTI trace samples.</p>
</section>
</section>
<section id="cupti-event-api">
<span id="event-api"></span><h2><span class="section-number">2.5. </span>CUPTI Event API<a class="headerlink" href="#cupti-event-api" title="Permalink to this headline"></a></h2>
<p>The CUPTI Event API allows you to query, configure, start, stop, and read the event counters on a CUDA-enabled device. The following terminology is used by the event API.</p>
<dl class="simple">
<dt>Event</dt><dd><p>An event is a countable activity, action, or occurrence on a device.</p>
</dd>
<dt>Event ID</dt><dd><p>Each event is assigned a unique identifier. A named event will represent the same activity, action, or occurrence on all device types. But the named event may have different IDs on different device families. Use <code class="docutils literal notranslate"><span class="pre">cuptiEventGetIdFromName</span></code> to get the ID for a named event on a particular device.</p>
</dd>
<dt>Event Category</dt><dd><p>Each event is placed in one of the categories defined by <code class="docutils literal notranslate"><span class="pre">CUpti_EventCategory</span></code>. The category indicates the general type of activity, action, or occurrence measured by the event.</p>
</dd>
<dt>Event Domain</dt><dd><p>A device exposes one or more event domains. Each event domain represents a group of related events available on that device. A device may have multiple instances of a domain, indicating that the device can simultaneously record multiple instances of each event within that domain.</p>
</dd>
<dt>Event Group</dt><dd><p>An event group is a collection of events that are managed together. The number and type of events that can be added to an event group are subject to device-specific limits. At any given time, a device may be configured to count events from a limited number of event groups. All events in an event group must belong to the same event domain.</p>
</dd>
<dt>Event Group Set</dt><dd><p>An event group set is a collection of event groups that can be enabled at the same time. Event group sets are created by <code class="docutils literal notranslate"><span class="pre">cuptiEventGroupSetsCreate</span></code> and <code class="docutils literal notranslate"><span class="pre">cuptiMetricCreateEventGroupSets</span></code>.</p>
</dd>
</dl>
<p>You can determine the events available on a device using the <code class="docutils literal notranslate"><span class="pre">cuptiDeviceEnumEventDomains</span></code> and <code class="docutils literal notranslate"><span class="pre">cuptiEventDomainEnumEvents</span></code> functions. The <strong>cupti_query</strong> sample described on the <a class="reference external" href="../main/main.html#samples">samples page</a> shows how to use these functions. You can also enumerate all the CUPTI events available on any device using the <code class="docutils literal notranslate"><span class="pre">cuptiEnumEventDomains</span></code> function.</p>
<p>Configuring and reading event counts requires the following steps. First, select your event collection mode. If you want to count events that occur during the execution of a kernel, use <code class="docutils literal notranslate"><span class="pre">cuptiSetEventCollectionMode</span></code> to set mode <code class="docutils literal notranslate"><span class="pre">CUPTI_EVENT_COLLECTION_MODE_KERNEL</span></code>. If you want to continuously sample the event counts, use mode <code class="docutils literal notranslate"><span class="pre">CUPTI_EVENT_COLLECTION_MODE_CONTINUOUS</span></code>. Next, determine the names of the events that you want to count, and then use the <code class="docutils literal notranslate"><span class="pre">cuptiEventGroupCreate</span></code>, <code class="docutils literal notranslate"><span class="pre">cuptiEventGetIdFromName</span></code>, and <code class="docutils literal notranslate"><span class="pre">cuptiEventGroupAddEvent</span></code> functions to create and initialize an event group with those events. If you are unable to add all the events to a single event group, then you will need to create multiple event groups. Alternatively, you can use the <code class="docutils literal notranslate"><span class="pre">cuptiEventGroupSetsCreate</span></code> function to automatically create the event group(s) required for a set of events.</p>
<p>It’s possible that all the requested events can’t be collected in the single pass due to hardware or software limitations, one needs to replay the exact same set of GPU workloads multiple times. Number of passes can be queried using the API <code class="docutils literal notranslate"><span class="pre">cuptiEventGroupSetsCreate</span></code>. Profiling one event always takes single pass. Multiple passes might be required when we want to profile multiple events together. Code snippet showing how to query number of passes:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">CUpti_EventGroupSets</span><span class="w"> </span><span class="o">*</span><span class="n">eventGroupSets</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">NULL</span><span class="p">;</span><span class="w"></span>
<span class="kt">size_t</span><span class="w"> </span><span class="n">eventIdArraySize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="n">CUpti_EventID</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">numEvents</span><span class="p">;</span><span class="w"></span>
<span class="n">CUpti_EventID</span><span class="w"> </span><span class="o">*</span><span class="n">eventIdArray</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">CUpti_EventID</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="k">sizeof</span><span class="p">(</span><span class="n">CUpti_EventID</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">numEvents</span><span class="p">);</span><span class="w"></span>
<span class="c1">// fill in event Ids</span>
<span class="n">cuptiEventGroupSetsCreate</span><span class="p">(</span><span class="n">context</span><span class="p">,</span><span class="w"> </span><span class="n">eventIdArraySize</span><span class="p">,</span><span class="w"> </span><span class="n">eventIdArray</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">eventGroupSets</span><span class="p">);</span><span class="w"></span>
<span class="c1">// number of passes required to collect all the events</span>
<span class="n">passes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">eventGroupSets</span><span class="o">-&gt;</span><span class="n">numSets</span><span class="p">;</span><span class="w"></span>
</pre></div>
</div>
<p>To begin counting a set of events, enable the event group or groups that contain those events by using the <code class="docutils literal notranslate"><span class="pre">cuptiEventGroupEnable</span></code> function. If your events are contained in multiple event groups, you may be unable to enable all of the event groups at the same time i.e. in the same pass. In this case, you can gather the events across multiple executions of the application or you can enable kernel replay. If you enable kernel replay using <code class="docutils literal notranslate"><span class="pre">cuptiEnableKernelReplayMode</span></code>, you will be able to enable any number of event groups and all the contained events will be collected.</p>
<p>Use the <code class="docutils literal notranslate"><span class="pre">cuptiEventGroupReadEvent</span></code> and/or <code class="docutils literal notranslate"><span class="pre">cuptiEventGroupReadAllEvents</span></code> functions to read the event values. When you are done collecting events, use the <code class="docutils literal notranslate"><span class="pre">cuptiEventGroupDisable</span></code> function to stop counting the events contained in an event group. The <strong>callback_event</strong> sample described on the <a class="reference external" href="../main/main.html#samples">samples page</a> shows how to use these functions to create, enable, and disable event groups, and how to read event counts.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For event collection mode <code class="docutils literal notranslate"><span class="pre">CUPTI_EVENT_COLLECTION_MODE_KERNEL</span></code>, event or metric collection may significantly change the overall performance characteristics of the application because all kernel executions that occur between the <code class="docutils literal notranslate"><span class="pre">cuptiEventGroupEnable</span></code> and <code class="docutils literal notranslate"><span class="pre">cuptiEventGroupDisable</span></code> calls are serialized on the GPU. This can be avoided by using mode <code class="docutils literal notranslate"><span class="pre">CUPTI_EVENT_COLLECTION_MODE_CONTINUOUS</span></code>, and restricting profiling to events and metrics that can be collected in a single pass.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>All the events and metrics except NVLink metrics are collected at the context level, irrespective of the event collection mode. That is, events or metrics can be attributed to the context being profiled and values can be accurately collected, when multiple contexts are executing on the GPU. NVLink metrics are collected at device level for all event collection modes.</p>
</div>
<p>In a system with multiple GPUs, events can be collected simultaneously on all the GPUs; in other words, event profiling doesn’t enforce any serialization of work across GPUs. The <a class="reference external" href="../main/main.html#sample-event-multi-gpu">event_multi_gpu</a> sample shows how to use the CUPTI event and CUDA APIs on such setups.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Event APIs from the header <code class="docutils literal notranslate"><span class="pre">cupti_events.h</span></code> are not supported for devices with compute capability 7.5 and higher. It is advised to use the <a class="reference external" href="../main/main.html#cupti-profiling-api">CUPTI Profiling API</a> instead. Refer to the section <a class="reference external" href="../main/main.html#migration-to-the-profiling-api">Migration to the Profiling API</a>.</p>
</div>
<section id="collecting-kernel-execution-events">
<span id="event-collecting-kernel-execution-events"></span><h3><span class="section-number">2.5.1. </span>Collecting Kernel Execution Events<a class="headerlink" href="#collecting-kernel-execution-events" title="Permalink to this headline"></a></h3>
<p>A common use of the event API is to count a set of events during the execution of a kernel (as demonstrated by the <strong>callback_event</strong> sample). The following code shows a typical callback used for this purpose. Assume that the callback was enabled only for a kernel launch using the CUDA runtime (i.e., by <code class="docutils literal notranslate"><span class="pre">cuptiEnableCallback(1,</span> <span class="pre">subscriber,</span> <span class="pre">CUPTI_CB_DOMAIN_RUNTIME_API,</span> <span class="pre">CUPTI_RUNTIME_TRACE_CBID_cudaLaunch_v3020)</span></code>. To simplify the presentation, error checking code has been removed.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="k">static</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">CUPTIAPI</span><span class="w"></span>
<span class="nf">getEventValueCallback</span><span class="p">(</span><span class="kt">void</span><span class="w"> </span><span class="o">*</span><span class="n">userdata</span><span class="p">,</span><span class="w"></span>
<span class="w">                      </span><span class="n">CUpti_CallbackDomain</span><span class="w"> </span><span class="n">domain</span><span class="p">,</span><span class="w"></span>
<span class="w">                      </span><span class="n">CUpti_CallbackId</span><span class="w"> </span><span class="n">cbid</span><span class="p">,</span><span class="w"></span>
<span class="w">                      </span><span class="k">const</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="o">*</span><span class="n">cbdata</span><span class="p">)</span><span class="w"></span>
<span class="p">{</span><span class="w"></span>
<span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="n">CUpti_CallbackData</span><span class="w"> </span><span class="o">*</span><span class="n">cbData</span><span class="w"> </span><span class="o">=</span><span class="w"></span>
<span class="w">                </span><span class="p">(</span><span class="n">CUpti_CallbackData</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="n">cbdata</span><span class="p">;</span><span class="w"></span>

<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">cbData</span><span class="o">-&gt;</span><span class="n">callbackSite</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">CUPTI_API_ENTER</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="n">cudaDeviceSynchronize</span><span class="p">();</span><span class="w"></span>
<span class="w">    </span><span class="n">cuptiSetEventCollectionMode</span><span class="p">(</span><span class="n">cbInfo</span><span class="o">-&gt;</span><span class="n">context</span><span class="p">,</span><span class="w"></span>
<span class="w">                                </span><span class="n">CUPTI_EVENT_COLLECTION_MODE_KERNEL</span><span class="p">);</span><span class="w"></span>
<span class="w">    </span><span class="n">cuptiEventGroupEnable</span><span class="p">(</span><span class="n">eventGroup</span><span class="p">);</span><span class="w"></span>
<span class="w">  </span><span class="p">}</span><span class="w"></span>

<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">cbData</span><span class="o">-&gt;</span><span class="n">callbackSite</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">CUPTI_API_EXIT</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="n">cudaDeviceSynchronize</span><span class="p">();</span><span class="w"></span>
<span class="w">    </span><span class="n">cuptiEventGroupReadEvent</span><span class="p">(</span><span class="n">eventGroup</span><span class="p">,</span><span class="w"></span>
<span class="w">                             </span><span class="n">CUPTI_EVENT_READ_FLAG_NONE</span><span class="p">,</span><span class="w"></span>
<span class="w">                             </span><span class="n">eventId</span><span class="p">,</span><span class="w"></span>
<span class="w">                             </span><span class="o">&amp;</span><span class="n">bytesRead</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">eventVal</span><span class="p">);</span><span class="w"></span>

<span class="w">    </span><span class="n">cuptiEventGroupDisable</span><span class="p">(</span><span class="n">eventGroup</span><span class="p">);</span><span class="w"></span>
<span class="w">  </span><span class="p">}</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</pre></div>
</div>
<p>Two synchronization points are used to ensure that events are counted only for the execution of the kernel. If the application contains other threads that launch kernels, then additional thread-level synchronization must also be introduced to ensure that those threads do not launch kernels while the callback is collecting events. When the cudaLaunch API is entered (that is, before the kernel is actually launched on the device), <code class="docutils literal notranslate"><span class="pre">cudaDeviceSynchronize</span></code> is used to wait until the GPU is idle. The event collection mode is set to <code class="docutils literal notranslate"><span class="pre">CUPTI_EVENT_COLLECTION_MODE_KERNEL</span></code> so that the event counters are automatically started and stopped just before and after the kernel executes. Then event collection is enabled with <code class="docutils literal notranslate"><span class="pre">cuptiEventGroupEnable</span></code>.</p>
<p>When the cudaLaunch API is exited (that is, after the kernel is queued for execution on the GPU) another <code class="docutils literal notranslate"><span class="pre">cudaDeviceSynchronize</span></code> is used to cause the CPU thread to wait for the kernel to finish execution. Finally, the event counts are read with <code class="docutils literal notranslate"><span class="pre">cuptiEventGroupReadEvent</span></code>.</p>
</section>
<section id="sampling-events">
<span id="event-sampling-events"></span><h3><span class="section-number">2.5.2. </span>Sampling Events<a class="headerlink" href="#sampling-events" title="Permalink to this headline"></a></h3>
<p>The event API can also be used to sample event values while a kernel or kernels are executing (as demonstrated by the <strong>event_sampling</strong> sample). The sample shows one possible way to perform the sampling. The event collection mode is set to <code class="docutils literal notranslate"><span class="pre">CUPTI_EVENT_COLLECTION_MODE_CONTINUOUS</span></code> so that the event counters run continuously. Two threads are used in <strong>event_sampling</strong>: one thread schedules the kernels and memcpys that perform the computation, while another thread wakes up periodically to sample an event counter. In this sample, there is no correlation of the event samples with what is happening on the GPU.</p>
</section>
</section>
<section id="cupti-metric-api">
<span id="metric-api"></span><h2><span class="section-number">2.6. </span>CUPTI Metric API<a class="headerlink" href="#cupti-metric-api" title="Permalink to this headline"></a></h2>
<p>The CUPTI Metric API allows you to collect application metrics calculated from one or more event values. The following terminology is used by the metric API.</p>
<dl class="simple">
<dt>Metric</dt><dd><p>A characteristic of an application that is calculated from one or more event values.</p>
</dd>
<dt>Metric ID</dt><dd><p>Each metric is assigned a unique identifier. A named metric will represent the same characteristic on all device types. But the named metric may have different IDs on different device families. Use <code class="docutils literal notranslate"><span class="pre">cuptiMetricGetIdFromName</span></code> to get the ID for a named metric on a particular device.</p>
</dd>
<dt>Metric Category</dt><dd><p>Each metric is placed in one of the categories defined by <code class="docutils literal notranslate"><span class="pre">CUpti_MetricCategory</span></code>. The category indicates the general type of the characteristic measured by the metric.</p>
</dd>
<dt>Metric Property</dt><dd><p>Each metric is calculated from input values. These input values can be events or properties of the device or system. The available properties are defined by <code class="docutils literal notranslate"><span class="pre">CUpti_MetricPropertyID</span></code>.</p>
</dd>
<dt>Metric Value</dt><dd><p>Each metric has a value that represents one of the kinds defined by <code class="docutils literal notranslate"><span class="pre">CUpti_MetricValueKind</span></code>. For each value kind, there is a corresponding member of the <code class="docutils literal notranslate"><span class="pre">CUpti_MetricValue</span></code> union that is used to hold the metric’s value.</p>
</dd>
</dl>
<p>The tables included in this section list the metrics available for each device, as determined by the device’s compute capability. You can also determine the metrics available on a device using the <code class="docutils literal notranslate"><span class="pre">cuptiDeviceEnumMetrics</span></code> function. The <strong>cupti_query</strong> sample described on the <a class="reference external" href="../main/main.html#samples">samples page</a> shows how to use this function. You can also enumerate all the CUPTI metrics available on any device using the <code class="docutils literal notranslate"><span class="pre">cuptiEnumMetrics</span></code> function.</p>
<p>CUPTI provides two functions for calculating a metric value. <code class="docutils literal notranslate"><span class="pre">cuptiMetricGetValue2</span></code> can be used to calculate a metric value when the device is not available. All required event values and metric properties must be provided by the caller. <code class="docutils literal notranslate"><span class="pre">cuptiMetricGetValue</span></code> can be used to calculate a metric value when the device is available (as a CUdevice object). All required event values must be provided by the caller, but CUPTI will determine the appropriate property values from the CUdevice object.</p>
<p>Configuring and calculating metric values requires the following steps. First, determine the name of the metric that you want to collect, and then use the <code class="docutils literal notranslate"><span class="pre">cuptiMetricGetIdFromName</span></code> to get the metric ID. Use <code class="docutils literal notranslate"><span class="pre">cuptiMetricEnumEvents</span></code> to get the events required to calculate the metric, and follow instructions in the CUPTI Event API section to create the event groups for those events. When creating event groups in this manner, it is important to use the result of <code class="docutils literal notranslate"><span class="pre">cuptiMetricGetRequiredEventGroupSets</span></code> to properly group together events that must be collected in the same pass to ensure proper metric calculation.</p>
<p>Alternatively, you can use the <code class="docutils literal notranslate"><span class="pre">cuptiMetricCreateEventGroupSets</span></code> function to automatically create the event group(s) required for metrics’ events. When using this function, events will be grouped as required to most accurately calculate the metric; as a result, it is not necessary to use <code class="docutils literal notranslate"><span class="pre">cuptiMetricGetRequiredEventGroupSets</span></code>.</p>
<p>If you are using <code class="docutils literal notranslate"><span class="pre">cuptiMetricGetValue2</span></code>, then you must also collect the required metric property values using <code class="docutils literal notranslate"><span class="pre">cuptiMetricEnumProperties</span></code>.</p>
<p>Collect event counts as described in the CUPTI Event API section, and then use either <code class="docutils literal notranslate"><span class="pre">cuptiMetricGetValue</span></code> or <code class="docutils literal notranslate"><span class="pre">cuptiMetricGetValue2</span></code> to calculate the metric value from the collected event and property values. The <strong>callback_metric</strong> sample described on the <a class="reference external" href="../main/main.html#samples">samples page</a> shows how to use the functions to calculate event values and calculate a metric using <code class="docutils literal notranslate"><span class="pre">cuptiMetricGetValue</span></code>. Note that as shown in the example, you should collect event counts from all domain instances, and normalize the counts to get the most accurate metric values. It is necessary to normalize the event counts because the number of event counter instances varies by device and by the event being counted.</p>
<p>For example, a device might have 8 multiprocessors but only have event counters for 4 of the multiprocessors, and might have 3 memory units and only have events counters for one memory unit. When calculating a metric that requires a multiprocessor event and a memory unit event, the 4 multiprocessor counters should be summed and multiplied by 2 to normalize the event count across the entire device. Similarly, the one memory unit counter should be multiplied by 3 to normalize the event count across the entire device. The normalized values can then be passed to <code class="docutils literal notranslate"><span class="pre">cuptiMetricGetValue</span></code> or <code class="docutils literal notranslate"><span class="pre">cuptiMetricGetValue2</span></code> to calculate the metric value.</p>
<p>As described, the normalization assumes the kernel executes a sufficient number of blocks to completely load the device. If the kernel has only a small number of blocks, normalizing across the entire device may skew the result.</p>
<p>It’s possible that all the requested metrics can’t be collected in the single pass due to hardware or software limitations, one needs to replay the exact same set of GPU workloads multiple times. Number of passes can be queried using the API <code class="docutils literal notranslate"><span class="pre">cuptiMetricCreateEventGroupSets</span></code>. Profiling a single metric can also take multiple passes depending on the number and type of events it is calculated from. Code snippet showing how to query number of passes:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">CUpti_EventGroupSets</span><span class="w"> </span><span class="o">*</span><span class="n">eventGroupSets</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">NULL</span><span class="p">;</span><span class="w"></span>
<span class="kt">size_t</span><span class="w"> </span><span class="n">metricIdArraySize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="n">CUpti_MetricID</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">numMetrics</span><span class="p">;</span><span class="w"></span>
<span class="n">CUpti_MetricID</span><span class="w"> </span><span class="n">metricIdArray</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">CUpti_MetricID</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="k">sizeof</span><span class="p">(</span><span class="n">CUpti_MetricID</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">numMetrics</span><span class="p">);</span><span class="w"></span>
<span class="c1">// fill in metric Ids</span>
<span class="n">cuptiMetricCreateEventGroupSets</span><span class="p">(</span><span class="n">context</span><span class="p">,</span><span class="w"> </span><span class="n">metricIdArraySize</span><span class="p">,</span><span class="w"> </span><span class="n">metricIdArray</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">eventGroupSets</span><span class="p">);</span><span class="w"></span>
<span class="c1">// number of passes required to collect all the metrics</span>
<span class="n">passes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">eventGroupSets</span><span class="o">-&gt;</span><span class="n">numSets</span><span class="p">;</span><span class="w"></span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Metric APIs from the header <code class="docutils literal notranslate"><span class="pre">cupti_metrics.h</span></code> are not supported for devices with compute capability 7.5 and higher. It is advised to use the <a class="reference external" href="../main/main.html#cupti-profiling-api">CUPTI Profiling API</a> instead. Refer to the section <a class="reference external" href="../main/main.html#migration-to-the-profiling-api">Migration to the Profiling API</a>.</p>
</div>
<section id="metrics-reference">
<span id="metric-metrics-reference"></span><h3><span class="section-number">2.6.1. </span>Metrics Reference<a class="headerlink" href="#metrics-reference" title="Permalink to this headline"></a></h3>
<p>This section contains detailed descriptions of the metrics that can be collected by the CUPTI. A scope value of “Single-context” indicates that the metric can only be accurately collected when a single context (CUDA or graphics) is executing on the GPU. A scope value of “Multi-context” indicates that the metric can be accurately collected when multiple contexts are executing on the GPU. A scope value of “Device” indicates that the metric will be collected at device level, that is, it will include values for all the contexts executing on the GPU.</p>
<section id="metrics-for-capability-5-x">
<span id="metric-metrics-reference-5x"></span><h4><span class="section-number">2.6.1.1. </span>Metrics for Capability 5.x<a class="headerlink" href="#metrics-for-capability-5-x" title="Permalink to this headline"></a></h4>
<p>Devices with compute capability 5.x implement the metrics shown in the following table. Note that for some metrics, the “Multi-context” scope is supported only for specific devices. Such metrics are marked with “Multi-context<sup>*</sup>” under the “Scope” column. Refer to the note at the bottom of the table.</p>
<table class="table-no-stripes docutils align-default" id="id10">
<caption><span class="caption-text">Table 1. Capability 5.x Metrics</span><a class="headerlink" href="#id10" title="Permalink to this table"></a></caption>
<colgroup>
<col style="width: 13%" />
<col style="width: 79%" />
<col style="width: 8%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Metric Name</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Scope</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>achieved_occupancy</p></td>
<td><p>Ratio of the average active warps per active cycle to the maximum number of warps supported on a multiprocessor</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>atomic_transactions</p></td>
<td><p>Global memory atomic and reduction transactions</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>atomic_transactions_per_request</p></td>
<td><p>Average number of global memory atomic and reduction transactions performed for each atomic and reduction instruction</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>branch_efficiency</p></td>
<td><p>Ratio of non-divergent branches to total branches expressed as percentage</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>cf_executed</p></td>
<td><p>Number of executed control-flow instructions</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>cf_fu_utilization</p></td>
<td><p>The utilization level of the multiprocessor function units that execute control-flow instructions on a scale of 0 to 10</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>cf_issued</p></td>
<td><p>Number of issued control-flow instructions</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>double_precision_fu_utilization</p></td>
<td><p>The utilization level of the multiprocessor function units that execute double-precision floating-point instructions on a scale of 0 to 10</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>dram_read_bytes</p></td>
<td><p>Total bytes read from DRAM to L2 cache. This is available for compute capability 5.0 and 5.2.</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-odd"><td><p>dram_read_throughput</p></td>
<td><p>Device memory read throughput. This is available for compute capability 5.0 and 5.2.</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-even"><td><p>dram_read_transactions</p></td>
<td><p>Device memory read transactions. This is available for compute capability 5.0 and 5.2.</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-odd"><td><p>dram_utilization</p></td>
<td><p>The utilization level of the device memory relative to the peak utilization on a scale of 0 to 10</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-even"><td><p>dram_write_bytes</p></td>
<td><p>Total bytes written from L2 cache to DRAM. This is available for compute capability 5.0 and 5.2.</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-odd"><td><p>dram_write_throughput</p></td>
<td><p>Device memory write throughput. This is available for compute capability 5.0 and 5.2.</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-even"><td><p>dram_write_transactions</p></td>
<td><p>Device memory write transactions. This is available for compute capability 5.0 and 5.2.</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-odd"><td><p>ecc_throughput</p></td>
<td><p>ECC throughput from L2 to DRAM. This is available for compute capability 5.0 and 5.2.</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-even"><td><p>ecc_transactions</p></td>
<td><p>Number of ECC transactions between L2 and DRAM. This is available for compute capability 5.0 and 5.2.</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-odd"><td><p>eligible_warps_per_cycle</p></td>
<td><p>Average number of warps that are eligible to issue per active cycle</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>flop_count_dp</p></td>
<td><p>Number of double-precision floating-point operations executed by non-predicated threads (add, multiply, and multiply-accumulate). Each multiply-accumulate operation contributes 2 to the count.</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>flop_count_dp_add</p></td>
<td><p>Number of double-precision floating-point add operations executed by non-predicated threads.</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>flop_count_dp_fma</p></td>
<td><p>Number of double-precision floating-point multiply-accumulate operations executed by non-predicated threads. Each multiply-accumulate operation contributes 1 to the count.</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>flop_count_dp_mul</p></td>
<td><p>Number of double-precision floating-point multiply operations executed by non-predicated threads.</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>flop_count_hp</p></td>
<td><p>Number of half-precision floating-point operations executed by non-predicated threads (add, multiply and multiply-accumulate). Each multiply-accumulate operation contributes 2 to the count. This is available for compute capability 5.3.</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-odd"><td><p>flop_count_hp_add</p></td>
<td><p>Number of half-precision floating-point add operations executed by non-predicated threads. This is available for compute capability 5.3.</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-even"><td><p>flop_count_hp_fma</p></td>
<td><p>Number of half-precision floating-point multiply-accumulate operations executed by non-predicated threads. Each multiply-accumulate operation contributes 1 to the count. This is available for compute capability 5.3.</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-odd"><td><p>flop_count_hp_mul</p></td>
<td><p>Number of half-precision floating-point multiply operations executed by non-predicated threads. This is available for compute capability 5.3.</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-even"><td><p>flop_count_sp</p></td>
<td><p>Number of single-precision floating-point operations executed by non-predicated threads (add, multiply, and multiply-accumulate). Each multiply-accumulate operation contributes 2 to the count. The count does not include special operations.</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>flop_count_sp_add</p></td>
<td><p>Number of single-precision floating-point add operations executed by non-predicated threads.</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>flop_count_sp_fma</p></td>
<td><p>Number of single-precision floating-point multiply-accumulate operations executed by non-predicated threads. Each multiply-accumulate operation contributes 1 to the count.</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>flop_count_sp_mul</p></td>
<td><p>Number of single-precision floating-point multiply operations executed by non-predicated threads.</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>flop_count_sp_special</p></td>
<td><p>Number of single-precision floating-point special operations executed by non-predicated threads.</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>flop_dp_efficiency</p></td>
<td><p>Ratio of achieved to peak double-precision floating-point operations</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>flop_hp_efficiency</p></td>
<td><p>Ratio of achieved to peak half-precision floating-point operations. This is available for compute capability 5.3.</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-odd"><td><p>flop_sp_efficiency</p></td>
<td><p>Ratio of achieved to peak single-precision floating-point operations</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>gld_efficiency</p></td>
<td><p>Ratio of requested global memory load throughput to required global memory load throughput expressed as percentage.</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-odd"><td><p>gld_requested_throughput</p></td>
<td><p>Requested global memory load throughput</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>gld_throughput</p></td>
<td><p>Global memory load throughput</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-odd"><td><p>gld_transactions</p></td>
<td><p>Number of global memory load transactions</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-even"><td><p>gld_transactions_per_request</p></td>
<td><p>Average number of global memory load transactions performed for each global memory load.</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-odd"><td><p>global_atomic_requests</p></td>
<td><p>Total number of global atomic(Atom and Atom CAS) requests from Multiprocessor</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>global_hit_rate</p></td>
<td><p>Hit rate for global loads in unified l1/tex cache. Metric value maybe wrong if malloc is used in kernel.</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-odd"><td><p>global_load_requests</p></td>
<td><p>Total number of global load requests from Multiprocessor</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>global_reduction_requests</p></td>
<td><p>Total number of global reduction requests from Multiprocessor</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>global_store_requests</p></td>
<td><p>Total number of global store requests from Multiprocessor. This does not include atomic requests.</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>gst_efficiency</p></td>
<td><p>Ratio of requested global memory store throughput to required global memory store throughput expressed as percentage.</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-odd"><td><p>gst_requested_throughput</p></td>
<td><p>Requested global memory store throughput</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>gst_throughput</p></td>
<td><p>Global memory store throughput</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-odd"><td><p>gst_transactions</p></td>
<td><p>Number of global memory store transactions</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-even"><td><p>gst_transactions_per_request</p></td>
<td><p>Average number of global memory store transactions performed for each global memory store</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-odd"><td><p>half_precision_fu_utilization</p></td>
<td><p>The utilization level of the multiprocessor function units that execute 16 bit floating-point instructions and integer instructions on a scale of 0 to 10. This is available for compute capability 5.3.</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-even"><td><p>inst_bit_convert</p></td>
<td><p>Number of bit-conversion instructions executed by non-predicated threads</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>inst_compute_ld_st</p></td>
<td><p>Number of compute load/store instructions executed by non-predicated threads</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>inst_control</p></td>
<td><p>Number of control-flow instructions executed by non-predicated threads (jump, branch, etc.)</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>inst_executed</p></td>
<td><p>The number of instructions executed</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>inst_executed_global_atomics</p></td>
<td><p>Warp level instructions for global atom and atom cas</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>inst_executed_global_loads</p></td>
<td><p>Warp level instructions for global loads</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>inst_executed_global_reductions</p></td>
<td><p>Warp level instructions for global reductions</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>inst_executed_global_stores</p></td>
<td><p>Warp level instructions for global stores</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>inst_executed_local_loads</p></td>
<td><p>Warp level instructions for local loads</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>inst_executed_local_stores</p></td>
<td><p>Warp level instructions for local stores</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>inst_executed_shared_atomics</p></td>
<td><p>Warp level shared instructions for atom and atom CAS</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>inst_executed_shared_loads</p></td>
<td><p>Warp level instructions for shared loads</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>inst_executed_shared_stores</p></td>
<td><p>Warp level instructions for shared stores</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>inst_executed_surface_atomics</p></td>
<td><p>Warp level instructions for surface atom and atom cas</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>inst_executed_surface_loads</p></td>
<td><p>Warp level instructions for surface loads</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>inst_executed_surface_reductions</p></td>
<td><p>Warp level instructions for surface reductions</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>inst_executed_surface_stores</p></td>
<td><p>Warp level instructions for surface stores</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>inst_executed_tex_ops</p></td>
<td><p>Warp level instructions for texture</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>inst_fp_16</p></td>
<td><p>Number of half-precision floating-point instructions executed by non-predicated threads (arithmetic, compare, etc.) This is available for compute capability 5.3.</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-odd"><td><p>inst_fp_32</p></td>
<td><p>Number of single-precision floating-point instructions executed by non-predicated threads (arithmetic, compare, etc.)</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>inst_fp_64</p></td>
<td><p>Number of double-precision floating-point instructions executed by non-predicated threads (arithmetic, compare, etc.)</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>inst_integer</p></td>
<td><p>Number of integer instructions executed by non-predicated threads</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>inst_inter_thread_communication</p></td>
<td><p>Number of inter-thread communication instructions executed by non-predicated threads</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>inst_issued</p></td>
<td><p>The number of instructions issued</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>inst_misc</p></td>
<td><p>Number of miscellaneous instructions executed by non-predicated threads</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>inst_per_warp</p></td>
<td><p>Average number of instructions executed by each warp</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>inst_replay_overhead</p></td>
<td><p>Average number of replays for each instruction executed</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>ipc</p></td>
<td><p>Instructions executed per cycle</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>issue_slot_utilization</p></td>
<td><p>Percentage of issue slots that issued at least one instruction, averaged across all cycles</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>issue_slots</p></td>
<td><p>The number of issue slots used</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>issued_ipc</p></td>
<td><p>Instructions issued per cycle</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>l2_atomic_throughput</p></td>
<td><p>Memory read throughput seen at L2 cache for atomic and reduction requests</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>l2_atomic_transactions</p></td>
<td><p>Memory read transactions seen at L2 cache for atomic and reduction requests</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-odd"><td><p>l2_global_atomic_store_bytes</p></td>
<td><p>Bytes written to L2 from Unified cache for global atomics (ATOM and ATOM CAS)</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-even"><td><p>l2_global_load_bytes</p></td>
<td><p>Bytes read from L2 for misses in Unified Cache for global loads</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-odd"><td><p>l2_global_reduction_bytes</p></td>
<td><p>Bytes written to L2 from Unified cache for global reductions</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-even"><td><p>l2_local_global_store_bytes</p></td>
<td><p>Bytes written to L2 from Unified Cache for local and global stores. This does not include global atomics.</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-odd"><td><p>l2_local_load_bytes</p></td>
<td><p>Bytes read from L2 for misses in Unified Cache for local loads</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-even"><td><p>l2_read_throughput</p></td>
<td><p>Memory read throughput seen at L2 cache for all read requests</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-odd"><td><p>l2_read_transactions</p></td>
<td><p>Memory read transactions seen at L2 cache for all read requests</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-even"><td><p>l2_surface_atomic_store_bytes</p></td>
<td><p>Bytes transferred between Unified Cache and L2 for surface atomics (ATOM and ATOM CAS)</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-odd"><td><p>l2_surface_load_bytes</p></td>
<td><p>Bytes read from L2 for misses in Unified Cache for surface loads</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-even"><td><p>l2_surface_reduction_bytes</p></td>
<td><p>Bytes written to L2 from Unified Cache for surface reductions</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-odd"><td><p>l2_surface_store_bytes</p></td>
<td><p>Bytes written to L2 from Unified Cache for surface stores. This does not include surface atomics.</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-even"><td><p>l2_tex_hit_rate</p></td>
<td><p>Hit rate at L2 cache for all requests from texture cache</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-odd"><td><p>l2_tex_read_hit_rate</p></td>
<td><p>Hit rate at L2 cache for all read requests from texture cache. This is available for compute capability 5.0 and 5.2.</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-even"><td><p>l2_tex_read_throughput</p></td>
<td><p>Memory read throughput seen at L2 cache for read requests from the texture cache</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-odd"><td><p>l2_tex_read_transactions</p></td>
<td><p>Memory read transactions seen at L2 cache for read requests from the texture cache</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-even"><td><p>l2_tex_write_hit_rate</p></td>
<td><p>Hit Rate at L2 cache for all write requests from texture cache. This is available for compute capability 5.0 and 5.2.</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-odd"><td><p>l2_tex_write_throughput</p></td>
<td><p>Memory write throughput seen at L2 cache for write requests from the texture cache</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-even"><td><p>l2_tex_write_transactions</p></td>
<td><p>Memory write transactions seen at L2 cache for write requests from the texture cache</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-odd"><td><p>l2_utilization</p></td>
<td><p>The utilization level of the L2 cache relative to the peak utilization on a scale of 0 to 10</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-even"><td><p>l2_write_throughput</p></td>
<td><p>Memory write throughput seen at L2 cache for all write requests</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-odd"><td><p>l2_write_transactions</p></td>
<td><p>Memory write transactions seen at L2 cache for all write requests</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-even"><td><p>ldst_executed</p></td>
<td><p>Number of executed local, global, shared and texture memory load and store instructions</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>ldst_fu_utilization</p></td>
<td><p>The utilization level of the multiprocessor function units that execute shared load, shared store and constant load instructions on a scale of 0 to 10</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>ldst_issued</p></td>
<td><p>Number of issued local, global, shared and texture memory load and store instructions</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>local_hit_rate</p></td>
<td><p>Hit rate for local loads and stores</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-even"><td><p>local_load_requests</p></td>
<td><p>Total number of local load requests from Multiprocessor</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-odd"><td><p>local_load_throughput</p></td>
<td><p>Local memory load throughput</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-even"><td><p>local_load_transactions</p></td>
<td><p>Number of local memory load transactions</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-odd"><td><p>local_load_transactions_per_request</p></td>
<td><p>Average number of local memory load transactions performed for each local memory load</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-even"><td><p>local_memory_overhead</p></td>
<td><p>Ratio of local memory traffic to total memory traffic between the L1 and L2 caches expressed as percentage</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-odd"><td><p>local_store_requests</p></td>
<td><p>Total number of local store requests from Multiprocessor</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-even"><td><p>local_store_throughput</p></td>
<td><p>Local memory store throughput</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-odd"><td><p>local_store_transactions</p></td>
<td><p>Number of local memory store transactions</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-even"><td><p>local_store_transactions_per_request</p></td>
<td><p>Average number of local memory store transactions performed for each local memory store</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-odd"><td><p>pcie_total_data_received</p></td>
<td><p>Total data bytes received through PCIe</p></td>
<td><p>Device</p></td>
</tr>
<tr class="row-even"><td><p>pcie_total_data_transmitted</p></td>
<td><p>Total data bytes transmitted through PCIe</p></td>
<td><p>Device</p></td>
</tr>
<tr class="row-odd"><td><p>shared_efficiency</p></td>
<td><p>Ratio of requested shared memory throughput to required shared memory throughput expressed as percentage</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-even"><td><p>shared_load_throughput</p></td>
<td><p>Shared memory load throughput</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-odd"><td><p>shared_load_transactions</p></td>
<td><p>Number of shared memory load transactions</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-even"><td><p>shared_load_transactions_per_request</p></td>
<td><p>Average number of shared memory load transactions performed for each shared memory load</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-odd"><td><p>shared_store_throughput</p></td>
<td><p>Shared memory store throughput</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-even"><td><p>shared_store_transactions</p></td>
<td><p>Number of shared memory store transactions</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-odd"><td><p>shared_store_transactions_per_request</p></td>
<td><p>Average number of shared memory store transactions performed for each shared memory store</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-even"><td><p>shared_utilization</p></td>
<td><p>The utilization level of the shared memory relative to peak utilization on a scale of 0 to 10</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-odd"><td><p>single_precision_fu_utilization</p></td>
<td><p>The utilization level of the multiprocessor function units that execute single-precision floating-point instructions and integer instructions on a scale of 0 to 10</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>sm_efficiency</p></td>
<td><p>The percentage of time at least one warp is active on a specific multiprocessor</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-odd"><td><p>special_fu_utilization</p></td>
<td><p>The utilization level of the multiprocessor function units that execute sin, cos, ex2, popc, flo, and similar instructions on a scale of 0 to 10</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>stall_constant_memory_dependency</p></td>
<td><p>Percentage of stalls occurring because of immediate constant cache miss</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>stall_exec_dependency</p></td>
<td><p>Percentage of stalls occurring because an input required by the instruction is not yet available</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>stall_inst_fetch</p></td>
<td><p>Percentage of stalls occurring because the next assembly instruction has not yet been fetched</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>stall_memory_dependency</p></td>
<td><p>Percentage of stalls occurring because a memory operation cannot be performed due to the required resources not being available or fully utilized, or because too many requests of a given type are outstanding</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>stall_memory_throttle</p></td>
<td><p>Percentage of stalls occurring because of memory throttle</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>stall_not_selected</p></td>
<td><p>Percentage of stalls occurring because warp was not selected</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>stall_other</p></td>
<td><p>Percentage of stalls occurring due to miscellaneous reasons</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>stall_pipe_busy</p></td>
<td><p>Percentage of stalls occurring because a compute operation cannot be performed because the compute pipeline is busy</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>stall_sync</p></td>
<td><p>Percentage of stalls occurring because the warp is blocked at a __syncthreads() call</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>stall_texture</p></td>
<td><p>Percentage of stalls occurring because the texture sub-system is fully utilized or has too many outstanding requests</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>surface_atomic_requests</p></td>
<td><p>Total number of surface atomic(Atom and Atom CAS) requests from Multiprocessor</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>surface_load_requests</p></td>
<td><p>Total number of surface load requests from Multiprocessor</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>surface_reduction_requests</p></td>
<td><p>Total number of surface reduction requests from Multiprocessor</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>surface_store_requests</p></td>
<td><p>Total number of surface store requests from Multiprocessor</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>sysmem_read_bytes</p></td>
<td><p>Number of bytes read from system memory</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-odd"><td><p>sysmem_read_throughput</p></td>
<td><p>System memory read throughput</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-even"><td><p>sysmem_read_transactions</p></td>
<td><p>Number of system memory read transactions</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-odd"><td><p>sysmem_read_utilization</p></td>
<td><p>The read utilization level of the system memory relative to the peak utilization on a scale of 0 to 10. This is available for compute capability 5.0 and 5.2.</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>sysmem_utilization</p></td>
<td><p>The utilization level of the system memory relative to the peak utilization on a scale of 0 to 10. This is available for compute capability 5.0 and 5.2.</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-odd"><td><p>sysmem_write_bytes</p></td>
<td><p>Number of bytes written to system memory</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-even"><td><p>sysmem_write_throughput</p></td>
<td><p>System memory write throughput</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-odd"><td><p>sysmem_write_transactions</p></td>
<td><p>Number of system memory write transactions</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-even"><td><p>sysmem_write_utilization</p></td>
<td><p>The write utilization level of the system memory relative to the peak utilization on a scale of 0 to 10. This is available for compute capability 5.0 and 5.2.</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-odd"><td><p>tex_cache_hit_rate</p></td>
<td><p>Unified cache hit rate</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-even"><td><p>tex_cache_throughput</p></td>
<td><p>Unified cache throughput</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-odd"><td><p>tex_cache_transactions</p></td>
<td><p>Unified cache read transactions</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-even"><td><p>tex_fu_utilization</p></td>
<td><p>The utilization level of the multiprocessor function units that execute global, local and texture memory instructions on a scale of 0 to 10</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>tex_utilization</p></td>
<td><p>The utilization level of the unified cache relative to the peak utilization on a scale of 0 to 10</p></td>
<td><p>Multi-context<sup>*</sup></p></td>
</tr>
<tr class="row-even"><td><p>texture_load_requests</p></td>
<td><p>Total number of texture Load requests from Multiprocessor</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>warp_execution_efficiency</p></td>
<td><p>Ratio of the average active threads per warp to the maximum number of threads per warp supported on a multiprocessor</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>warp_nonpred_execution_efficiency</p></td>
<td><p>Ratio of the average active threads per warp executing non-predicated instructions to the maximum number of threads per warp supported on a multiprocessor</p></td>
<td><p>Multi-context</p></td>
</tr>
</tbody>
</table>
<p><strong>* The “Multi-context” scope for this metric is supported only for devices with compute capability 5.0 and 5.2.</strong></p>
</section>
<section id="metrics-for-capability-6-x">
<span id="metric-metrics-reference-6x"></span><h4><span class="section-number">2.6.1.2. </span>Metrics for Capability 6.x<a class="headerlink" href="#metrics-for-capability-6-x" title="Permalink to this headline"></a></h4>
<p>Devices with compute capability 6.x implement the metrics shown in the following table.</p>
<table class="table-no-stripes docutils align-default" id="id11">
<caption><span class="caption-text">Table 2. Capability 6.x Metrics</span><a class="headerlink" href="#id11" title="Permalink to this table"></a></caption>
<colgroup>
<col style="width: 13%" />
<col style="width: 82%" />
<col style="width: 5%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Metric Name</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Scope</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>achieved_occupancy</p></td>
<td><p>Ratio of the average active warps per active cycle to the maximum number of warps supported on a multiprocessor</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>atomic_transactions</p></td>
<td><p>Global memory atomic and reduction transactions</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>atomic_transactions_per_request</p></td>
<td><p>Average number of global memory atomic and reduction transactions performed for each atomic and reduction instruction</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>branch_efficiency</p></td>
<td><p>Ratio of non-divergent branches to total branches expressed as percentage</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>cf_executed</p></td>
<td><p>Number of executed control-flow instructions</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>cf_fu_utilization</p></td>
<td><p>The utilization level of the multiprocessor function units that execute control-flow instructions on a scale of 0 to 10</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>cf_issued</p></td>
<td><p>Number of issued control-flow instructions</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>double_precision_fu_utilization</p></td>
<td><p>The utilization level of the multiprocessor function units that execute double-precision floating-point instructions on a scale of 0 to 10</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>dram_read_bytes</p></td>
<td><p>Total bytes read from DRAM to L2 cache</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>dram_read_throughput</p></td>
<td><p>Device memory read throughput. This is available for compute capability 6.0 and 6.1.</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>dram_read_transactions</p></td>
<td><p>Device memory read transactions. This is available for compute capability 6.0 and 6.1.</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>dram_utilization</p></td>
<td><p>The utilization level of the device memory relative to the peak utilization on a scale of 0 to 10</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>dram_write_bytes</p></td>
<td><p>Total bytes written from L2 cache to DRAM</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>dram_write_throughput</p></td>
<td><p>Device memory write throughput. This is available for compute capability 6.0 and 6.1.</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>dram_write_transactions</p></td>
<td><p>Device memory write transactions. This is available for compute capability 6.0 and 6.1.</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>ecc_throughput</p></td>
<td><p>ECC throughput from L2 to DRAM. This is available for compute capability 6.1.</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>ecc_transactions</p></td>
<td><p>Number of ECC transactions between L2 and DRAM. This is available for compute capability 6.1.</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>eligible_warps_per_cycle</p></td>
<td><p>Average number of warps that are eligible to issue per active cycle</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>flop_count_dp</p></td>
<td><p>Number of double-precision floating-point operations executed by non-predicated threads (add, multiply, and multiply-accumulate). Each multiply-accumulate operation contributes 2 to the count.</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>flop_count_dp_add</p></td>
<td><p>Number of double-precision floating-point add operations executed by non-predicated threads.</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>flop_count_dp_fma</p></td>
<td><p>Number of double-precision floating-point multiply-accumulate operations executed by non-predicated threads. Each multiply-accumulate operation contributes 1 to the count.</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>flop_count_dp_mul</p></td>
<td><p>Number of double-precision floating-point multiply operations executed by non-predicated threads.</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>flop_count_hp</p></td>
<td><p>Number of half-precision floating-point operations executed by non-predicated threads (add, multiply, and multiply-accumulate). Each multiply-accumulate operation contributes 2 to the count.</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>flop_count_hp_add</p></td>
<td><p>Number of half-precision floating-point add operations executed by non-predicated threads.</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>flop_count_hp_fma</p></td>
<td><p>Number of half-precision floating-point multiply-accumulate operations executed by non-predicated threads. Each multiply-accumulate operation contributes 1 to the count.</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>flop_count_hp_mul</p></td>
<td><p>Number of half-precision floating-point multiply operations executed by non-predicated threads.</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>flop_count_sp</p></td>
<td><p>Number of single-precision floating-point operations executed by non-predicated threads (add, multiply, and multiply-accumulate). Each multiply-accumulate operation contributes 2 to the count. The count does not include special operations.</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>flop_count_sp_add</p></td>
<td><p>Number of single-precision floating-point add operations executed by non-predicated threads.</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>flop_count_sp_fma</p></td>
<td><p>Number of single-precision floating-point multiply-accumulate operations executed by non-predicated threads. Each multiply-accumulate operation contributes 1 to the count.</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>flop_count_sp_mul</p></td>
<td><p>Number of single-precision floating-point multiply operations executed by non-predicated threads.</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>flop_count_sp_special</p></td>
<td><p>Number of single-precision floating-point special operations executed by non-predicated threads.</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>flop_dp_efficiency</p></td>
<td><p>Ratio of achieved to peak double-precision floating-point operations</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>flop_hp_efficiency</p></td>
<td><p>Ratio of achieved to peak half-precision floating-point operations</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>flop_sp_efficiency</p></td>
<td><p>Ratio of achieved to peak single-precision floating-point operations</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>gld_efficiency</p></td>
<td><p>Ratio of requested global memory load throughput to required global memory load throughput expressed as percentage.</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>gld_requested_throughput</p></td>
<td><p>Requested global memory load throughput</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>gld_throughput</p></td>
<td><p>Global memory load throughput</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>gld_transactions</p></td>
<td><p>Number of global memory load transactions</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>gld_transactions_per_request</p></td>
<td><p>Average number of global memory load transactions performed for each global memory load.</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>global_atomic_requests</p></td>
<td><p>Total number of global atomic(Atom and Atom CAS) requests from Multiprocessor</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>global_hit_rate</p></td>
<td><p>Hit rate for global loads in unified l1/tex cache. Metric value maybe wrong if malloc is used in kernel.</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>global_load_requests</p></td>
<td><p>Total number of global load requests from Multiprocessor</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>global_reduction_requests</p></td>
<td><p>Total number of global reduction requests from Multiprocessor</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>global_store_requests</p></td>
<td><p>Total number of global store requests from Multiprocessor. This does not include atomic requests.</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>gst_efficiency</p></td>
<td><p>Ratio of requested global memory store throughput to required global memory store throughput expressed as percentage.</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>gst_requested_throughput</p></td>
<td><p>Requested global memory store throughput</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>gst_throughput</p></td>
<td><p>Global memory store throughput</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>gst_transactions</p></td>
<td><p>Number of global memory store transactions</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>gst_transactions_per_request</p></td>
<td><p>Average number of global memory store transactions performed for each global memory store</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>half_precision_fu_utilization</p></td>
<td><p>The utilization level of the multiprocessor function units that execute 16 bit floating-point instructions on a scale of 0 to 10</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>inst_bit_convert</p></td>
<td><p>Number of bit-conversion instructions executed by non-predicated threads</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>inst_compute_ld_st</p></td>
<td><p>Number of compute load/store instructions executed by non-predicated threads</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>inst_control</p></td>
<td><p>Number of control-flow instructions executed by non-predicated threads (jump, branch, etc.)</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>inst_executed</p></td>
<td><p>The number of instructions executed</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>inst_executed_global_atomics</p></td>
<td><p>Warp level instructions for global atom and atom cas</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>inst_executed_global_loads</p></td>
<td><p>Warp level instructions for global loads</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>inst_executed_global_reductions</p></td>
<td><p>Warp level instructions for global reductions</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>inst_executed_global_stores</p></td>
<td><p>Warp level instructions for global stores</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>inst_executed_local_loads</p></td>
<td><p>Warp level instructions for local loads</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>inst_executed_local_stores</p></td>
<td><p>Warp level instructions for local stores</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>inst_executed_shared_atomics</p></td>
<td><p>Warp level shared instructions for atom and atom CAS</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>inst_executed_shared_loads</p></td>
<td><p>Warp level instructions for shared loads</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>inst_executed_shared_stores</p></td>
<td><p>Warp level instructions for shared stores</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>inst_executed_surface_atomics</p></td>
<td><p>Warp level instructions for surface atom and atom cas</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>inst_executed_surface_loads</p></td>
<td><p>Warp level instructions for surface loads</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>inst_executed_surface_reductions</p></td>
<td><p>Warp level instructions for surface reductions</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>inst_executed_surface_stores</p></td>
<td><p>Warp level instructions for surface stores</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>inst_executed_tex_ops</p></td>
<td><p>Warp level instructions for texture</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>inst_fp_16</p></td>
<td><p>Number of half-precision floating-point instructions executed by non-predicated threads (arithmetic, compare, etc.)</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>inst_fp_32</p></td>
<td><p>Number of single-precision floating-point instructions executed by non-predicated threads (arithmetic, compare, etc.)</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>inst_fp_64</p></td>
<td><p>Number of double-precision floating-point instructions executed by non-predicated threads (arithmetic, compare, etc.)</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>inst_integer</p></td>
<td><p>Number of integer instructions executed by non-predicated threads</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>inst_inter_thread_communication</p></td>
<td><p>Number of inter-thread communication instructions executed by non-predicated threads</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>inst_issued</p></td>
<td><p>The number of instructions issued</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>inst_misc</p></td>
<td><p>Number of miscellaneous instructions executed by non-predicated threads</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>inst_per_warp</p></td>
<td><p>Average number of instructions executed by each warp</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>inst_replay_overhead</p></td>
<td><p>Average number of replays for each instruction executed</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>ipc</p></td>
<td><p>Instructions executed per cycle</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>issue_slot_utilization</p></td>
<td><p>Percentage of issue slots that issued at least one instruction, averaged across all cycles</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>issue_slots</p></td>
<td><p>The number of issue slots used</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>issued_ipc</p></td>
<td><p>Instructions issued per cycle</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>l2_atomic_throughput</p></td>
<td><p>Memory read throughput seen at L2 cache for atomic and reduction requests</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>l2_atomic_transactions</p></td>
<td><p>Memory read transactions seen at L2 cache for atomic and reduction requests</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>l2_global_atomic_store_bytes</p></td>
<td><p>Bytes written to L2 from Unified cache for global atomics (ATOM and ATOM CAS)</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>l2_global_load_bytes</p></td>
<td><p>Bytes read from L2 for misses in Unified Cache for global loads</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>l2_global_reduction_bytes</p></td>
<td><p>Bytes written to L2 from Unified cache for global reductions</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>l2_local_global_store_bytes</p></td>
<td><p>Bytes written to L2 from Unified Cache for local and global stores. This does not include global atomics.</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>l2_local_load_bytes</p></td>
<td><p>Bytes read from L2 for misses in Unified Cache for local loads</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>l2_read_throughput</p></td>
<td><p>Memory read throughput seen at L2 cache for all read requests</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>l2_read_transactions</p></td>
<td><p>Memory read transactions seen at L2 cache for all read requests</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>l2_surface_atomic_store_bytes</p></td>
<td><p>Bytes transferred between Unified Cache and L2 for surface atomics (ATOM and ATOM CAS)</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>l2_surface_load_bytes</p></td>
<td><p>Bytes read from L2 for misses in Unified Cache for surface loads</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>l2_surface_reduction_bytes</p></td>
<td><p>Bytes written to L2 from Unified Cache for surface reductions</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>l2_surface_store_bytes</p></td>
<td><p>Bytes written to L2 from Unified Cache for surface stores. This does not include surface atomics.</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>l2_tex_hit_rate</p></td>
<td><p>Hit rate at L2 cache for all requests from texture cache</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>l2_tex_read_hit_rate</p></td>
<td><p>Hit rate at L2 cache for all read requests from texture cache. This is available for compute capability 6.0 and 6.1.</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>l2_tex_read_throughput</p></td>
<td><p>Memory read throughput seen at L2 cache for read requests from the texture cache</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>l2_tex_read_transactions</p></td>
<td><p>Memory read transactions seen at L2 cache for read requests from the texture cache</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>l2_tex_write_hit_rate</p></td>
<td><p>Hit Rate at L2 cache for all write requests from texture cache. This is available for compute capability 6.0 and 6.1.</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>l2_tex_write_throughput</p></td>
<td><p>Memory write throughput seen at L2 cache for write requests from the texture cache</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>l2_tex_write_transactions</p></td>
<td><p>Memory write transactions seen at L2 cache for write requests from the texture cache</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>l2_utilization</p></td>
<td><p>The utilization level of the L2 cache relative to the peak utilization on a scale of 0 to 10</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>l2_write_throughput</p></td>
<td><p>Memory write throughput seen at L2 cache for all write requests</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>l2_write_transactions</p></td>
<td><p>Memory write transactions seen at L2 cache for all write requests</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>ldst_executed</p></td>
<td><p>Number of executed local, global, shared and texture memory load and store instructions</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>ldst_fu_utilization</p></td>
<td><p>The utilization level of the multiprocessor function units that execute shared load, shared store and constant load instructions on a scale of 0 to 10</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>ldst_issued</p></td>
<td><p>Number of issued local, global, shared and texture memory load and store instructions</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>local_hit_rate</p></td>
<td><p>Hit rate for local loads and stores</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>local_load_requests</p></td>
<td><p>Total number of local load requests from Multiprocessor</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>local_load_throughput</p></td>
<td><p>Local memory load throughput</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>local_load_transactions</p></td>
<td><p>Number of local memory load transactions</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>local_load_transactions_per_request</p></td>
<td><p>Average number of local memory load transactions performed for each local memory load</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>local_memory_overhead</p></td>
<td><p>Ratio of local memory traffic to total memory traffic between the L1 and L2 caches expressed as percentage</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>local_store_requests</p></td>
<td><p>Total number of local store requests from Multiprocessor</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>local_store_throughput</p></td>
<td><p>Local memory store throughput</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>local_store_transactions</p></td>
<td><p>Number of local memory store transactions</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>local_store_transactions_per_request</p></td>
<td><p>Average number of local memory store transactions performed for each local memory store</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>nvlink_overhead_data_received</p></td>
<td><p>Ratio of overhead data to the total data, received through NVLink. This is available for compute capability 6.0.</p></td>
<td><p>Device</p></td>
</tr>
<tr class="row-even"><td><p>nvlink_overhead_data_transmitted</p></td>
<td><p>Ratio of overhead data to the total data, transmitted through NVLink. This is available for compute capability 6.0.</p></td>
<td><p>Device</p></td>
</tr>
<tr class="row-odd"><td><p>nvlink_receive_throughput</p></td>
<td><p>Number of bytes received per second through NVLinks. This is available for compute capability 6.0.</p></td>
<td><p>Device</p></td>
</tr>
<tr class="row-even"><td><p>nvlink_total_data_received</p></td>
<td><p>Total data bytes received through NVLinks including headers. This is available for compute capability 6.0.</p></td>
<td><p>Device</p></td>
</tr>
<tr class="row-odd"><td><p>nvlink_total_data_transmitted</p></td>
<td><p>Total data bytes transmitted through NVLinks including headers. This is available for compute capability 6.0.</p></td>
<td><p>Device</p></td>
</tr>
<tr class="row-even"><td><p>nvlink_total_nratom_data_transmitted</p></td>
<td><p>Total non-reduction atomic data bytes transmitted through NVLinks. This is available for compute capability 6.0.</p></td>
<td><p>Device</p></td>
</tr>
<tr class="row-odd"><td><p>nvlink_total_ratom_data_transmitted</p></td>
<td><p>Total reduction atomic data bytes transmitted through NVLinks This is available for compute capability 6.0.</p></td>
<td><p>Device</p></td>
</tr>
<tr class="row-even"><td><p>nvlink_total_response_data_received</p></td>
<td><p>Total response data bytes received through NVLink, response data includes data for read requests and result of non-reduction atomic requests. This is available for compute capability 6.0.</p></td>
<td><p>Device</p></td>
</tr>
<tr class="row-odd"><td><p>nvlink_total_write_data_transmitted</p></td>
<td><p>Total write data bytes transmitted through NVLinks. This is available for compute capability 6.0.</p></td>
<td><p>Device</p></td>
</tr>
<tr class="row-even"><td><p>nvlink_transmit_throughput</p></td>
<td><p>Number of Bytes Transmitted per second through NVLinks. This is available for compute capability 6.0.</p></td>
<td><p>Device</p></td>
</tr>
<tr class="row-odd"><td><p>nvlink_user_data_received</p></td>
<td><p>User data bytes received through NVLinks, doesn’t include headers. This is available for compute capability 6.0.</p></td>
<td><p>Device</p></td>
</tr>
<tr class="row-even"><td><p>nvlink_user_data_transmitted</p></td>
<td><p>User data bytes transmitted through NVLinks, doesn’t include headers. This is available for compute capability 6.0.</p></td>
<td><p>Device</p></td>
</tr>
<tr class="row-odd"><td><p>nvlink_user_nratom_data_transmitted</p></td>
<td><p>Total non-reduction atomic user data bytes transmitted through NVLinks. This is available for compute capability 6.0.</p></td>
<td><p>Device</p></td>
</tr>
<tr class="row-even"><td><p>nvlink_user_ratom_data_transmitted</p></td>
<td><p>Total reduction atomic user data bytes transmitted through NVLinks. This is available for compute capability 6.0.</p></td>
<td><p>Device</p></td>
</tr>
<tr class="row-odd"><td><p>nvlink_user_response_data_received</p></td>
<td><p>Total user response data bytes received through NVLink, response data includes data for read requests and result of non-reduction atomic requests. This is available for compute capability 6.0.</p></td>
<td><p>Device</p></td>
</tr>
<tr class="row-even"><td><p>nvlink_user_write_data_transmitted</p></td>
<td><p>User write data bytes transmitted through NVLinks. This is available for compute capability 6.0.</p></td>
<td><p>Device</p></td>
</tr>
<tr class="row-odd"><td><p>pcie_total_data_received</p></td>
<td><p>Total data bytes received through PCIe</p></td>
<td><p>Device</p></td>
</tr>
<tr class="row-even"><td><p>pcie_total_data_transmitted</p></td>
<td><p>Total data bytes transmitted through PCIe</p></td>
<td><p>Device</p></td>
</tr>
<tr class="row-odd"><td><p>shared_efficiency</p></td>
<td><p>Ratio of requested shared memory throughput to required shared memory throughput expressed as percentage</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>shared_load_throughput</p></td>
<td><p>Shared memory load throughput</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>shared_load_transactions</p></td>
<td><p>Number of shared memory load transactions</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>shared_load_transactions_per_request</p></td>
<td><p>Average number of shared memory load transactions performed for each shared memory load</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>shared_store_throughput</p></td>
<td><p>Shared memory store throughput</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>shared_store_transactions</p></td>
<td><p>Number of shared memory store transactions</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>shared_store_transactions_per_request</p></td>
<td><p>Average number of shared memory store transactions performed for each shared memory store</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>shared_utilization</p></td>
<td><p>The utilization level of the shared memory relative to peak utilization on a scale of 0 to 10</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>single_precision_fu_utilization</p></td>
<td><p>The utilization level of the multiprocessor function units that execute single-precision floating-point instructions and integer instructions on a scale of 0 to 10</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>sm_efficiency</p></td>
<td><p>The percentage of time at least one warp is active on a specific multiprocessor</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>special_fu_utilization</p></td>
<td><p>The utilization level of the multiprocessor function units that execute sin, cos, ex2, popc, flo, and similar instructions on a scale of 0 to 10</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>stall_constant_memory_dependency</p></td>
<td><p>Percentage of stalls occurring because of immediate constant cache miss</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>stall_exec_dependency</p></td>
<td><p>Percentage of stalls occurring because an input required by the instruction is not yet available</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>stall_inst_fetch</p></td>
<td><p>Percentage of stalls occurring because the next assembly instruction has not yet been fetched</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>stall_memory_dependency</p></td>
<td><p>Percentage of stalls occurring because a memory operation cannot be performed due to the required resources not being available or fully utilized, or because too many requests of a given type are outstanding</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>stall_memory_throttle</p></td>
<td><p>Percentage of stalls occurring because of memory throttle</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>stall_not_selected</p></td>
<td><p>Percentage of stalls occurring because warp was not selected</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>stall_other</p></td>
<td><p>Percentage of stalls occurring due to miscellaneous reasons</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>stall_pipe_busy</p></td>
<td><p>Percentage of stalls occurring because a compute operation cannot be performed because the compute pipeline is busy</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>stall_sync</p></td>
<td><p>Percentage of stalls occurring because the warp is blocked at a __syncthreads() call</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>stall_texture</p></td>
<td><p>Percentage of stalls occurring because the texture sub-system is fully utilized or has too many outstanding requests</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>surface_atomic_requests</p></td>
<td><p>Total number of surface atomic(Atom and Atom CAS) requests from Multiprocessor</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>surface_load_requests</p></td>
<td><p>Total number of surface load requests from Multiprocessor</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>surface_reduction_requests</p></td>
<td><p>Total number of surface reduction requests from Multiprocessor</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>surface_store_requests</p></td>
<td><p>Total number of surface store requests from Multiprocessor</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>sysmem_read_bytes</p></td>
<td><p>Number of bytes read from system memory</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>sysmem_read_throughput</p></td>
<td><p>System memory read throughput</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>sysmem_read_transactions</p></td>
<td><p>Number of system memory read transactions</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>sysmem_read_utilization</p></td>
<td><p>The read utilization level of the system memory relative to the peak utilization on a scale of 0 to 10. This is available for compute capability 6.0 and 6.1.</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>sysmem_utilization</p></td>
<td><p>The utilization level of the system memory relative to the peak utilization on a scale of 0 to 10. This is available for compute capability 6.0 and 6.1.</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>sysmem_write_bytes</p></td>
<td><p>Number of bytes written to system memory</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>sysmem_write_throughput</p></td>
<td><p>System memory write throughput</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>sysmem_write_transactions</p></td>
<td><p>Number of system memory write transactions</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>sysmem_write_utilization</p></td>
<td><p>The write utilization level of the system memory relative to the peak utilization on a scale of 0 to 10. This is available for compute capability 6.0 and 6.1.</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>tex_cache_hit_rate</p></td>
<td><p>Unified cache hit rate</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>tex_cache_throughput</p></td>
<td><p>Unified cache throughput</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>tex_cache_transactions</p></td>
<td><p>Unified cache read transactions</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>tex_fu_utilization</p></td>
<td><p>The utilization level of the multiprocessor function units that execute global, local and texture memory instructions on a scale of 0 to 10</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>tex_utilization</p></td>
<td><p>The utilization level of the unified cache relative to the peak utilization on a scale of 0 to 10</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>texture_load_requests</p></td>
<td><p>Total number of texture Load requests from Multiprocessor</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>unique_warps_launched</p></td>
<td><p>Number of warps launched. Value is unaffected by compute preemption.</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>warp_execution_efficiency</p></td>
<td><p>Ratio of the average active threads per warp to the maximum number of threads per warp supported on a multiprocessor</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>warp_nonpred_execution_efficiency</p></td>
<td><p>Ratio of the average active threads per warp executing non-predicated instructions to the maximum number of threads per warp supported on a multiprocessor</p></td>
<td><p>Multi-context</p></td>
</tr>
</tbody>
</table>
</section>
<section id="metrics-for-capability-7-0">
<span id="metric-metrics-reference-7x"></span><h4><span class="section-number">2.6.1.3. </span>Metrics for Capability 7.0<a class="headerlink" href="#metrics-for-capability-7-0" title="Permalink to this headline"></a></h4>
<p>Devices with compute capability 7.0 implement the metrics shown in the following table.</p>
<table class="table-no-stripes docutils align-default" id="id12">
<caption><span class="caption-text">Table 3. Capability 7.x (7.0 and 7.2) Metrics</span><a class="headerlink" href="#id12" title="Permalink to this table"></a></caption>
<colgroup>
<col style="width: 13%" />
<col style="width: 82%" />
<col style="width: 5%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Metric Name</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Scope</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>achieved_occupancy</p></td>
<td><p>Ratio of the average active warps per active cycle to the maximum number of warps supported on a multiprocessor</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>atomic_transactions</p></td>
<td><p>Global memory atomic and reduction transactions</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>atomic_transactions_per_request</p></td>
<td><p>Average number of global memory atomic and reduction transactions performed for each atomic and reduction instruction</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>branch_efficiency</p></td>
<td><p>Ratio of branch instruction to sum of branch and divergent branch instruction</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>cf_executed</p></td>
<td><p>Number of executed control-flow instructions</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>cf_fu_utilization</p></td>
<td><p>The utilization level of the multiprocessor function units that execute control-flow instructions on a scale of 0 to 10</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>cf_issued</p></td>
<td><p>Number of issued control-flow instructions</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>double_precision_fu_utilization</p></td>
<td><p>The utilization level of the multiprocessor function units that execute double-precision floating-point instructions on a scale of 0 to 10</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>dram_read_bytes</p></td>
<td><p>Total bytes read from DRAM to L2 cache</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>dram_read_throughput</p></td>
<td><p>Device memory read throughput</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>dram_read_transactions</p></td>
<td><p>Device memory read transactions</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>dram_utilization</p></td>
<td><p>The utilization level of the device memory relative to the peak utilization on a scale of 0 to 10</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>dram_write_bytes</p></td>
<td><p>Total bytes written from L2 cache to DRAM</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>dram_write_throughput</p></td>
<td><p>Device memory write throughput</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>dram_write_transactions</p></td>
<td><p>Device memory write transactions</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>eligible_warps_per_cycle</p></td>
<td><p>Average number of warps that are eligible to issue per active cycle</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>flop_count_dp</p></td>
<td><p>Number of double-precision floating-point operations executed by non-predicated threads (add, multiply, and multiply-accumulate). Each multiply-accumulate operation contributes 2 to the count.</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>flop_count_dp_add</p></td>
<td><p>Number of double-precision floating-point add operations executed by non-predicated threads.</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>flop_count_dp_fma</p></td>
<td><p>Number of double-precision floating-point multiply-accumulate operations executed by non-predicated threads. Each multiply-accumulate operation contributes 1 to the count.</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>flop_count_dp_mul</p></td>
<td><p>Number of double-precision floating-point multiply operations executed by non-predicated threads.</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>flop_count_hp</p></td>
<td><p>Number of half-precision floating-point operations executed by non-predicated threads (add, multiply, and multiply-accumulate). Each multiply-accumulate contributes 2 or 4 to the count based on the number of inputs.</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>flop_count_hp_add</p></td>
<td><p>Number of half-precision floating-point add operations executed by non-predicated threads.</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>flop_count_hp_fma</p></td>
<td><p>Number of half-precision floating-point multiply-accumulate operations executed by non-predicated threads. Each multiply-accumulate contributes 2 or 4 to the count based on the number of inputs.</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>flop_count_hp_mul</p></td>
<td><p>Number of half-precision floating-point multiply operations executed by non-predicated threads.</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>flop_count_sp</p></td>
<td><p>Number of single-precision floating-point operations executed by non-predicated threads (add, multiply, and multiply-accumulate). Each multiply-accumulate operation contributes 2 to the count. The count does not include special operations.</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>flop_count_sp_add</p></td>
<td><p>Number of single-precision floating-point add operations executed by non-predicated threads.</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>flop_count_sp_fma</p></td>
<td><p>Number of single-precision floating-point multiply-accumulate operations executed by non-predicated threads. Each multiply-accumulate operation contributes 1 to the count.</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>flop_count_sp_mul</p></td>
<td><p>Number of single-precision floating-point multiply operations executed by non-predicated threads.</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>flop_count_sp_special</p></td>
<td><p>Number of single-precision floating-point special operations executed by non-predicated threads.</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>flop_dp_efficiency</p></td>
<td><p>Ratio of achieved to peak double-precision floating-point operations</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>flop_hp_efficiency</p></td>
<td><p>Ratio of achieved to peak half-precision floating-point operations</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>flop_sp_efficiency</p></td>
<td><p>Ratio of achieved to peak single-precision floating-point operations</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>gld_efficiency</p></td>
<td><p>Ratio of requested global memory load throughput to required global memory load throughput expressed as percentage.</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>gld_requested_throughput</p></td>
<td><p>Requested global memory load throughput</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>gld_throughput</p></td>
<td><p>Global memory load throughput</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>gld_transactions</p></td>
<td><p>Number of global memory load transactions</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>gld_transactions_per_request</p></td>
<td><p>Average number of global memory load transactions performed for each global memory load.</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>global_atomic_requests</p></td>
<td><p>Total number of global atomic(Atom and Atom CAS) requests from Multiprocessor</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>global_hit_rate</p></td>
<td><p>Hit rate for global load and store in unified l1/tex cache</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>global_load_requests</p></td>
<td><p>Total number of global load requests from Multiprocessor</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>global_reduction_requests</p></td>
<td><p>Total number of global reduction requests from Multiprocessor</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>global_store_requests</p></td>
<td><p>Total number of global store requests from Multiprocessor. This does not include atomic requests.</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>gst_efficiency</p></td>
<td><p>Ratio of requested global memory store throughput to required global memory store throughput expressed as percentage.</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>gst_requested_throughput</p></td>
<td><p>Requested global memory store throughput</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>gst_throughput</p></td>
<td><p>Global memory store throughput</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>gst_transactions</p></td>
<td><p>Number of global memory store transactions</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>gst_transactions_per_request</p></td>
<td><p>Average number of global memory store transactions performed for each global memory store</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>half_precision_fu_utilization</p></td>
<td><p>The utilization level of the multiprocessor function units that execute 16 bit floating-point instructions on a scale of 0 to 10. Note that this doesn’t specify the utilization level of tensor core unit</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>inst_bit_convert</p></td>
<td><p>Number of bit-conversion instructions executed by non-predicated threads</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>inst_compute_ld_st</p></td>
<td><p>Number of compute load/store instructions executed by non-predicated threads</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>inst_control</p></td>
<td><p>Number of control-flow instructions executed by non-predicated threads (jump, branch, etc.)</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>inst_executed</p></td>
<td><p>The number of instructions executed</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>inst_executed_global_atomics</p></td>
<td><p>Warp level instructions for global atom and atom cas</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>inst_executed_global_loads</p></td>
<td><p>Warp level instructions for global loads</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>inst_executed_global_reductions</p></td>
<td><p>Warp level instructions for global reductions</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>inst_executed_global_stores</p></td>
<td><p>Warp level instructions for global stores</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>inst_executed_local_loads</p></td>
<td><p>Warp level instructions for local loads</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>inst_executed_local_stores</p></td>
<td><p>Warp level instructions for local stores</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>inst_executed_shared_atomics</p></td>
<td><p>Warp level shared instructions for atom and atom CAS</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>inst_executed_shared_loads</p></td>
<td><p>Warp level instructions for shared loads</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>inst_executed_shared_stores</p></td>
<td><p>Warp level instructions for shared stores</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>inst_executed_surface_atomics</p></td>
<td><p>Warp level instructions for surface atom and atom cas</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>inst_executed_surface_loads</p></td>
<td><p>Warp level instructions for surface loads</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>inst_executed_surface_reductions</p></td>
<td><p>Warp level instructions for surface reductions</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>inst_executed_surface_stores</p></td>
<td><p>Warp level instructions for surface stores</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>inst_executed_tex_ops</p></td>
<td><p>Warp level instructions for texture</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>inst_fp_16</p></td>
<td><p>Number of half-precision floating-point instructions executed by non-predicated threads (arithmetic, compare, etc.)</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>inst_fp_32</p></td>
<td><p>Number of single-precision floating-point instructions executed by non-predicated threads (arithmetic, compare, etc.)</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>inst_fp_64</p></td>
<td><p>Number of double-precision floating-point instructions executed by non-predicated threads (arithmetic, compare, etc.)</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>inst_integer</p></td>
<td><p>Number of integer instructions executed by non-predicated threads</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>inst_inter_thread_communication</p></td>
<td><p>Number of inter-thread communication instructions executed by non-predicated threads</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>inst_issued</p></td>
<td><p>The number of instructions issued</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>inst_misc</p></td>
<td><p>Number of miscellaneous instructions executed by non-predicated threads</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>inst_per_warp</p></td>
<td><p>Average number of instructions executed by each warp</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>inst_replay_overhead</p></td>
<td><p>Average number of replays for each instruction executed</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>ipc</p></td>
<td><p>Instructions executed per cycle</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>issue_slot_utilization</p></td>
<td><p>Percentage of issue slots that issued at least one instruction, averaged across all cycles</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>issue_slots</p></td>
<td><p>The number of issue slots used</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>issued_ipc</p></td>
<td><p>Instructions issued per cycle</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>l2_atomic_throughput</p></td>
<td><p>Memory read throughput seen at L2 cache for atomic and reduction requests</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>l2_atomic_transactions</p></td>
<td><p>Memory read transactions seen at L2 cache for atomic and reduction requests</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>l2_global_atomic_store_bytes</p></td>
<td><p>Bytes written to L2 from L1 for global atomics (ATOM and ATOM CAS)</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>l2_global_load_bytes</p></td>
<td><p>Bytes read from L2 for misses in L1 for global loads</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>l2_local_global_store_bytes</p></td>
<td><p>Bytes written to L2 from L1 for local and global stores. This does not include global atomics.</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>l2_local_load_bytes</p></td>
<td><p>Bytes read from L2 for misses in L1 for local loads</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>l2_read_throughput</p></td>
<td><p>Memory read throughput seen at L2 cache for all read requests</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>l2_read_transactions</p></td>
<td><p>Memory read transactions seen at L2 cache for all read requests</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>l2_surface_load_bytes</p></td>
<td><p>Bytes read from L2 for misses in L1 for surface loads</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>l2_surface_store_bytes</p></td>
<td><p>Bytes read from L2 for misses in L1 for surface stores</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>l2_tex_hit_rate</p></td>
<td><p>Hit rate at L2 cache for all requests from texture cache</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>l2_tex_read_hit_rate</p></td>
<td><p>Hit rate at L2 cache for all read requests from texture cache</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>l2_tex_read_throughput</p></td>
<td><p>Memory read throughput seen at L2 cache for read requests from the texture cache</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>l2_tex_read_transactions</p></td>
<td><p>Memory read transactions seen at L2 cache for read requests from the texture cache</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>l2_tex_write_hit_rate</p></td>
<td><p>Hit Rate at L2 cache for all write requests from texture cache</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>l2_tex_write_throughput</p></td>
<td><p>Memory write throughput seen at L2 cache for write requests from the texture cache</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>l2_tex_write_transactions</p></td>
<td><p>Memory write transactions seen at L2 cache for write requests from the texture cache</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>l2_utilization</p></td>
<td><p>The utilization level of the L2 cache relative to the peak utilization on a scale of 0 to 10</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>l2_write_throughput</p></td>
<td><p>Memory write throughput seen at L2 cache for all write requests</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>l2_write_transactions</p></td>
<td><p>Memory write transactions seen at L2 cache for all write requests</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>ldst_executed</p></td>
<td><p>Number of executed local, global, shared and texture memory load and store instructions</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>ldst_fu_utilization</p></td>
<td><p>The utilization level of the multiprocessor function units that execute shared load, shared store and constant load instructions on a scale of 0 to 10</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>ldst_issued</p></td>
<td><p>Number of issued local, global, shared and texture memory load and store instructions</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>local_hit_rate</p></td>
<td><p>Hit rate for local loads and stores</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>local_load_requests</p></td>
<td><p>Total number of local load requests from Multiprocessor</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>local_load_throughput</p></td>
<td><p>Local memory load throughput</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>local_load_transactions</p></td>
<td><p>Number of local memory load transactions</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>local_load_transactions_per_request</p></td>
<td><p>Average number of local memory load transactions performed for each local memory load</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>local_memory_overhead</p></td>
<td><p>Ratio of local memory traffic to total memory traffic between the L1 and L2 caches expressed as percentage</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>local_store_requests</p></td>
<td><p>Total number of local store requests from Multiprocessor</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>local_store_throughput</p></td>
<td><p>Local memory store throughput</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>local_store_transactions</p></td>
<td><p>Number of local memory store transactions</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>local_store_transactions_per_request</p></td>
<td><p>Average number of local memory store transactions performed for each local memory store</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>nvlink_overhead_data_received</p></td>
<td><p>Ratio of overhead data to the total data, received through NVLink.</p></td>
<td><p>Device</p></td>
</tr>
<tr class="row-odd"><td><p>nvlink_overhead_data_transmitted</p></td>
<td><p>Ratio of overhead data to the total data, transmitted through NVLink.</p></td>
<td><p>Device</p></td>
</tr>
<tr class="row-even"><td><p>nvlink_receive_throughput</p></td>
<td><p>Number of bytes received per second through NVLinks.</p></td>
<td><p>Device</p></td>
</tr>
<tr class="row-odd"><td><p>nvlink_total_data_received</p></td>
<td><p>Total data bytes received through NVLinks including headers.</p></td>
<td><p>Device</p></td>
</tr>
<tr class="row-even"><td><p>nvlink_total_data_transmitted</p></td>
<td><p>Total data bytes transmitted through NVLinks including headers.</p></td>
<td><p>Device</p></td>
</tr>
<tr class="row-odd"><td><p>nvlink_total_nratom_data_transmitted</p></td>
<td><p>Total non-reduction atomic data bytes transmitted through NVLinks.</p></td>
<td><p>Device</p></td>
</tr>
<tr class="row-even"><td><p>nvlink_total_ratom_data_transmitted</p></td>
<td><p>Total reduction atomic data bytes transmitted through NVLinks.</p></td>
<td><p>Device</p></td>
</tr>
<tr class="row-odd"><td><p>nvlink_total_response_data_received</p></td>
<td><p>Total response data bytes received through NVLink, response data includes data for read requests and result of non-reduction atomic requests.</p></td>
<td><p>Device</p></td>
</tr>
<tr class="row-even"><td><p>nvlink_total_write_data_transmitted</p></td>
<td><p>Total write data bytes transmitted through NVLinks.</p></td>
<td><p>Device</p></td>
</tr>
<tr class="row-odd"><td><p>nvlink_transmit_throughput</p></td>
<td><p>Number of Bytes Transmitted per second through NVLinks.</p></td>
<td><p>Device</p></td>
</tr>
<tr class="row-even"><td><p>nvlink_user_data_received</p></td>
<td><p>User data bytes received through NVLinks, doesn’t include headers.</p></td>
<td><p>Device</p></td>
</tr>
<tr class="row-odd"><td><p>nvlink_user_data_transmitted</p></td>
<td><p>User data bytes transmitted through NVLinks, doesn’t include headers.</p></td>
<td><p>Device</p></td>
</tr>
<tr class="row-even"><td><p>nvlink_user_nratom_data_transmitted</p></td>
<td><p>Total non-reduction atomic user data bytes transmitted through NVLinks.</p></td>
<td><p>Device</p></td>
</tr>
<tr class="row-odd"><td><p>nvlink_user_ratom_data_transmitted</p></td>
<td><p>Total reduction atomic user data bytes transmitted through NVLinks.</p></td>
<td><p>Device</p></td>
</tr>
<tr class="row-even"><td><p>nvlink_user_response_data_received</p></td>
<td><p>Total user response data bytes received through NVLink, response data includes data for read requests and result of non-reduction atomic requests.</p></td>
<td><p>Device</p></td>
</tr>
<tr class="row-odd"><td><p>nvlink_user_write_data_transmitted</p></td>
<td><p>User write data bytes transmitted through NVLinks.</p></td>
<td><p>Device</p></td>
</tr>
<tr class="row-even"><td><p>pcie_total_data_received</p></td>
<td><p>Total data bytes received through PCIe</p></td>
<td><p>Device</p></td>
</tr>
<tr class="row-odd"><td><p>pcie_total_data_transmitted</p></td>
<td><p>Total data bytes transmitted through PCIe</p></td>
<td><p>Device</p></td>
</tr>
<tr class="row-even"><td><p>shared_efficiency</p></td>
<td><p>Ratio of requested shared memory throughput to required shared memory throughput expressed as percentage</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>shared_load_throughput</p></td>
<td><p>Shared memory load throughput</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>shared_load_transactions</p></td>
<td><p>Number of shared memory load transactions</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>shared_load_transactions_per_request</p></td>
<td><p>Average number of shared memory load transactions performed for each shared memory load</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>shared_store_throughput</p></td>
<td><p>Shared memory store throughput</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>shared_store_transactions</p></td>
<td><p>Number of shared memory store transactions</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>shared_store_transactions_per_request</p></td>
<td><p>Average number of shared memory store transactions performed for each shared memory store</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>shared_utilization</p></td>
<td><p>The utilization level of the shared memory relative to peak utilization on a scale of 0 to 10</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>single_precision_fu_utilization</p></td>
<td><p>The utilization level of the multiprocessor function units that execute single-precision floating-point instructions on a scale of 0 to 10</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>sm_efficiency</p></td>
<td><p>The percentage of time at least one warp is active on a specific multiprocessor</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>special_fu_utilization</p></td>
<td><p>The utilization level of the multiprocessor function units that execute sin, cos, ex2, popc, flo, and similar instructions on a scale of 0 to 10</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>stall_constant_memory_dependency</p></td>
<td><p>Percentage of stalls occurring because of immediate constant cache miss</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>stall_exec_dependency</p></td>
<td><p>Percentage of stalls occurring because an input required by the instruction is not yet available</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>stall_inst_fetch</p></td>
<td><p>Percentage of stalls occurring because the next assembly instruction has not yet been fetched</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>stall_memory_dependency</p></td>
<td><p>Percentage of stalls occurring because a memory operation cannot be performed due to the required resources not being available or fully utilized, or because too many requests of a given type are outstanding</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>stall_memory_throttle</p></td>
<td><p>Percentage of stalls occurring because of memory throttle</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>stall_not_selected</p></td>
<td><p>Percentage of stalls occurring because warp was not selected</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>stall_other</p></td>
<td><p>Percentage of stalls occurring due to miscellaneous reasons</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>stall_pipe_busy</p></td>
<td><p>Percentage of stalls occurring because a compute operation cannot be performed because the compute pipeline is busy</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>stall_sleeping</p></td>
<td><p>Percentage of stalls occurring because warp was sleeping</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>stall_sync</p></td>
<td><p>Percentage of stalls occurring because the warp is blocked at a __syncthreads() call</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>stall_texture</p></td>
<td><p>Percentage of stalls occurring because the texture sub-system is fully utilized or has too many outstanding requests</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>surface_atomic_requests</p></td>
<td><p>Total number of surface atomic(Atom and Atom CAS) requests from Multiprocessor</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>surface_load_requests</p></td>
<td><p>Total number of surface load requests from Multiprocessor</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>surface_reduction_requests</p></td>
<td><p>Total number of surface reduction requests from Multiprocessor</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>surface_store_requests</p></td>
<td><p>Total number of surface store requests from Multiprocessor</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>sysmem_read_bytes</p></td>
<td><p>Number of bytes read from system memory</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>sysmem_read_throughput</p></td>
<td><p>System memory read throughput</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>sysmem_read_transactions</p></td>
<td><p>Number of system memory read transactions</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>sysmem_read_utilization</p></td>
<td><p>The read utilization level of the system memory relative to the peak utilization on a scale of 0 to 10</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>sysmem_utilization</p></td>
<td><p>The utilization level of the system memory relative to the peak utilization on a scale of 0 to 10</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>sysmem_write_bytes</p></td>
<td><p>Number of bytes written to system memory</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>sysmem_write_throughput</p></td>
<td><p>System memory write throughput</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>sysmem_write_transactions</p></td>
<td><p>Number of system memory write transactions</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>sysmem_write_utilization</p></td>
<td><p>The write utilization level of the system memory relative to the peak utilization on a scale of 0 to 10</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>tensor_precision_fu_utilization</p></td>
<td><p>The utilization level of the multiprocessor function units that execute tensor core instructions on a scale of 0 to 10</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>tensor_int_fu_utilization</p></td>
<td><p>The utilization level of the multiprocessor function units that execute tensor core int8 instructions on a scale of 0 to 10. This metric is only available for device with compute capability 7.2.</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>tex_cache_hit_rate</p></td>
<td><p>Unified cache hit rate</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>tex_cache_throughput</p></td>
<td><p>Unified cache to Multiprocessor read throughput</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>tex_cache_transactions</p></td>
<td><p>Unified cache to Multiprocessor read transactions</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>tex_fu_utilization</p></td>
<td><p>The utilization level of the multiprocessor function units that execute global, local and texture memory instructions on a scale of 0 to 10</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>tex_utilization</p></td>
<td><p>The utilization level of the unified cache relative to the peak utilization on a scale of 0 to 10</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>texture_load_requests</p></td>
<td><p>Total number of texture Load requests from Multiprocessor</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-odd"><td><p>warp_execution_efficiency</p></td>
<td><p>Ratio of the average active threads per warp to the maximum number of threads per warp supported on a multiprocessor</p></td>
<td><p>Multi-context</p></td>
</tr>
<tr class="row-even"><td><p>warp_nonpred_execution_efficiency</p></td>
<td><p>Ratio of the average active threads per warp executing non-predicated instructions to the maximum number of threads per warp supported on a multiprocessor</p></td>
<td><p>Multi-context</p></td>
</tr>
</tbody>
</table>
</section>
</section>
</section>
<section id="cupti-profiling-api">
<span id="profiler"></span><h2><span class="section-number">2.7. </span>CUPTI Profiling API<a class="headerlink" href="#cupti-profiling-api" title="Permalink to this headline"></a></h2>
<p>Starting with CUDA 10.0, a new set of metric APIs are added for devices with compute capability 7.0 and higher. These APIs provide low and deterministic profiling overhead on the target system. These are supported on all CUDA supported platforms except Android, and are not supported under MPS (Multi-Process Service), Confidential Compute, or SLI configured systems. In order to determine whether a device is compatible with this API, a new function <code class="docutils literal notranslate"><span class="pre">cuptiProfilerDeviceSupported</span></code> is introduced in CUDA 11.5 which exposes overall Profiling API support and specific requirements for a given device. Profiling API must be initialized by calling <code class="docutils literal notranslate"><span class="pre">cuptiProfilerInitialize</span></code> before testing device support.</p>
<p>This section covers performance profiling Host and Target APIs for CUDA. Broadly profiling APIs are divided into following four sections:</p>
<ul class="simple">
<li><p>Enumeration (Host)</p></li>
<li><p>Configuration (Host)</p></li>
<li><p>Collection (Target)</p></li>
<li><p>Evaluation (Host)</p></li>
</ul>
<p>Host APIs provide a <a class="reference external" href="../main/main.html#profiler-definitions-metric">metric</a> interface for enumeration, configuration and evaluation that doesn’t require a compute(GPU) device, and can also run in an offline mode. In the samples section under <a class="reference external" href="../main/main.html#sample-extensions">extensions</a>, profiler host utility covers the usage of host APIs. Target APIs are used for data collection of the metrics and requires a compute (GPU) device. Refer to samples <a class="reference external" href="../main/main.html#sample-autorange-profiling">auto_rangeProfiling</a> and <a class="reference external" href="../main/main.html#sample-userrange-profiling">userrange_profiling</a> for usage of profiling APIs.</p>
<p>The list of metrics has been overhauled from earlier generation metrics and event APIs, to support a standard naming convention based upon <code class="docutils literal notranslate"><span class="pre">unit__(subunit?)_(pipestage?)_quantity_qualifiers</span></code></p>
<section id="multi-pass-collection">
<span id="profiler-multi-pass-collection"></span><h3><span class="section-number">2.7.1. </span>Multi Pass Collection<a class="headerlink" href="#multi-pass-collection" title="Permalink to this headline"></a></h3>
<p>NVIDIA GPU hardware has a limited number of counter registers and cannot collect all possible counters concurrently. There are also limitations on which counters can be collected together in a single <a class="reference external" href="../main/main.html#profiler-definitions-pass">pass</a>. This is resolved by replaying the exact same set of GPU workloads multiple times, where each replay is termed a <a class="reference external" href="../main/main.html#profiler-definitions-pass">pass</a>. On each pass, a different subset of requested counters are collected. Once all passes are collected, the data is available for evaluation. Certain metrics have many counters as inputs; adding a single metric may require many passes to collect. CUPTI APIs support multi pass collection through different collection attributes.</p>
<p>Sample <a class="reference external" href="../main/main.html#sample-cupti-metric-properties">cupti_metric_properties</a> shows how to query number of passes required to collect a set of counters.</p>
</section>
<section id="range-profiling">
<span id="profiler-range-profiling"></span><h3><span class="section-number">2.7.2. </span>Range Profiling<a class="headerlink" href="#range-profiling" title="Permalink to this headline"></a></h3>
<p>Each profiling session runs a series of replay passes, where each pass contains a sequence of ranges. Every metric enabled in the session’s configuration is collected separately per unique range-stack in the pass. CUPTI supports auto and user defined ranges.</p>
<section id="auto-range">
<span id="profiler-auto-range"></span><h4><span class="section-number">2.7.2.1. </span>Auto Range<a class="headerlink" href="#auto-range" title="Permalink to this headline"></a></h4>
<p>In a session with auto range mode, ranges are defined around each kernel automatically with a unique name assigned to each range, while profiling is enabled. This mode is useful for tight metric collection around each kernel. A user can choose one of the supported replay modes, pseudo code for each is described below:</p>
<p class="rubric-h4 rubric">Kernel Replay</p>
<p>The replay logic (multiple pass, if needed) is done by CUPTI implicitly (opaque to the user), and usage of CUPTI replay API’s <code class="docutils literal notranslate"><span class="pre">cuptiProfilerBeginPass</span></code> and <code class="docutils literal notranslate"><span class="pre">cuptiProfilerEndPass</span></code> will be a no-op in this mode. This mode is useful for collecting metrics around a kernel in tight control. Each kernel launch is synchronized to segregate its metrics into a separate range, and a CPU-GPU sync is made to ensure the profiled data is collected from GPU. Counter Collection can be enabled and disabled with <code class="docutils literal notranslate"><span class="pre">cuptiProfilerEnableProfiling</span></code> and <code class="docutils literal notranslate"><span class="pre">cuptiProfilerDisableProfiling</span></code>. Refer to the sample <a class="reference external" href="../main/main.html#sample-autorange-profiling">autorange_profiling</a></p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="cm">/* Assume Inputs(counterDataImagePrefix and configImage) from configuration phase at host */</span><span class="w"></span>
<span class="kt">void</span><span class="w"> </span><span class="nf">Collection</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">uint8_t</span><span class="o">&gt;&amp;</span><span class="w"> </span><span class="n">counterDataImagePrefix</span><span class="p">,</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">uint8_t</span><span class="o">&gt;&amp;</span><span class="w"> </span><span class="n">configImage</span><span class="p">)</span><span class="w"></span>
<span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="n">CUpti_Profiler_Initialize_Params</span><span class="w"> </span><span class="n">profilerInitializeParams</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="n">CUpti_Profiler_Initialize_Params_STRUCT_SIZE</span><span class="w"> </span><span class="p">};</span><span class="w"></span>
<span class="w">    </span><span class="n">cuptiProfilerInitialize</span><span class="p">(</span><span class="o">&amp;</span><span class="n">profilerInitializeParams</span><span class="p">);</span><span class="w"></span>

<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">uint8_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">counterDataImages</span><span class="p">;</span><span class="w"></span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">uint8_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">counterDataScratchBuffer</span><span class="p">;</span><span class="w"></span>
<span class="w">    </span><span class="n">CreateCounterDataImage</span><span class="p">(</span><span class="n">counterDataImages</span><span class="p">,</span><span class="w"> </span><span class="n">counterDataScratchBuffer</span><span class="p">,</span><span class="w"> </span><span class="n">counterDataImagePrefix</span><span class="p">);</span><span class="w"></span>

<span class="w">    </span><span class="n">CUpti_Profiler_BeginSession_Params</span><span class="w"> </span><span class="n">beginSessionParams</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="n">CUpti_Profiler_BeginSession_Params_STRUCT_SIZE</span><span class="w"> </span><span class="p">};</span><span class="w"></span>
<span class="w">    </span><span class="n">CUpti_ProfilerRange</span><span class="w"> </span><span class="n">profilerRange</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">CUPTI_AutoRange</span><span class="p">;</span><span class="w"></span>
<span class="w">    </span><span class="n">CUpti_ProfilerReplayMode</span><span class="w"> </span><span class="n">profilerReplayMode</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">CUPTI_KernelReplay</span><span class="p">;</span><span class="w"></span>

<span class="w">    </span><span class="n">beginSessionParams</span><span class="p">.</span><span class="n">ctx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">NULL</span><span class="p">;</span><span class="w"></span>
<span class="w">    </span><span class="n">beginSessionParams</span><span class="p">.</span><span class="n">counterDataImageSize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">counterDataImage</span><span class="p">.</span><span class="n">size</span><span class="p">();</span><span class="w"></span>
<span class="w">    </span><span class="n">beginSessionParams</span><span class="p">.</span><span class="n">pCounterDataImage</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">&amp;</span><span class="n">counterDataImage</span><span class="p">[</span><span class="mi">0</span><span class="p">];</span><span class="w"></span>
<span class="w">    </span><span class="n">beginSessionParams</span><span class="p">.</span><span class="n">counterDataScratchBufferSize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">counterDataScratchBuffer</span><span class="p">.</span><span class="n">size</span><span class="p">();</span><span class="w"></span>
<span class="w">    </span><span class="n">beginSessionParams</span><span class="p">.</span><span class="n">pCounterDataScratchBuffer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">&amp;</span><span class="n">counterDataScratchBuffer</span><span class="p">[</span><span class="mi">0</span><span class="p">];</span><span class="w"></span>
<span class="w">    </span><span class="n">beginSessionParams</span><span class="p">.</span><span class="n">range</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">profilerRange</span><span class="p">;</span><span class="w"></span>
<span class="w">    </span><span class="n">beginSessionParams</span><span class="p">.</span><span class="n">replayMode</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">profilerReplayMode</span><span class="p">;</span><span class="w"></span>
<span class="w">    </span><span class="n">beginSessionParams</span><span class="p">.</span><span class="n">maxRangesPerPass</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">num_ranges</span><span class="p">;</span><span class="w"></span>
<span class="w">    </span><span class="n">beginSessionParams</span><span class="p">.</span><span class="n">maxLaunchesPerPass</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">num_ranges</span><span class="p">;</span><span class="w"></span>

<span class="w">    </span><span class="n">cuptiProfilerBeginSession</span><span class="p">(</span><span class="o">&amp;</span><span class="n">beginSessionParams</span><span class="p">));</span><span class="w"></span>

<span class="w">    </span><span class="n">CUpti_Profiler_SetConfig_Params</span><span class="w"> </span><span class="n">setConfigParams</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="n">CUpti_Profiler_SetConfig_Params_STRUCT_SIZE</span><span class="w"> </span><span class="p">};</span><span class="w"></span>
<span class="w">    </span><span class="n">setConfigParams</span><span class="p">.</span><span class="n">pConfig</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">&amp;</span><span class="n">configImage</span><span class="p">[</span><span class="mi">0</span><span class="p">];</span><span class="w"></span>
<span class="w">    </span><span class="n">setConfigParams</span><span class="p">.</span><span class="n">configSize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">configImage</span><span class="p">.</span><span class="n">size</span><span class="p">();</span><span class="w"></span>

<span class="w">    </span><span class="n">cuptiProfilerSetConfig</span><span class="p">(</span><span class="o">&amp;</span><span class="n">setConfigParams</span><span class="p">));</span><span class="w"></span>

<span class="w">    </span><span class="n">kernelA</span><span class="w"> </span><span class="o">&lt;&lt;&lt;</span><span class="n">grid</span><span class="p">,</span><span class="w"> </span><span class="n">tids</span><span class="w"> </span><span class="o">&gt;&gt;&gt;</span><span class="p">(...);</span><span class="w">                  </span><span class="c1">// KernelA not profiled</span>

<span class="w">    </span><span class="n">CUpti_Profiler_EnableProfiling_Params</span><span class="w"> </span><span class="n">enableProfilingParams</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="n">CUpti_Profiler_EnableProfiling_Params_STRUCT_SIZE</span><span class="w"> </span><span class="p">};</span><span class="w"></span>
<span class="w">    </span><span class="n">cuptiProfilerEnableProfiling</span><span class="p">(</span><span class="o">&amp;</span><span class="n">enableProfilingParams</span><span class="p">);</span><span class="w"></span>
<span class="w">    </span><span class="p">{</span><span class="w"></span>

<span class="w">        </span><span class="n">kernelB</span><span class="w"> </span><span class="o">&lt;&lt;&lt;</span><span class="n">grid</span><span class="p">,</span><span class="w"> </span><span class="n">tids</span><span class="w"> </span><span class="o">&gt;&gt;&gt;</span><span class="p">(...);</span><span class="w">              </span><span class="c1">// KernelB profiled and captured in an unique range.</span>
<span class="w">        </span><span class="n">kernelC</span><span class="w"> </span><span class="o">&lt;&lt;&lt;</span><span class="n">grid</span><span class="p">,</span><span class="w"> </span><span class="n">tids</span><span class="w"> </span><span class="o">&gt;&gt;&gt;</span><span class="p">(...);</span><span class="w">              </span><span class="c1">// KernelC profiled and captured in an unique range.</span>
<span class="w">        </span><span class="n">kernelD</span><span class="w"> </span><span class="o">&lt;&lt;&lt;</span><span class="n">grid</span><span class="p">,</span><span class="w"> </span><span class="n">tids</span><span class="w"> </span><span class="o">&gt;&gt;&gt;</span><span class="p">(...);</span><span class="w">              </span><span class="c1">// KernelD profiled and captured in an unique range.</span>
<span class="w">    </span><span class="p">}</span><span class="w"></span>

<span class="w">    </span><span class="n">CUpti_Profiler_DisableProfiling_Params</span><span class="w"> </span><span class="n">disableProfilingParams</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="n">CUpti_Profiler_DisableProfiling_Params_STRUCT_SIZE</span><span class="w"> </span><span class="p">};</span><span class="w"></span>
<span class="w">    </span><span class="n">cuptiProfilerDisableProfiling</span><span class="p">(</span><span class="o">&amp;</span><span class="n">disableProfilingParams</span><span class="p">);</span><span class="w"></span>

<span class="w">    </span><span class="n">kernelE</span><span class="w"> </span><span class="o">&lt;&lt;&lt;</span><span class="n">grid</span><span class="p">,</span><span class="w"> </span><span class="n">tids</span><span class="w"> </span><span class="o">&gt;&gt;&gt;</span><span class="p">(...);</span><span class="w">                  </span><span class="c1">// KernelE not profiled</span>

<span class="w">    </span><span class="n">CUpti_Profiler_UnsetConfig_Params</span><span class="w"> </span><span class="n">unsetConfigParams</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="n">CUpti_Profiler_UnsetConfig_Params_STRUCT_SIZE</span><span class="w"> </span><span class="p">};</span><span class="w"></span>
<span class="w">    </span><span class="n">cuptiProfilerUnsetConfig</span><span class="p">(</span><span class="o">&amp;</span><span class="n">unsetConfigParams</span><span class="p">);</span><span class="w"></span>

<span class="w">    </span><span class="n">CUpti_Profiler_EndSession_Params</span><span class="w"> </span><span class="n">endSessionParams</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="n">CUpti_Profiler_EndSession_Params_STRUCT_SIZE</span><span class="w"> </span><span class="p">};</span><span class="w"></span>
<span class="w">    </span><span class="n">cuptiProfilerEndSession</span><span class="p">(</span><span class="o">&amp;</span><span class="n">endSessionParams</span><span class="p">);</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</pre></div>
</div>
<p class="rubric-h4 rubric">User Replay</p>
<p>The replay (multiple passes, if needed) is done by the user using the replay API’s <code class="docutils literal notranslate"><span class="pre">cuptiProfilerBeginPass</span></code> and <code class="docutils literal notranslate"><span class="pre">cuptiProfilerEndPass</span></code>. It is user responsibility to flush the counter data <code class="docutils literal notranslate"><span class="pre">cuptiProfilerFlushCounterData</span></code> before ending the session to ensure collection of metric data in CPU. Counter collection can be enabled and disabled with <code class="docutils literal notranslate"><span class="pre">cuptiProfilerEnableProfiling</span></code>/ <code class="docutils literal notranslate"><span class="pre">cuptiProfilerDisableProfiling</span></code>. Refer to the sample <a class="reference external" href="../main/main.html#sample-autorange-profiling">autorange_profiling</a></p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="cm">/* Assume Inputs(counterDataImagePrefix and configImage) from configuration phase at host */</span><span class="w"></span>

<span class="kt">void</span><span class="w"> </span><span class="nf">Collection</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">uint8_t</span><span class="o">&gt;&amp;</span><span class="w"> </span><span class="n">counterDataImagePrefix</span><span class="p">,</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">uint8_t</span><span class="o">&gt;&amp;</span><span class="w"> </span><span class="n">configImage</span><span class="p">)</span><span class="w"></span>
<span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="n">CUpti_Profiler_Initialize_Params</span><span class="w"> </span><span class="n">profilerInitializeParams</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="n">CUpti_Profiler_Initialize_Params_STRUCT_SIZE</span><span class="p">};</span><span class="w"></span>
<span class="w">    </span><span class="n">cuptiProfilerInitialize</span><span class="p">(</span><span class="o">&amp;</span><span class="n">profilerInitializeParams</span><span class="p">);</span><span class="w"></span>

<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">uint8_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">counterDataImages</span><span class="p">;</span><span class="w"></span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">uint8_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">counterDataScratchBuffer</span><span class="p">;</span><span class="w"></span>
<span class="w">    </span><span class="n">CreateCounterDataImage</span><span class="p">(</span><span class="n">counterDataImages</span><span class="p">,</span><span class="w"> </span><span class="n">counterDataScratchBuffer</span><span class="p">,</span><span class="w"> </span><span class="n">counterDataImagePrefix</span><span class="p">);</span><span class="w"></span>

<span class="w">    </span><span class="n">CUpti_Profiler_BeginSession_Params</span><span class="w"> </span><span class="n">beginSessionParams</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="n">CUpti_Profiler_BeginSession_Params_STRUCT_SIZE</span><span class="p">};</span><span class="w"></span>
<span class="w">    </span><span class="n">CUpti_ProfilerRange</span><span class="w"> </span><span class="n">profilerRange</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">CUPTI_AutoRange</span><span class="p">;</span><span class="w"></span>
<span class="w">    </span><span class="n">CUpti_ProfilerReplayMode</span><span class="w"> </span><span class="n">profilerReplayMode</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">CUPTI_UserReplay</span><span class="p">;</span><span class="w"></span>

<span class="w">    </span><span class="n">beginSessionParams</span><span class="p">.</span><span class="n">ctx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">NULL</span><span class="p">;</span><span class="w"></span>
<span class="w">    </span><span class="n">beginSessionParams</span><span class="p">.</span><span class="n">counterDataImageSize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">counterDataImage</span><span class="p">.</span><span class="n">size</span><span class="p">();</span><span class="w"></span>
<span class="w">    </span><span class="n">beginSessionParams</span><span class="p">.</span><span class="n">pCounterDataImage</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">&amp;</span><span class="n">counterDataImage</span><span class="p">[</span><span class="mi">0</span><span class="p">];</span><span class="w"></span>
<span class="w">    </span><span class="n">beginSessionParams</span><span class="p">.</span><span class="n">counterDataScratchBufferSize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">counterDataScratchBuffer</span><span class="p">.</span><span class="n">size</span><span class="p">();</span><span class="w"></span>
<span class="w">    </span><span class="n">beginSessionParams</span><span class="p">.</span><span class="n">pCounterDataScratchBuffer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">&amp;</span><span class="n">counterDataScratchBuffer</span><span class="p">[</span><span class="mi">0</span><span class="p">];</span><span class="w"></span>
<span class="w">    </span><span class="n">beginSessionParams</span><span class="p">.</span><span class="n">range</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">profilerRange</span><span class="p">;</span><span class="w"></span>
<span class="w">    </span><span class="n">beginSessionParams</span><span class="p">.</span><span class="n">replayMode</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">profilerReplayMode</span><span class="p">;</span><span class="w"></span>
<span class="w">    </span><span class="n">beginSessionParams</span><span class="p">.</span><span class="n">maxRangesPerPass</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">num_ranges</span><span class="p">;</span><span class="w"></span>
<span class="w">    </span><span class="n">beginSessionParams</span><span class="p">.</span><span class="n">maxLaunchesPerPass</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">num_ranges</span><span class="p">;</span><span class="w"></span>

<span class="w">    </span><span class="n">cuptiProfilerBeginSession</span><span class="p">(</span><span class="o">&amp;</span><span class="n">beginSessionParams</span><span class="p">));</span><span class="w"></span>

<span class="w">    </span><span class="n">CUpti_Profiler_SetConfig_Params</span><span class="w"> </span><span class="n">setConfigParams</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="n">CUpti_Profiler_SetConfig_Params_STRUCT_SIZE</span><span class="p">};</span><span class="w"></span>
<span class="w">    </span><span class="n">setConfigParams</span><span class="p">.</span><span class="n">pConfig</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">&amp;</span><span class="n">configImage</span><span class="p">[</span><span class="mi">0</span><span class="p">];</span><span class="w"></span>
<span class="w">    </span><span class="n">setConfigParams</span><span class="p">.</span><span class="n">configSize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">configImage</span><span class="p">.</span><span class="n">size</span><span class="p">();</span><span class="w"></span>

<span class="w">    </span><span class="n">cuptiProfilerSetConfig</span><span class="p">(</span><span class="o">&amp;</span><span class="n">setConfigParams</span><span class="p">));</span><span class="w"></span>

<span class="w">    </span><span class="n">CUpti_Profiler_FlushCounterData_Params</span><span class="w"> </span><span class="n">cuptiFlushCounterDataParams</span><span class="w"> </span><span class="o">=</span><span class="w">        </span><span class="p">{</span><span class="n">CUpti_Profiler_FlushCounterData_Params_STRUCT_SIZE</span><span class="p">};</span><span class="w"></span>

<span class="w">    </span><span class="n">CUpti_Profiler_EnableProfiling_Params</span><span class="w"> </span><span class="n">enableProfilingParams</span><span class="w"> </span><span class="o">=</span><span class="w">       </span><span class="p">{</span><span class="n">CUpti_Profiler_EnableProfiling_Params_STRUCT_SIZE</span><span class="p">};</span><span class="w"></span>

<span class="w">    </span><span class="n">CUpti_Profiler_DisableProfiling_Params</span><span class="w"> </span><span class="n">disableProfilingParams</span><span class="w"> </span><span class="o">=</span><span class="w">         </span><span class="p">{</span><span class="n">CUpti_Profiler_DisableProfiling_Params_STRUCT_SIZE</span><span class="p">};</span><span class="w"></span>


<span class="w">    </span><span class="n">kernelA</span><span class="o">&lt;&lt;&lt;</span><span class="n">grid</span><span class="p">,</span><span class="w"> </span><span class="n">tids</span><span class="o">&gt;&gt;&gt;</span><span class="p">(...);</span><span class="w">                  </span><span class="c1">// KernelA neither profiled, nor replayed</span>

<span class="w">    </span><span class="n">CUpti_Profiler_BeginPass_Params</span><span class="w"> </span><span class="n">beginPassParams</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="n">CUpti_Profiler_BeginPass_Params_STRUCT_SIZE</span><span class="p">};</span><span class="w"></span>
<span class="w">    </span><span class="n">CUpti_Profiler_EndPass_Params</span><span class="w"> </span><span class="n">endPassParams</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="n">CUpti_Profiler_EndPass_Params_STRUCT_SIZE</span><span class="p">};</span><span class="w"></span>

<span class="w">    </span><span class="n">cuptiProfilerBeginPass</span><span class="p">(</span><span class="o">&amp;</span><span class="n">beginPassParams</span><span class="p">);</span><span class="w"></span>
<span class="w">    </span><span class="p">{</span><span class="w"></span>
<span class="w">        </span><span class="n">kernelB</span><span class="o">&lt;&lt;&lt;</span><span class="n">grid</span><span class="p">,</span><span class="w"> </span><span class="n">tids</span><span class="o">&gt;&gt;&gt;</span><span class="p">(...);</span><span class="w">              </span><span class="c1">// KernelB replayed but not profiled</span>

<span class="w">        </span><span class="n">cuptiProfilerEnableProfiling</span><span class="p">(</span><span class="o">&amp;</span><span class="n">enableProfilingParams</span><span class="p">);</span><span class="w"></span>

<span class="w">        </span><span class="n">kernelC</span><span class="o">&lt;&lt;&lt;</span><span class="n">grid</span><span class="p">,</span><span class="w"> </span><span class="n">tids</span><span class="o">&gt;&gt;&gt;</span><span class="p">(...);</span><span class="w">              </span><span class="c1">// KernelC profiled and captured in an unique range.</span>
<span class="w">        </span><span class="n">kernelD</span><span class="o">&lt;&lt;&lt;</span><span class="n">grid</span><span class="p">,</span><span class="w"> </span><span class="n">tids</span><span class="o">&gt;&gt;&gt;</span><span class="p">(...);</span><span class="w">              </span><span class="c1">// KernelD profiled and captured in an unique range.</span>

<span class="w">        </span><span class="n">cuptiProfilerDisableProfiling</span><span class="p">(</span><span class="o">&amp;</span><span class="n">disableProfilingParams</span><span class="p">);</span><span class="w"></span>
<span class="w">    </span><span class="p">}</span><span class="w"></span>
<span class="w">    </span><span class="n">cuptiProfilerEndPass</span><span class="p">(</span><span class="o">&amp;</span><span class="n">endPassParams</span><span class="p">);</span><span class="w"></span>

<span class="w">    </span><span class="n">cuptiProfilerFlushCounterData</span><span class="p">(</span><span class="o">&amp;</span><span class="n">cuptiFlushCounterDataParams</span><span class="p">);</span><span class="w"></span>

<span class="w">    </span><span class="n">kernelE</span><span class="o">&lt;&lt;&lt;</span><span class="n">grid</span><span class="p">,</span><span class="w"> </span><span class="n">tids</span><span class="o">&gt;&gt;&gt;</span><span class="p">(...);</span><span class="w">                  </span><span class="c1">// KernelE not profiled</span>

<span class="w">    </span><span class="n">CUpti_Profiler_UnsetConfig_Params</span><span class="w"> </span><span class="n">unsetConfigParams</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="n">CUpti_Profiler_UnsetConfig_Params_STRUCT_SIZE</span><span class="p">};</span><span class="w"></span>
<span class="w">    </span><span class="n">cuptiProfilerUnsetConfig</span><span class="p">(</span><span class="o">&amp;</span><span class="n">unsetConfigParams</span><span class="p">);</span><span class="w"></span>

<span class="w">    </span><span class="n">CUpti_Profiler_EndSession_Params</span><span class="w"> </span><span class="n">endSessionParams</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="n">CUpti_Profiler_EndSession_Params_STRUCT_SIZE</span><span class="p">};</span><span class="w"></span>
<span class="w">    </span><span class="n">cuptiProfilerEndSession</span><span class="p">(</span><span class="o">&amp;</span><span class="n">endSessionParams</span><span class="p">);</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</pre></div>
</div>
<p class="rubric-h4 rubric">Application Replay</p>
<p>This replay mode is same as user replay, instead of in process replay, you can replay the whole process again. You will need to update the pass index while setting the config <code class="docutils literal notranslate"><span class="pre">cuptiProfilerSetConfig</span></code> and reload the intermediate counterDataImage on each pass.</p>
</section>
<section id="user-range">
<span id="profiler-user-range"></span><h4><span class="section-number">2.7.2.2. </span>User Range<a class="headerlink" href="#user-range" title="Permalink to this headline"></a></h4>
<p>In a session with user range mode, ranges are defined by you, <code class="docutils literal notranslate"><span class="pre">cuptiProfilerPushRange</span></code> and <code class="docutils literal notranslate"><span class="pre">cuptiProfilerPopRange</span></code>. Kernel launches are concurrent within a range. This mode is useful for metric data collection around a specific section of code, instead of per-kernel metric collection. Kernel replay is not supported in user range mode. You own the responsibility of replay using <code class="docutils literal notranslate"><span class="pre">cuptiProfilerBeginPass</span></code> and <code class="docutils literal notranslate"><span class="pre">cuptiProfilerEndPass</span></code>.</p>
<p class="rubric-h4 rubric">User Replay</p>
<p>The replay (multiple passes, if needed) is done by the user using the replay API’s <code class="docutils literal notranslate"><span class="pre">cuptiProfilerBeginPass</span></code> and <code class="docutils literal notranslate"><span class="pre">cuptiProfilerEndPass</span></code>. It is your responsibility to flush the counter data using <code class="docutils literal notranslate"><span class="pre">cuptiProfilerFlushCounterData</span></code> before ending the session. Counter collection can be enabled/disabled with <code class="docutils literal notranslate"><span class="pre">cuptiProfilerEnableProfiling</span></code> and <code class="docutils literal notranslate"><span class="pre">cuptiProfilerDisableProfiling</span></code>. Refer to the sample <a class="reference external" href="../main/main.html#sample-userrange-profiling">userrange_profiling</a></p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="cm">/* Assume Inputs(counterDataImagePrefix and configImage) from configuration phase at host */</span><span class="w"></span>

<span class="kt">void</span><span class="w"> </span><span class="nf">Collection</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">uint8_t</span><span class="o">&gt;&amp;</span><span class="w"> </span><span class="n">counterDataImagePrefix</span><span class="p">,</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">uint8_t</span><span class="o">&gt;&amp;</span><span class="w"> </span><span class="n">configImage</span><span class="p">)</span><span class="w"></span>
<span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="n">CUpti_Profiler_Initialize_Params</span><span class="w"> </span><span class="n">profilerInitializeParams</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="n">CUpti_Profiler_Initialize_Params_STRUCT_SIZE</span><span class="p">};</span><span class="w"></span>
<span class="w">    </span><span class="n">cuptiProfilerInitialize</span><span class="p">(</span><span class="o">&amp;</span><span class="n">profilerInitializeParams</span><span class="p">);</span><span class="w"></span>

<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">uint8_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">counterDataImages</span><span class="p">;</span><span class="w"></span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">uint8_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">counterDataScratchBuffer</span><span class="p">;</span><span class="w"></span>
<span class="w">    </span><span class="n">CreateCounterDataImage</span><span class="p">(</span><span class="n">counterDataImages</span><span class="p">,</span><span class="w"> </span><span class="n">counterDataScratchBuffer</span><span class="p">,</span><span class="w"> </span><span class="n">counterDataImagePrefix</span><span class="p">);</span><span class="w"></span>

<span class="w">    </span><span class="n">CUpti_Profiler_BeginSession_Params</span><span class="w"> </span><span class="n">beginSessionParams</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="n">CUpti_Profiler_BeginSession_Params_STRUCT_SIZE</span><span class="p">};</span><span class="w"></span>
<span class="w">    </span><span class="n">CUpti_ProfilerRange</span><span class="w"> </span><span class="n">profilerRange</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">CUPTI_UserRange</span><span class="p">;</span><span class="w"></span>
<span class="w">    </span><span class="n">CUpti_ProfilerReplayMode</span><span class="w"> </span><span class="n">profilerReplayMode</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">CUPTI_UserReplay</span><span class="p">;</span><span class="w"></span>

<span class="w">    </span><span class="n">beginSessionParams</span><span class="p">.</span><span class="n">ctx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">NULL</span><span class="p">;</span><span class="w"></span>
<span class="w">    </span><span class="n">beginSessionParams</span><span class="p">.</span><span class="n">counterDataImageSize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">counterDataImage</span><span class="p">.</span><span class="n">size</span><span class="p">();</span><span class="w"></span>
<span class="w">    </span><span class="n">beginSessionParams</span><span class="p">.</span><span class="n">pCounterDataImage</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">&amp;</span><span class="n">counterDataImage</span><span class="p">[</span><span class="mi">0</span><span class="p">];</span><span class="w"></span>
<span class="w">    </span><span class="n">beginSessionParams</span><span class="p">.</span><span class="n">counterDataScratchBufferSize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">counterDataScratchBuffer</span><span class="p">.</span><span class="n">size</span><span class="p">();</span><span class="w"></span>
<span class="w">    </span><span class="n">beginSessionParams</span><span class="p">.</span><span class="n">pCounterDataScratchBuffer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">&amp;</span><span class="n">counterDataScratchBuffer</span><span class="p">[</span><span class="mi">0</span><span class="p">];</span><span class="w"></span>
<span class="w">    </span><span class="n">beginSessionParams</span><span class="p">.</span><span class="n">range</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">profilerRange</span><span class="p">;</span><span class="w"></span>
<span class="w">    </span><span class="n">beginSessionParams</span><span class="p">.</span><span class="n">replayMode</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">profilerReplayMode</span><span class="p">;</span><span class="w"></span>
<span class="w">    </span><span class="n">beginSessionParams</span><span class="p">.</span><span class="n">maxRangesPerPass</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">num_ranges</span><span class="p">;</span><span class="w"></span>
<span class="w">    </span><span class="n">beginSessionParams</span><span class="p">.</span><span class="n">maxLaunchesPerPass</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">num_ranges</span><span class="p">;</span><span class="w"></span>

<span class="w">    </span><span class="n">cuptiProfilerBeginSession</span><span class="p">(</span><span class="o">&amp;</span><span class="n">beginSessionParams</span><span class="p">));</span><span class="w"></span>

<span class="w">    </span><span class="n">CUpti_Profiler_SetConfig_Params</span><span class="w"> </span><span class="n">setConfigParams</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="n">CUpti_Profiler_SetConfig_Params_STRUCT_SIZE</span><span class="p">};</span><span class="w"></span>
<span class="w">    </span><span class="n">setConfigParams</span><span class="p">.</span><span class="n">pConfig</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">&amp;</span><span class="n">configImage</span><span class="p">[</span><span class="mi">0</span><span class="p">];</span><span class="w"></span>
<span class="w">    </span><span class="n">setConfigParams</span><span class="p">.</span><span class="n">configSize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">configImage</span><span class="p">.</span><span class="n">size</span><span class="p">();</span><span class="w"></span>

<span class="w">    </span><span class="n">cuptiProfilerSetConfig</span><span class="p">(</span><span class="o">&amp;</span><span class="n">setConfigParams</span><span class="p">));</span><span class="w"></span>

<span class="w">    </span><span class="n">CUpti_Profiler_FlushCounterData_Params</span><span class="w"> </span><span class="n">cuptiFlushCounterDataParams</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="n">CUpti_Profiler_FlushCounterData_Params_STRUCT_SIZE</span><span class="p">};</span><span class="w"></span>

<span class="w">    </span><span class="n">kernelA</span><span class="o">&lt;&lt;&lt;</span><span class="n">grid</span><span class="p">,</span><span class="w"> </span><span class="n">tids</span><span class="o">&gt;&gt;&gt;</span><span class="p">(...);</span><span class="w">                  </span><span class="c1">// KernelA neither profiled, nor replayed</span>

<span class="w">    </span><span class="n">CUpti_Profiler_BeginPass_Params</span><span class="w"> </span><span class="n">beginPassParams</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="n">CUpti_Profiler_BeginPass_Params_STRUCT_SIZE</span><span class="p">};</span><span class="w"></span>
<span class="w">    </span><span class="n">CUpti_Profiler_EndPass_Params</span><span class="w"> </span><span class="n">endPassParams</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="n">CUpti_Profiler_EndPass_Params_STRUCT_SIZE</span><span class="p">};</span><span class="w"></span>

<span class="w">    </span><span class="n">cuptiProfilerBeginPass</span><span class="p">(</span><span class="o">&amp;</span><span class="n">beginPassParams</span><span class="p">);</span><span class="w"></span>
<span class="w">    </span><span class="p">{</span><span class="w"></span>
<span class="w">        </span><span class="n">kernelB</span><span class="o">&lt;&lt;&lt;</span><span class="n">grid</span><span class="p">,</span><span class="w"> </span><span class="n">tids</span><span class="o">&gt;&gt;&gt;</span><span class="p">(...);</span><span class="w">              </span><span class="c1">// KernelB replayed but not profiled</span>

<span class="w">        </span><span class="n">CUpti_Profiler_PushRange_Params</span><span class="w"> </span><span class="n">enableProfilingParams</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="n">CUpti_Profiler_PushRange_Params_STRUCT_SIZE</span><span class="p">};</span><span class="w"></span>
<span class="w">        </span><span class="n">pushRangeParams</span><span class="p">.</span><span class="n">pRangeName</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;RangeA&quot;</span><span class="p">;</span><span class="w"></span>
<span class="w">        </span><span class="n">cuptiProfilerPushRange</span><span class="p">(</span><span class="o">&amp;</span><span class="n">pushRangeParams</span><span class="p">);</span><span class="w"></span>

<span class="w">        </span><span class="n">kernelC</span><span class="o">&lt;&lt;&lt;</span><span class="n">grid</span><span class="p">,</span><span class="w"> </span><span class="n">tids</span><span class="o">&gt;&gt;&gt;</span><span class="p">(...);</span><span class="w"></span>
<span class="w">        </span><span class="n">kernelD</span><span class="o">&lt;&lt;&lt;</span><span class="n">grid</span><span class="p">,</span><span class="w"> </span><span class="n">tids</span><span class="o">&gt;&gt;&gt;</span><span class="p">(...);</span><span class="w"></span>

<span class="w">        </span><span class="n">cuptiProfilerPopRange</span><span class="p">(</span><span class="o">&amp;</span><span class="n">popRangeParams</span><span class="p">);</span><span class="w">     </span><span class="c1">// Kernel C and Kernel D are captured in rangeA without any serialization introduced by profiler</span>
<span class="w">    </span><span class="p">}</span><span class="w"></span>
<span class="w">    </span><span class="n">cuptiProfilerEndPass</span><span class="p">(</span><span class="o">&amp;</span><span class="n">endPassParams</span><span class="p">);</span><span class="w"></span>
<span class="w">    </span><span class="n">cuptiProfilerFlushCounterData</span><span class="p">(</span><span class="o">&amp;</span><span class="n">cuptiFlushCounterDataParams</span><span class="p">);</span><span class="w"></span>

<span class="w">    </span><span class="n">kernelE</span><span class="o">&lt;&lt;&lt;</span><span class="n">grid</span><span class="p">,</span><span class="w"> </span><span class="n">tids</span><span class="o">&gt;&gt;&gt;</span><span class="p">(...);</span><span class="w">                  </span><span class="c1">// KernelE not Profiled</span>

<span class="w">    </span><span class="n">CUpti_Profiler_UnsetConfig_Params</span><span class="w"> </span><span class="n">unsetConfigParams</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="n">CUpti_Profiler_UnsetConfig_Params_STRUCT_SIZE</span><span class="p">};</span><span class="w"></span>
<span class="w">    </span><span class="n">cuptiProfilerUnsetConfig</span><span class="p">(</span><span class="o">&amp;</span><span class="n">unsetConfigParams</span><span class="p">);</span><span class="w"></span>

<span class="w">    </span><span class="n">CUpti_Profiler_EndSession_Params</span><span class="w"> </span><span class="n">endSessionParams</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="n">CUpti_Profiler_EndSession_Params_STRUCT_SIZE</span><span class="p">};</span><span class="w"></span>
<span class="w">    </span><span class="n">cuptiProfilerEndSession</span><span class="p">(</span><span class="o">&amp;</span><span class="n">endSessionParams</span><span class="p">);</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</pre></div>
</div>
<p class="rubric-h4 rubric">Application Replay</p>
<p>This replay mode is same as user replay, instead of in process replay, you can replay the whole process again. You will need to update the pass index while setting the config using the <code class="docutils literal notranslate"><span class="pre">cuptiProfilerSetConfig</span></code> API, and reload the intermediate counterDataImage on each pass.</p>
</section>
</section>
<section id="cupti-profiler-definitions">
<span id="profiler-definitions"></span><h3><span class="section-number">2.7.3. </span>CUPTI Profiler Definitions<a class="headerlink" href="#cupti-profiler-definitions" title="Permalink to this headline"></a></h3>
<p>Definitions of glossary used in this section.</p>
<dl class="simple" id="profiler-definitions-counter">
<dt>Counter:</dt><dd><p>The number of occurrences of a specific event on the <a class="reference external" href="../main/main.html#profiler-definitions-device">device</a>.</p>
</dd>
<dt>Configuration Image:</dt><dd><p>A Blob to configure the session for <a class="reference external" href="../main/main.html#profiler-definitions-counter">counters</a> to be collected.</p>
</dd>
</dl>
<dl class="simple" id="profiler-definitions-counterdataimage">
<dt>CounterData Image:</dt><dd><p>A Blob which contains the values of collected <a class="reference external" href="../main/main.html#profiler-definitions-counter">counters</a></p>
</dd>
<dt>CounterData Prefix:</dt><dd><p>A metadata header for <a class="reference external" href="../main/main.html#profiler-definitions-counterdataimage">CounterData Image</a></p>
</dd>
</dl>
<dl class="simple" id="profiler-definitions-device">
<dt>Device:</dt><dd><p>A physical NVIDIA GPU.</p>
</dd>
<dt>Event:</dt><dd><p>An event is a countable activity, action, or occurrence on <a class="reference external" href="../main/main.html#profiler-definitions-device">device</a>.</p>
</dd>
</dl>
<dl class="simple" id="profiler-definitions-metric">
<dt>Metric:</dt><dd><p>A high-level value derived from <a class="reference external" href="../main/main.html#profiler-definitions-counter">counter</a> values.</p>
</dd>
</dl>
<dl class="simple" id="profiler-definitions-pass">
<dt>Pass:</dt><dd><p>A repeatable set of operations, with consistently labeled <a class="reference external" href="../main/main.html#profiler-definitions-range">ranges</a>.</p>
</dd>
</dl>
<dl class="simple" id="profiler-definitions-range">
<dt>Range:</dt><dd><p>A labeled region of execution</p>
</dd>
<dt>Replay:</dt><dd><p>Performing the repeatable set of operation.</p>
</dd>
<dt>Session:</dt><dd><p>A profiling session where GPU resources needed for profiling are allocated. The profiler is in armed state at session boundaries, and power management may be disabled at session boundaries. Outside of a session, the GPU will return to its normal operating state.</p>
</dd>
</dl>
</section>
<section id="differences-from-event-and-metric-apis">
<span id="profiler-missing-features"></span><h3><span class="section-number">2.7.4. </span>Differences from event and metric APIs<a class="headerlink" href="#differences-from-event-and-metric-apis" title="Permalink to this headline"></a></h3>
<p>Here is the list of features which are supported by the event and metric APIs but these are not available with the Profiling API:</p>
<ul class="simple">
<li><p>Continuous mode or sampling of the metrics.</p></li>
<li><p>Profiling API provides closest equivalent metrics for most of the events and metrics supported by the event and metric APIs. However, there are some events and metrics, for example NVLink performance metrics, for which there is no equivalent metrics in the Profiling API. Tables <a class="reference external" href="../main/main.html#metrics-mapping-table">Metrics Mapping Table</a> and <a class="reference external" href="../main/main.html#events-mapping-table">Events Mapping Table</a> can be referred to find the equivalent Perfworks metrics for compute capability 7.0.</p></li>
<li><p>Per-instance metrics i.e. users can’t collect metrics for each instance of the hardware units like SM, FB etc separately. However Profiling API provides sub-metrics which can be used to get the avg/sum/min/max across all instances of a hardware unit.</p></li>
</ul>
</section>
</section>
<section id="perfworks-metric-api">
<span id="host-metrics-api"></span><h2><span class="section-number">2.8. </span>Perfworks Metric API<a class="headerlink" href="#perfworks-metric-api" title="Permalink to this headline"></a></h2>
<p class="rubric-h4 rubric">Introduction:</p>
<p>The Perfworks Metric API supports the enumeration, configuration and evaluation of metrics. The binary outputs of the configuration phase are inputs to the <a class="reference external" href="../main/main.html#range-profiling">CUPTI Range Profiling API</a>. The output of Range Profiling is the <strong>CounterData</strong>, which is passed to the Derived Metrics Evaluation APIs.</p>
<p>GPU Metrics are generally presented as counts, ratios and percentages. The underlying values collected from hardware are raw counters (analogous to CUPTI events), but those details are hidden behind derived metric formulas.</p>
<p>The Metric APIs are split into two layers: Derived Metrics and Raw Metrics. Derived Metrics contains the list of named metrics and performs evaluation to numeric results, serving a similar purpose as <a class="reference external" href="../main/main.html#cupti-metric-api">the previous CUPTI Metric API</a>. Most user interaction will be with derived metrics. Raw Metrics contains the list of raw counters and generates configuration file images analogous to <a class="reference external" href="../main/main.html#cupti-event-api">the previous CUPTI Event API</a>.</p>
<p class="rubric-h4 rubric">Metric Enumeration</p>
<p>Metric Enumeration is the process of listing available counters and metrics.</p>
<p>Refer to file <code class="docutils literal notranslate"><span class="pre">List.cpp</span></code> used by the <a class="reference external" href="../main/main.html#sample-cupti-metric-properties">cupti_metric_properties</a> sample.</p>
<p>Metrics are grouped into three types i.e. counters, ratios and throughput. Except ratios metric type each metrics have four type of sub-metrics also known as rollup metrics i.e. sum, avg, min, max.</p>
<p>For enumerating supported metrics for a chip, we need to calculate the scratch buffer needed for host operation and to initialize the Metric Evaluator.</p>
<ul class="simple">
<li><p>Call <code class="docutils literal notranslate"><span class="pre">NVPW_CUDA_MetricsEvaluator_CalculateScratchBufferSize</span></code> for calculating scratch buffer size required for allocating memory for host operations.</p></li>
<li><p>Call <code class="docutils literal notranslate"><span class="pre">NVPW_CUDA_MetricsEvaluator_Initialize</span></code> for initializing the Metrics Evaluator which creates a NVPW_MetricsEvaluator object.</p></li>
</ul>
<p>The outline for enumerating supported counter metrics for a chip:</p>
<ul class="simple">
<li><p>Call <code class="docutils literal notranslate"><span class="pre">NVPW_MetricsEvaluator_GetMetricNames</span></code> for <strong>NVPW_METRIC_TYPE_COUNTER</strong> metric type for listing all the counter metrics supported.</p></li>
<li><p>Call <code class="docutils literal notranslate"><span class="pre">NVPW_MetricsEvaluator_GetSupportedSubmetrics</span></code> to list all the sub-metric supported for <strong>NVPW_METRIC_TYPE_COUNTER</strong> metric type.</p></li>
<li><p>Call <code class="docutils literal notranslate"><span class="pre">NVPW_MetricsEvaluator_GetCounterProperties</span></code> to give description of the counter and the collection hardware unit.</p></li>
</ul>
<p>Similarly, for enumerating ratio and throughput metrics we need to pass <strong>NVPW_METRIC_TYPE_RATIO</strong> and <strong>NVPW_METRIC_TYPE_THROUGHPUT</strong> as metric types to <code class="docutils literal notranslate"><span class="pre">NVPW_MetricsEvaluator_GetMetricNames</span></code> and <code class="docutils literal notranslate"><span class="pre">NVPW_MetricsEvaluator_GetSupportedSubmetrics</span></code>.</p>
<p>For more details about the metric properties call <code class="docutils literal notranslate"><span class="pre">NVPW_MetricsEvaluator_GetRatioMetricProperties</span></code> and <code class="docutils literal notranslate"><span class="pre">NVPW_MetricsEvaluator_GetThroughputMetricProperties</span></code> respectively.</p>
<p class="rubric-h4 rubric">Configuration Workflow</p>
<p>Configuration is the process of specifying the metrics that will be collected and how those metrics should be collected. The inputs for this phase are the metric names and metric collection properties. The output for this phase is a <strong>ConfigImage</strong> and a <strong>CounterDataPrefix</strong> Image.</p>
<p>Refer to file <code class="docutils literal notranslate"><span class="pre">Metric.cpp</span></code> used by the <a class="reference external" href="../main/main.html#sample-userrange-profiling">userrange_profiling sample</a>.</p>
<p>The outline for configuring metrics:</p>
<ul class="simple">
<li><p>As input, take a list of metric names.</p></li>
<li><p>Before creating ConfigImage or CounterDataPrefixImage, we need a list of NVPA_RawMetricRequest for the metrics listed for collection.</p>
<ul>
<li><p>We need to calculate the scratch buffer size required for the host operation and to initialize the Metric Evaluator like in the Enumeration phase.</p></li>
<li><p>For each metric, Call <code class="docutils literal notranslate"><span class="pre">NVPW_MetricsEvaluator_ConvertMetricNameToMetricEvalRequest</span></code> for creating a <strong>NVPW_MetricEvalRequest</strong>.</p></li>
<li><p>Call <code class="docutils literal notranslate"><span class="pre">NVPW_MetricsEvaluator_GetMetricRawDependencies</span></code> which takes the <strong>NVPW_MetricsEvaluator</strong> and <strong>NVPW_MetricEvalRequest</strong> as input, for getting raw dependencies for given metrics.</p></li>
</ul>
</li>
<li><p>Create an <code class="docutils literal notranslate"><span class="pre">NVPA_RawMetricRequest</span></code> with <code class="docutils literal notranslate"><span class="pre">keepInstances=true</span></code> and <code class="docutils literal notranslate"><span class="pre">isolated=true</span></code></p></li>
<li><p>Pass the <code class="docutils literal notranslate"><span class="pre">NVPA_RawMetricRequest</span></code> to <code class="docutils literal notranslate"><span class="pre">NVPW_RawMetricsConfig_AddMetrics</span></code> for the <strong>ConfigImage</strong>.</p></li>
<li><p>Pass the <code class="docutils literal notranslate"><span class="pre">NVPA_RawMetricRequest</span></code> to <code class="docutils literal notranslate"><span class="pre">NVPW_CounterDataBuilder_AddMetrics</span></code> for the <strong>CounterDataPrefix</strong>.</p></li>
<li><p>Generate binary configuration “images” (file format in memory):</p>
<ul>
<li><p><strong>ConfigImage</strong> from <code class="docutils literal notranslate"><span class="pre">NVPW_RawMetricsConfig_GetConfigImage</span></code></p></li>
<li><p><strong>CounterDataPrefix</strong> from <code class="docutils literal notranslate"><span class="pre">NVPW_CounterDataBuilder_GetCounterDataPrefix</span></code></p></li>
</ul>
</li>
</ul>
<p class="rubric-h4 rubric">Metric Evaluation</p>
<p>Metric Evaluation is the process of forming metrics from the counters stored in the <strong>CounterData</strong> image.</p>
<p>Refer to file <code class="docutils literal notranslate"><span class="pre">Eval.cpp</span></code> used by the <a class="reference external" href="../main/main.html#sample-userrange-profiling">userrange_profiling sample</a>.</p>
<p>The outline for configuring metrics:</p>
<ul class="simple">
<li><p>As input, take the same list of metric names as used during configuration.</p></li>
<li><p>As input, take a <strong>CounterDataImage</strong> collected on a target device.</p></li>
<li><p>We need to calculate the scratch buffer size required for the host operation and to initialize the Metric Evaluator like in the Enumeration phase.</p></li>
<li><p>Query the number of ranges collected via <code class="docutils literal notranslate"><span class="pre">NVPW_CounterData_GetNumRanges</span></code>.</p></li>
<li><p>For each metric:</p>
<ul>
<li><p>Call <code class="docutils literal notranslate"><span class="pre">NVPW_MetricsEvaluator_ConvertMetricNameToMetricEvalRequest</span></code> for creating <strong>NVPW_MetricEvalRequest</strong></p></li>
<li><p>For each range:</p>
<ul>
<li><p>Call <code class="docutils literal notranslate"><span class="pre">NVPW_Profiler_CounterData_GetRangeDescriptions</span></code> to retrieve the range’s description, originally set by <code class="docutils literal notranslate"><span class="pre">cuptiProfilerPushRange</span></code>.</p></li>
<li><p>Call <code class="docutils literal notranslate"><span class="pre">NVPW_MetricsEvaluator_SetDeviceAttributes</span></code> to set the current range for evaluation on the <strong>NVPW_MetricEvalRequest</strong>.</p></li>
<li><p>Call <code class="docutils literal notranslate"><span class="pre">NVPW_MetricsEvaluator_EvaluateToGpuValues</span></code> to query an array of numeric values corresponding to each input metric.</p></li>
</ul>
</li>
</ul>
</li>
</ul>
<section id="derived-metrics">
<span id="host-derived-metrics-api"></span><h3><span class="section-number">2.8.1. </span>Derived metrics<a class="headerlink" href="#derived-metrics" title="Permalink to this headline"></a></h3>
<p class="rubric-h3 rubric">Metrics Overview</p>
<p>The PerfWorks API comes with an advanced metrics calculation system, designed to help you determine what happened (counters and metrics), and how close the program reached to peak GPU performance (throughputs as a percentage). Every counter has associated peak rates in the database, to allow computing its throughput as a percentage.</p>
<p>Throughput metrics return the maximum percentage value of their constituent counters. Constituents can be programmatically queried via <code class="docutils literal notranslate"><span class="pre">NVPW_MetricsEvaluator_GetMetricNames</span></code> with <strong>NVPW_METRIC_TYPE_THROUGHPUT</strong> as metric types. These constituents have been carefully selected to represent the sections of the GPU pipeline that govern peak performance. While all counters can be converted to a %-of-peak, not all counters are suitable for peak-performance analysis; examples of unsuitable counters include qualified subsets of activity, and workload residency counters. Using throughput metrics ensures meaningful and actionable analysis.</p>
<p>Two types of peak rates are available for every counter: burst and sustained. Burst rate is the maximum rate reportable in a single clock cycle. Sustained rate is the maximum rate achievable over an infinitely long measurement period, for “typical” operations. For many counters, burst == sustained. Since the burst rate cannot be exceeded, percentages of burst rate will always be less than 100%. Percentages of sustained rate can occasionally exceed 100% in edge cases. Burst metrics are only supported with MetricsContext APIs and these will be deprecated in a future CUDA release. These metrics are not supported with NVPW_MetricsEvaluator APIs.</p>
<p class="rubric-h3 rubric">Metrics Entities</p>
<p>The Metrics layer has 3 major types of entities:</p>
<ul>
<li><p>Metrics : these are calculated quantities, with the following static properties:</p>
<ul>
<li><p>Description string.</p></li>
<li><p>Dimensional Units : a list of (‘name’, exponent) in the style of <a class="reference external" href="https://en.wikipedia.org/wiki/Dimensional_analysis">dimensional analysis</a>. Example string representation: <code class="docutils literal notranslate"><span class="pre">pixels</span> <span class="pre">/</span> <span class="pre">gpc_clk</span></code>.</p></li>
<li><p>Raw Metric dependencies : the list of raw metrics that must be collected, in order to evaluate the metric.</p></li>
<li><p>Every metric has the following sub-metrics built in.</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 36%" />
<col style="width: 64%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">.peak_sustained</span></code></p></td>
<td><p>the peak sustained rate</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">.peak_sustained_active</span></code></p></td>
<td><p>the peak sustained rate during unit active cycles</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">.peak_sustained_active.per_second</span></code></p></td>
<td><p>the peak sustained rate during unit active cycles, per second *</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">.peak_sustained_elapsed</span></code></p></td>
<td><p>the peak sustained rate during unit elapsed cycles</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">.peak_sustained_elapsed.per_second</span></code></p></td>
<td><p>the peak sustained rate during unit elapsed cycles, per second *</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">.peak_sustained_region</span></code></p></td>
<td><p>the peak sustained rate over a user-specified “range”</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">.peak_sustained_region.per_second</span></code></p></td>
<td><p>the peak sustained rate over a user-specified “range”, per second *</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">.peak_sustained_frame</span></code></p></td>
<td><p>the peak sustained rate over a user-specified “frame”</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">.peak_sustained_frame.per_second</span></code></p></td>
<td><p>the peak sustained rate over a user-specified “frame”, per second *</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">.per_cycle_active</span></code></p></td>
<td><p>the number of operations per unit active cycle</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">.per_cycle_elapsed</span></code></p></td>
<td><p>the number of operations per unit elapsed cycle</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">.per_cycle_in_region</span></code></p></td>
<td><p>the number of operations per user-specified “range” cycle</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">.per_cycle_in_frame</span></code></p></td>
<td><p>the number of operations per user-specified “frame” cycle</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">.per_second</span></code></p></td>
<td><p>the number of operations per second</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">.pct_of_peak_sustained_active</span></code></p></td>
<td><p>% of peak sustained rate achieved during unit active cycles</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">.pct_of_peak_sustained_elapsed</span></code></p></td>
<td><p>% of peak sustained rate achieved during unit elapsed cycles</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">.pct_of_peak_sustained_region</span></code></p></td>
<td><p>% of peak sustained rate achieved over a user-specified “range” time</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">.pct_of_peak_sustained_frame</span></code></p></td>
<td><p>% of peak sustained rate achieved over a user-specified “frame” time</p></td>
</tr>
</tbody>
</table>
<p>* sub-metrics added in CUPTI 11.3.</p>
</li>
</ul>
</li>
<li><p><strong>Counters</strong> may be either a raw counter from the GPU, or a calculated counter value. Every counter has four sub-metrics under it, which are also called <em>roll-ups</em>:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 13%" />
<col style="width: 87%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">.sum</span></code></p></td>
<td><p>The sum of counter values across all unit instances.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">.avg</span></code></p></td>
<td><p>The average counter value across all unit instances.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">.min</span></code></p></td>
<td><p>The minimum counter value across all unit instances.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">.max</span></code></p></td>
<td><p>The maximum counter value across all unit instances.</p></td>
</tr>
</tbody>
</table>
</li>
<li><p><strong>Ratios</strong> have three sub-metrics under it:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 27%" />
<col style="width: 73%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">.pct</span></code></p></td>
<td><p>The value expressed as a percentage.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">.ratio</span></code></p></td>
<td><p>The value expressed as a ratio.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">.max_rate</span></code></p></td>
<td><p>The ratio’s maximum value.</p></td>
</tr>
</tbody>
</table>
</li>
<li><p><strong>Throughputs</strong> indicate how close a portion of the GPU reached to peak rate. Every throughput has the following sub-metrics:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 34%" />
<col style="width: 66%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">.pct_of_peak_sustained_active</span></code></p></td>
<td><p>% of peak sustained rate achieved during unit active cycles</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">.pct_of_peak_sustained_elapsed</span></code></p></td>
<td><p>% of peak sustained rate achieved during unit elapsed cycles</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">.pct_of_peak_sustained_region</span></code></p></td>
<td><p>% of peak sustained rate achieved over a user-specified “range” time</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">.pct_of_peak_sustained_frame</span></code></p></td>
<td><p>% of peak sustained rate achieved over a user-specified “frame” time</p></td>
</tr>
</tbody>
</table>
</li>
</ul>
<p>At the configuration step, you must specify metric names. Counters, ratios, and throughputs are not directly schedulable.</p>
<p><strong>Note:</strong> Burst metrics are only supported with MetricsContext APIs.</p>
<p>From CUPTI 11.3 onwards, due to not being useful for performance optimization following <strong>counter</strong> sub-metrics are not present in MetricEvaluator APIs and are only supported with MetricsContext APIs:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 34%" />
<col style="width: 66%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">.peak_burst</span></code></p></td>
<td><p>the peak burst rate</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">.pct_of_peak_burst_active</span></code></p></td>
<td><p>% of peak burst rate achieved during unit active cycles</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">.pct_of_peak_burst_elapsed</span></code></p></td>
<td><p>% of peak burst rate achieved during unit elapsed cycles</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">.pct_of_peak_burst_region</span></code></p></td>
<td><p>% of peak burst rate achieved over a user-specified “range”</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">.pct_of_peak_burst_frame</span></code></p></td>
<td><p>% of peak burst rate achieved over a user-specified “frame”</p></td>
</tr>
</tbody>
</table>
<p>From CUPTI 11.3 onwards, due to not being useful for performance optimization following <strong>throughput</strong> sub-metrics are not present in MetricEvaluator APIs and are only supported with MetricsContext APIs:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 33%" />
<col style="width: 67%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">.pct_of_peak_burst_active</span></code></p></td>
<td><p>% of peak burst rate achieved during unit active cycles</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">.pct_of_peak_burst_elapsed</span></code></p></td>
<td><p>% of peak burst rate achieved during unit elapsed cycles</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">.pct_of_peak_burst_region</span></code></p></td>
<td><p>% of peak burst rate achieved over a user-specified “range” time</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">.pct_of_peak_burst_frame</span></code></p></td>
<td><p>% of peak burst rate achieved over a user-specified “frame” time</p></td>
</tr>
</tbody>
</table>
<p class="rubric-h3 rubric">Metrics Examples</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>## non-metric names -- *not* directly evaluable
sm__inst_executed                   # counter
smsp__average_warp_latency          # ratio
sm__throughput                      # throughput

## a counter&#39;s four roll-ups as sub-metrics -- all evaluable
sm__inst_executed.sum               # metric
sm__inst_executed.avg               # metric
sm__inst_executed.min               # metric
sm__inst_executed.max               # metric

## all names below are metrics -- all evaluable
l1tex__data_bank_conflicts_pipe_lsu.sum
l1tex__data_bank_conflicts_pipe_lsu.sum.peak_burst
l1tex__data_bank_conflicts_pipe_lsu.sum.peak_sustained
l1tex__data_bank_conflicts_pipe_lsu.sum.per_cycle_active
l1tex__data_bank_conflicts_pipe_lsu.sum.per_cycle_elapsed
l1tex__data_bank_conflicts_pipe_lsu.sum.per_cycle_in_region
l1tex__data_bank_conflicts_pipe_lsu.sum.per_cycle_in_frame
l1tex__data_bank_conflicts_pipe_lsu.sum.per_second
l1tex__data_bank_conflicts_pipe_lsu.sum.pct_of_peak_sustained_active
l1tex__data_bank_conflicts_pipe_lsu.sum.pct_of_peak_sustained_elapsed
l1tex__data_bank_conflicts_pipe_lsu.sum.pct_of_peak_sustained_region
l1tex__data_bank_conflicts_pipe_lsu.sum.pct_of_peak_sustained_frame
</pre></div>
</div>
<p class="rubric-h3 rubric">Metrics Naming Conventions</p>
<p>Counters and metrics _generally_ obey the naming scheme:</p>
<ul class="simple">
<li><p>Unit-Level Counter : <code class="docutils literal notranslate"><span class="pre">unit__(subunit?)_(pipestage?)_quantity_(qualifiers?)</span></code></p></li>
<li><p>Interface Counter : <code class="docutils literal notranslate"><span class="pre">unit__(subunit?)_(pipestage?)_(interface)_quantity_(qualifiers?)</span></code></p></li>
<li><p>Unit Metric : <code class="docutils literal notranslate"><span class="pre">(counter_name).(rollup_metric)</span></code></p></li>
<li><p>Sub-Metric : <code class="docutils literal notranslate"><span class="pre">(counter_name).(rollup_metric).(submetric)</span></code></p></li>
</ul>
<p>where</p>
<ul class="simple">
<li><p>unit: A logical of physical unit of the GPU</p></li>
<li><p>subunit: The subunit within the unit where the counter was measured. Sometimes this is a pipeline mode instead.</p></li>
<li><p>pipestage: The pipeline stage within the subunit where the counter was measured.</p></li>
<li><p>quantity: What is being measured. Generally matches the “dimensional units”.</p></li>
<li><p>qualifiers: Any additional predicates or filters applied to the counter. Often, an unqualified counter can be broken down into several qualified sub-components.</p></li>
<li><p>interface: Of the form <code class="docutils literal notranslate"><span class="pre">sender2receiver</span></code>, where <code class="docutils literal notranslate"><span class="pre">sender</span></code> is the source-unit and <code class="docutils literal notranslate"><span class="pre">receiver</span></code> is the destination-unit.</p></li>
<li><p>rollup_metric: One of sum,avg,min,max.</p></li>
<li><p>submetric: refer to section <a class="reference external" href="../main/main.html#host-derived-metrics-api">Metric Entities</a></p></li>
</ul>
<p>Components are not always present. Most top-level counters have no qualifiers. Subunit and pipestage may be absent where irrelevant, or there may be many subunit specifiers for detailed counters.</p>
<p class="rubric-h3 rubric">Cycle Metrics</p>
<p>Counters using the term <code class="docutils literal notranslate"><span class="pre">cycles</span></code> in the name report the number of cycles in the unit’s clock domain. Unit-level cycle metrics include:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">unit__cycles_elapsed</span></code> : The number of cycles within a range. The cycles’ DimUnits are specific to the unit’s clock domain.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">unit__cycles_active</span></code> : The number of cycles where the unit was processing data.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">unit__cycles_stalled</span></code> : The number of cycles where the unit was unable to process new data because its output interface was blocked.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">unit__cycles_idle</span></code> : The number of cycles where the unit was idle.</p></li>
</ul>
<p>Interface-level cycle counters are often (not always) available in the following variations:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">unit__(interface)_active</span></code> : Cycles where data was transferred from source-unit to destination-unit.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">unit__(interface)_stalled</span></code> : Cycles where the source-unit had data, but the destination-unit was unable to accept data.</p></li>
</ul>
</section>
<section id="raw-metrics">
<span id="host-raw-metrics-api"></span><h3><span class="section-number">2.8.2. </span>Raw Metrics<a class="headerlink" href="#raw-metrics" title="Permalink to this headline"></a></h3>
<p>The raw metrics layer contains a list of low-level GPU counters, and the “scheduling” logic needed to program the hardware. The binary output files (<strong>ConfigImage</strong> and <strong>CounterDataPrefix</strong>) can be generated offline, stored on disk, and used on any compatible GPU. They do not need to be generated on a machine where a GPU is available.</p>
<p>Refer to <a class="reference external" href="../main/main.html#perfworks-metric-api">Metrics Configuration</a> to see where Raw Metrics fit into the overall data flow of the profiler.</p>
</section>
<section id="metrics-mapping-table">
<span id="host-metrics-map-table-70"></span><h3><span class="section-number">2.8.3. </span>Metrics Mapping Table<a class="headerlink" href="#metrics-mapping-table" title="Permalink to this headline"></a></h3>
<p>The table below lists the CUPTI metrics for devices with compute capability 7.0. For each CUPTI metric the closest equivalent Perfworks metric or formula is given. If no equivalent Perfworks metric is available the column is left blank. Note that there can be some difference in the metric values between the CUPTI metric and the Perfworks metrics.</p>
<table class="table-no-stripes docutils align-default" id="id13">
<caption><span class="caption-text">Table 4. Metrics Mapping Table from CUPTI to Perfworks for Compute Capability 7.0</span><a class="headerlink" href="#id13" title="Permalink to this table"></a></caption>
<colgroup>
<col style="width: 16%" />
<col style="width: 84%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>CUPTI Metric</p></th>
<th class="head"><p>Perfworks Metric or Formula</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>achieved_occupancy</p></td>
<td><p>sm__warps_active.avg.pct_of_peak_sustained_active</p></td>
</tr>
<tr class="row-odd"><td><p>atomic_transactions</p></td>
<td><p>l1tex__t_set_accesses_pipe_lsu_mem_global_op_atom.sum + l1tex__t_set_accesses_pipe_lsu_mem_global_op_red.sum</p></td>
</tr>
<tr class="row-even"><td><p>atomic_transactions_per_request</p></td>
<td><p>(l1tex__t_sectors_pipe_lsu_mem_global_op_atom.sum + l1tex__t_sectors_pipe_lsu_mem_global_op_red.sum) / (l1tex__t_requests_pipe_lsu_mem_global_op_atom.sum + l1tex__t_requests_pipe_lsu_mem_global_op_red.sum)</p></td>
</tr>
<tr class="row-odd"><td><p>branch_efficiency</p></td>
<td><p>smsp__sass_average_branch_targets_threads_uniform.pct</p></td>
</tr>
<tr class="row-even"><td><p>cf_executed</p></td>
<td><p>smsp__inst_executed_pipe_cbu.sum + smsp__inst_executed_pipe_adu.sum</p></td>
</tr>
<tr class="row-odd"><td><p>cf_fu_utilization</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>cf_issued</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>double_precision_fu_utilization</p></td>
<td><p>smsp__inst_executed_pipe_fp64.avg.pct_of_peak_sustained_active</p></td>
</tr>
<tr class="row-even"><td><p>dram_read_bytes</p></td>
<td><p>dram__bytes_read.sum</p></td>
</tr>
<tr class="row-odd"><td><p>dram_read_throughput</p></td>
<td><p>dram__bytes_read.sum.per_second</p></td>
</tr>
<tr class="row-even"><td><p>dram_read_transactions</p></td>
<td><p>dram__sectors_read.sum</p></td>
</tr>
<tr class="row-odd"><td><p>dram_utilization</p></td>
<td><p>dram__throughput.avg.pct_of_peak_sustained_elapsed</p></td>
</tr>
<tr class="row-even"><td><p>dram_write_bytes</p></td>
<td><p>dram__bytes_write.sum</p></td>
</tr>
<tr class="row-odd"><td><p>dram_write_throughput</p></td>
<td><p>dram__bytes_write.sum.per_second</p></td>
</tr>
<tr class="row-even"><td><p>dram_write_transactions</p></td>
<td><p>dram__sectors_write.sum</p></td>
</tr>
<tr class="row-odd"><td><p>eligible_warps_per_cycle</p></td>
<td><p>smsp__warps_eligible.sum.per_cycle_active</p></td>
</tr>
<tr class="row-even"><td><p>flop_count_dp</p></td>
<td><p>smsp__sass_thread_inst_executed_op_dadd_pred_on.sum + smsp__sass_thread_inst_executed_op_dmul_pred_on.sum + smsp__sass_thread_inst_executed_op_dfma_pred_on.sum * 2</p></td>
</tr>
<tr class="row-odd"><td><p>flop_count_dp_add</p></td>
<td><p>smsp__sass_thread_inst_executed_op_dadd_pred_on.sum</p></td>
</tr>
<tr class="row-even"><td><p>flop_count_dp_fma</p></td>
<td><p>smsp__sass_thread_inst_executed_op_dfma_pred_on.sum</p></td>
</tr>
<tr class="row-odd"><td><p>flop_count_dp_mul</p></td>
<td><p>smsp__sass_thread_inst_executed_op_dmul_pred_on.sum</p></td>
</tr>
<tr class="row-even"><td><p>flop_count_hp</p></td>
<td><p>smsp__sass_thread_inst_executed_op_hadd_pred_on.sum + smsp__sass_thread_inst_executed_op_hmul_pred_on.sum + smsp__sass_thread_inst_executed_op_hfma_pred_on.sum * 2</p></td>
</tr>
<tr class="row-odd"><td><p>flop_count_hp_add</p></td>
<td><p>smsp__sass_thread_inst_executed_op_hadd_pred_on.sum</p></td>
</tr>
<tr class="row-even"><td><p>flop_count_hp_fma</p></td>
<td><p>smsp__sass_thread_inst_executed_op_hfma_pred_on.sum</p></td>
</tr>
<tr class="row-odd"><td><p>flop_count_hp_mul</p></td>
<td><p>smsp__sass_thread_inst_executed_op_hmul_pred_on.sum</p></td>
</tr>
<tr class="row-even"><td><p>flop_count_sp</p></td>
<td><p>smsp__sass_thread_inst_executed_op_fadd_pred_on.sum + smsp__sass_thread_inst_executed_op_fmul_pred_on.sum + smsp__sass_thread_inst_executed_op_ffma_pred_on.sum * 2</p></td>
</tr>
<tr class="row-odd"><td><p>flop_count_sp_add</p></td>
<td><p>smsp__sass_thread_inst_executed_op_fadd_pred_on.sum</p></td>
</tr>
<tr class="row-even"><td><p>flop_count_sp_fma</p></td>
<td><p>smsp__sass_thread_inst_executed_op_ffma_pred_on.sum</p></td>
</tr>
<tr class="row-odd"><td><p>flop_count_sp_mul</p></td>
<td><p>smsp__sass_thread_inst_executed_op_fmul_pred_on.sum</p></td>
</tr>
<tr class="row-even"><td><p>flop_count_sp_special</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>flop_dp_efficiency</p></td>
<td><p>smsp__sass_thread_inst_executed_ops_dadd_dmul_dfma_pred_on.avg.pct_of_peak_sustained_elapsed</p></td>
</tr>
<tr class="row-even"><td><p>flop_hp_efficiency</p></td>
<td><p>smsp__sass_thread_inst_executed_ops_hadd_hmul_hfma_pred_on.avg.pct_of_peak_sustained_elapsed</p></td>
</tr>
<tr class="row-odd"><td><p>flop_sp_efficiency</p></td>
<td><p>smsp__sass_thread_inst_executed_ops_fadd_fmul_ffma_pred_on.avg.pct_of_peak_sustained_elapsed</p></td>
</tr>
<tr class="row-even"><td><p>gld_efficiency</p></td>
<td><p>smsp__sass_average_data_bytes_per_sector_mem_global_op_ld.pct</p></td>
</tr>
<tr class="row-odd"><td><p>gld_requested_throughput</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>gld_throughput</p></td>
<td><p>l1tex__t_bytes_pipe_lsu_mem_global_op_ld.sum.per_second</p></td>
</tr>
<tr class="row-odd"><td><p>gld_transactions</p></td>
<td><p>l1tex__t_sectors_pipe_lsu_mem_global_op_ld.sum</p></td>
</tr>
<tr class="row-even"><td><p>gld_transactions_per_request</p></td>
<td><p>l1tex__average_t_sectors_per_request_pipe_lsu_mem_global_op_ld.ratio</p></td>
</tr>
<tr class="row-odd"><td><p>global_atomic_requests</p></td>
<td><p>l1tex__t_requests_pipe_lsu_mem_global_op_atom.sum</p></td>
</tr>
<tr class="row-even"><td><p>global_hit_rate</p></td>
<td><p>l1tex__t_sectors_pipe_lsu_mem_global_op_{op}_lookup_hit.sum / l1tex__t_sectors_pipe_lsu_mem_global_op_{op}.sum</p></td>
</tr>
<tr class="row-odd"><td><p>global_load_requests</p></td>
<td><p>l1tex__t_requests_pipe_lsu_mem_global_op_ld.sum</p></td>
</tr>
<tr class="row-even"><td><p>global_reduction_requests</p></td>
<td><p>l1tex__t_requests_pipe_lsu_mem_global_op_red.sum</p></td>
</tr>
<tr class="row-odd"><td><p>global_store_requests</p></td>
<td><p>l1tex__t_requests_pipe_lsu_mem_global_op_st.sum</p></td>
</tr>
<tr class="row-even"><td><p>gst_efficiency</p></td>
<td><p>smsp__sass_average_data_bytes_per_sector_mem_global_op_st.pct</p></td>
</tr>
<tr class="row-odd"><td><p>gst_requested_throughput</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>gst_throughput</p></td>
<td><p>l1tex__t_bytes_pipe_lsu_mem_global_op_st.sum.per_second</p></td>
</tr>
<tr class="row-odd"><td><p>gst_transactions</p></td>
<td><p>l1tex__t_bytes_pipe_lsu_mem_global_op_st.sum</p></td>
</tr>
<tr class="row-even"><td><p>gst_transactions_per_request</p></td>
<td><p>l1tex__average_t_sectors_per_request_pipe_lsu_mem_global_op_st.ratio</p></td>
</tr>
<tr class="row-odd"><td><p>half_precision_fu_utilization</p></td>
<td><p>smsp__inst_executed_pipe_fp16.avg.pct_of_peak_sustained_active</p></td>
</tr>
<tr class="row-even"><td><p>inst_bit_convert</p></td>
<td><p>smsp__sass_thread_inst_executed_op_conversion_pred_on.sum</p></td>
</tr>
<tr class="row-odd"><td><p>inst_compute_ld_st</p></td>
<td><p>smsp__sass_thread_inst_executed_op_memory_pred_on.sum</p></td>
</tr>
<tr class="row-even"><td><p>inst_control</p></td>
<td><p>smsp__sass_thread_inst_executed_op_control_pred_on.sum</p></td>
</tr>
<tr class="row-odd"><td><p>inst_executed</p></td>
<td><p>smsp__inst_executed.sum</p></td>
</tr>
<tr class="row-even"><td><p>inst_executed_global_atomics</p></td>
<td><p>smsp__sass_inst_executed_op_global_atom.sum</p></td>
</tr>
<tr class="row-odd"><td><p>inst_executed_global_loads</p></td>
<td><p>smsp__inst_executed_op_global_ld.sum</p></td>
</tr>
<tr class="row-even"><td><p>inst_executed_global_reductions</p></td>
<td><p>smsp__inst_executed_op_global_red.sum</p></td>
</tr>
<tr class="row-odd"><td><p>inst_executed_global_stores</p></td>
<td><p>smsp__inst_executed_op_global_st.sum</p></td>
</tr>
<tr class="row-even"><td><p>inst_executed_local_loads</p></td>
<td><p>smsp__inst_executed_op_local_ld.sum</p></td>
</tr>
<tr class="row-odd"><td><p>inst_executed_local_stores</p></td>
<td><p>smsp__inst_executed_op_local_st.sum</p></td>
</tr>
<tr class="row-even"><td><p>inst_executed_shared_atomics</p></td>
<td><p>smsp__inst_executed_op_shared_atom.sum + smsp__inst_executed_op_shared_atom_dot_alu.sum + smsp__inst_executed_op_shared_atom_dot_cas.sum</p></td>
</tr>
<tr class="row-odd"><td><p>inst_executed_shared_loads</p></td>
<td><p>smsp__inst_executed_op_shared_ld.sum</p></td>
</tr>
<tr class="row-even"><td><p>inst_executed_shared_stores</p></td>
<td><p>smsp__inst_executed_op_shared_st.sum</p></td>
</tr>
<tr class="row-odd"><td><p>inst_executed_surface_atomics</p></td>
<td><p>smsp__inst_executed_op_surface_atom.sum</p></td>
</tr>
<tr class="row-even"><td><p>inst_executed_surface_loads</p></td>
<td><p>smsp__inst_executed_op_surface_ld.sum + smsp__inst_executed_op_shared_atom_dot_alu.sum + smsp__inst_executed_op_shared_atom_dot_cas.sum</p></td>
</tr>
<tr class="row-odd"><td><p>inst_executed_surface_reductions</p></td>
<td><p>smsp__inst_executed_op_surface_red.sum</p></td>
</tr>
<tr class="row-even"><td><p>inst_executed_surface_stores</p></td>
<td><p>smsp__inst_executed_op_surface_st.sum</p></td>
</tr>
<tr class="row-odd"><td><p>inst_executed_tex_ops</p></td>
<td><p>smsp__inst_executed_op_texture.sum</p></td>
</tr>
<tr class="row-even"><td><p>inst_fp_16</p></td>
<td><p>smsp__sass_thread_inst_executed_op_fp16_pred_on.sum</p></td>
</tr>
<tr class="row-odd"><td><p>inst_fp_32</p></td>
<td><p>smsp__sass_thread_inst_executed_op_fp32_pred_on.sum</p></td>
</tr>
<tr class="row-even"><td><p>inst_fp_64</p></td>
<td><p>smsp__sass_thread_inst_executed_op_fp64_pred_on.sum</p></td>
</tr>
<tr class="row-odd"><td><p>inst_integer</p></td>
<td><p>smsp__sass_thread_inst_executed_op_integer_pred_on.sum</p></td>
</tr>
<tr class="row-even"><td><p>inst_inter_thread_communication</p></td>
<td><p>smsp__sass_thread_inst_executed_op_inter_thread_communication_pred_on.sum</p></td>
</tr>
<tr class="row-odd"><td><p>inst_issued</p></td>
<td><p>smsp__inst_issued.sum</p></td>
</tr>
<tr class="row-even"><td><p>inst_misc</p></td>
<td><p>smsp__sass_thread_inst_executed_op_misc_pred_on.sum</p></td>
</tr>
<tr class="row-odd"><td><p>inst_per_warp</p></td>
<td><p>smsp__average_inst_executed_per_warp.ratio</p></td>
</tr>
<tr class="row-even"><td><p>inst_replay_overhead</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>ipc</p></td>
<td><p>smsp__inst_executed.avg.per_cycle_active</p></td>
</tr>
<tr class="row-even"><td><p>issue_slot_utilization</p></td>
<td><p>smsp__issue_active.avg.pct_of_peak_sustained_active</p></td>
</tr>
<tr class="row-odd"><td><p>issue_slots</p></td>
<td><p>smsp__inst_issued.sum</p></td>
</tr>
<tr class="row-even"><td><p>issued_ipc</p></td>
<td><p>smsp__inst_issued.avg.per_cycle_active</p></td>
</tr>
<tr class="row-odd"><td><p>l2_atomic_throughput</p></td>
<td><p>lts__t_sectors_srcunit_l1_op_atom.sum.per_second</p></td>
</tr>
<tr class="row-even"><td><p>l2_atomic_transactions</p></td>
<td><p>lts__t_sectors_srcunit_l1_op_atom.sum</p></td>
</tr>
<tr class="row-odd"><td><p>l2_global_atomic_store_bytes</p></td>
<td><p>lts__t_bytes_equiv_l1sectormiss_pipe_lsu_mem_global_op_atom.sum</p></td>
</tr>
<tr class="row-even"><td><p>l2_global_load_bytes</p></td>
<td><p>lts__t_bytes_equiv_l1sectormiss_pipe_lsu_mem_global_op_ld.sum</p></td>
</tr>
<tr class="row-odd"><td><p>l2_local_global_store_bytes</p></td>
<td><p>lts__t_bytes_equiv_l1sectormiss_pipe_lsu_mem_local_op_st.sum + lts__t_bytes_equiv_l1sectormiss_pipe_lsu_mem_global_op_st.sum</p></td>
</tr>
<tr class="row-even"><td><p>l2_local_load_bytes</p></td>
<td><p>lts__t_bytes_equiv_l1sectormiss_pipe_lsu_mem_local_op_ld.sum</p></td>
</tr>
<tr class="row-odd"><td><p>l2_read_throughput</p></td>
<td><p>lts__t_sectors_op_read.sum.per_second</p></td>
</tr>
<tr class="row-even"><td><p>l2_read_transactions</p></td>
<td><p>lts__t_sectors_op_read.sum</p></td>
</tr>
<tr class="row-odd"><td><p>l2_surface_load_bytes</p></td>
<td><p>lts__t_bytes_equiv_l1sectormiss_pipe_tex_mem_surface_op_ld.sum</p></td>
</tr>
<tr class="row-even"><td><p>l2_surface_store_bytes</p></td>
<td><p>lts__t_bytes_equiv_l1sectormiss_pipe_tex_mem_surface_op_st.sum</p></td>
</tr>
<tr class="row-odd"><td><p>l2_tex_hit_rate</p></td>
<td><p>lts__t_sector_hit_rate.pct</p></td>
</tr>
<tr class="row-even"><td><p>l2_tex_read_hit_rate</p></td>
<td><p>lts__t_sector_op_read_hit_rate.pct</p></td>
</tr>
<tr class="row-odd"><td><p>l2_tex_read_throughput</p></td>
<td><p>lts__t_sectors_srcunit_tex_op_read.sum.per_second</p></td>
</tr>
<tr class="row-even"><td><p>l2_tex_read_transactions</p></td>
<td><p>lts__t_sectors_srcunit_tex_op_read.sum</p></td>
</tr>
<tr class="row-odd"><td><p>l2_tex_write_hit_rate</p></td>
<td><p>lts__t_sector_op_write_hit_rate.pct</p></td>
</tr>
<tr class="row-even"><td><p>l2_tex_write_throughput</p></td>
<td><p>lts__t_sectors_srcunit_tex_op_read.sum.per_second</p></td>
</tr>
<tr class="row-odd"><td><p>l2_tex_write_transactions</p></td>
<td><p>lts__t_sectors_srcunit_tex_op_read.sum</p></td>
</tr>
<tr class="row-even"><td><p>l2_utilization</p></td>
<td><p>lts__t_sectors.avg.pct_of_peak_sustained_elapsed</p></td>
</tr>
<tr class="row-odd"><td><p>l2_write_throughput</p></td>
<td><p>lts__t_sectors_op_write.sum.per_second</p></td>
</tr>
<tr class="row-even"><td><p>l2_write_transactions</p></td>
<td><p>lts__t_sectors_op_write.sum</p></td>
</tr>
<tr class="row-odd"><td><p>ldst_executed</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>ldst_fu_utilization</p></td>
<td><p>smsp__inst_executed_pipe_lsu.avg.pct_of_peak_sustained_active</p></td>
</tr>
<tr class="row-odd"><td><p>ldst_issued</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>local_hit_rate</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>local_load_requests</p></td>
<td><p>l1tex__t_requests_pipe_lsu_mem_local_op_ld.sum</p></td>
</tr>
<tr class="row-even"><td><p>local_load_throughput</p></td>
<td><p>l1tex__t_bytes_pipe_lsu_mem_local_op_ld.sum.per_second</p></td>
</tr>
<tr class="row-odd"><td><p>local_load_transactions</p></td>
<td><p>l1tex__t_sectors_pipe_lsu_mem_local_op_ld.sum</p></td>
</tr>
<tr class="row-even"><td><p>local_load_transactions_per_request</p></td>
<td><p>l1tex__average_t_sectors_per_request_pipe_lsu_mem_local_op_ld.ratio</p></td>
</tr>
<tr class="row-odd"><td><p>local_memory_overhead</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>local_store_requests</p></td>
<td><p>l1tex__t_requests_pipe_lsu_mem_local_op_st.sum</p></td>
</tr>
<tr class="row-odd"><td><p>local_store_throughput</p></td>
<td><p>l1tex__t_sectors_pipe_lsu_mem_local_op_st.sum.per_second</p></td>
</tr>
<tr class="row-even"><td><p>local_store_transactions</p></td>
<td><p>l1tex__t_sectors_pipe_lsu_mem_local_op_st.sum</p></td>
</tr>
<tr class="row-odd"><td><p>local_store_transactions_per_request</p></td>
<td><p>l1tex__average_t_sectors_per_request_pipe_lsu_mem_local_op_st.ratio</p></td>
</tr>
<tr class="row-even"><td><p>nvlink_data_receive_efficiency</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>nvlink_data_transmission_efficiency</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>nvlink_overhead_data_received</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>nvlink_overhead_data_transmitted</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>nvlink_receive_throughput</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>nvlink_total_data_received</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>nvlink_total_data_transmitted</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>nvlink_total_nratom_data_transmitted</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>nvlink_total_ratom_data_transmitted</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>nvlink_total_response_data_received</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>nvlink_total_write_data_transmitted</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>nvlink_transmit_throughput</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>nvlink_user_data_received</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>nvlink_user_data_transmitted</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>nvlink_user_nratom_data_transmitted</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>nvlink_user_ratom_data_transmitted</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>nvlink_user_response_data_received</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>nvlink_user_write_data_transmitted</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>pcie_total_data_received</p></td>
<td><p>pcie__read_bytes.sum</p></td>
</tr>
<tr class="row-odd"><td><p>pcie_total_data_transmitted</p></td>
<td><p>pcie__write_bytes.sum</p></td>
</tr>
<tr class="row-even"><td><p>shared_efficiency</p></td>
<td><p>smsp__sass_average_data_bytes_per_wavefront_mem_shared.pct</p></td>
</tr>
<tr class="row-odd"><td><p>shared_load_throughput</p></td>
<td><p>l1tex__data_pipe_lsu_wavefronts_mem_shared_op_ld.sum.per_second</p></td>
</tr>
<tr class="row-even"><td><p>shared_load_transactions</p></td>
<td><p>l1tex__data_pipe_lsu_wavefronts_mem_shared_op_ld.sum</p></td>
</tr>
<tr class="row-odd"><td><p>shared_load_transactions_per_request</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>shared_store_throughput</p></td>
<td><p>l1tex__data_pipe_lsu_wavefronts_mem_shared_op_st.sum.per_second</p></td>
</tr>
<tr class="row-odd"><td><p>shared_store_transactions</p></td>
<td><p>l1tex__data_pipe_lsu_wavefronts_mem_shared_op_st.sum</p></td>
</tr>
<tr class="row-even"><td><p>shared_store_transactions_per_request</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>shared_utilization</p></td>
<td><p>l1tex__data_pipe_lsu_wavefronts_mem_shared.avg.pct_of_peak_sustained_elapsed</p></td>
</tr>
<tr class="row-even"><td><p>single_precision_fu_utilization</p></td>
<td><p>smsp__pipe_fma_cycles_active.avg.pct_of_peak_sustained_active</p></td>
</tr>
<tr class="row-odd"><td><p>sm_efficiency</p></td>
<td><p>smsp__cycles_active.avg.pct_of_peak_sustained_elapsed</p></td>
</tr>
<tr class="row-even"><td><p>sm_tex_utilization</p></td>
<td><p>l1tex__texin_sm2tex_req_cycles_active.avg.pct_of_peak_sustained_elapsed</p></td>
</tr>
<tr class="row-odd"><td><p>special_fu_utilization</p></td>
<td><p>smsp__inst_executed_pipe_xu.avg.pct_of_peak_sustained_active</p></td>
</tr>
<tr class="row-even"><td><p>stall_constant_memory_dependency</p></td>
<td><p>smsp__warp_issue_stalled_imc_miss_per_warp_active.pct</p></td>
</tr>
<tr class="row-odd"><td><p>stall_exec_dependency</p></td>
<td><p>smsp__warp_issue_stalled_short_scoreboard_per_warp_active.pct + smsp__warp_issue_stalled_wait_per_warp_active.pct</p></td>
</tr>
<tr class="row-even"><td><p>stall_inst_fetch</p></td>
<td><p>smsp__warp_issue_stalled_no_instruction_per_warp_active.pct</p></td>
</tr>
<tr class="row-odd"><td><p>stall_memory_dependency</p></td>
<td><p>smsp__warp_issue_stalled_long_scoreboard_per_warp_active.pct</p></td>
</tr>
<tr class="row-even"><td><p>stall_memory_throttle</p></td>
<td><p>smsp__warp_issue_stalled_drain_per_warp_active.pct + smsp__warp_issue_stalled_lg_throttle_per_warp_active.pct</p></td>
</tr>
<tr class="row-odd"><td><p>stall_not_selected</p></td>
<td><p>smsp__warp_issue_stalled_not_selected_per_warp_active.pct</p></td>
</tr>
<tr class="row-even"><td><p>stall_other</p></td>
<td><p>smsp__warp_issue_stalled_misc_per_warp_active.pct + smsp__warp_issue_stalled_dispatch_stall_per_warp_active.pct</p></td>
</tr>
<tr class="row-odd"><td><p>stall_pipe_busy</p></td>
<td><p>smsp__warp_issue_stalled_mio_throttle_per_warp_active.pct + smsp__warp_issue_stalled_math_pipe_throttle_per_warp_active.pct</p></td>
</tr>
<tr class="row-even"><td><p>stall_sleeping</p></td>
<td><p>smsp__warp_issue_stalled_sleeping_per_warp_active.pct</p></td>
</tr>
<tr class="row-odd"><td><p>stall_sync</p></td>
<td><p>smsp__warp_issue_stalled_membar_per_warp_active.pct + smsp__warp_issue_stalled_barrier_per_warp_active.pct</p></td>
</tr>
<tr class="row-even"><td><p>stall_texture</p></td>
<td><p>smsp__warp_issue_stalled_tex_throttle_per_warp_active.pct</p></td>
</tr>
<tr class="row-odd"><td><p>surface_atomic_requests</p></td>
<td><p>l1tex__t_requests_pipe_tex_mem_surface_op_atom.sum</p></td>
</tr>
<tr class="row-even"><td><p>surface_load_requests</p></td>
<td><p>l1tex__t_requests_pipe_tex_mem_surface_op_ld.sum</p></td>
</tr>
<tr class="row-odd"><td><p>surface_reduction_requests</p></td>
<td><p>l1tex__t_requests_pipe_tex_mem_surface_op_red.sum</p></td>
</tr>
<tr class="row-even"><td><p>surface_store_requests</p></td>
<td><p>l1tex__t_requests_pipe_tex_mem_surface_op_st.sum</p></td>
</tr>
<tr class="row-odd"><td><p>sysmem_read_bytes</p></td>
<td><p>lts__t_sectors_aperture_sysmem_op_read* 32</p></td>
</tr>
<tr class="row-even"><td><p>sysmem_read_throughput</p></td>
<td><p>lts__t_sectors_aperture_sysmem_op_read.sum.per_second</p></td>
</tr>
<tr class="row-odd"><td><p>sysmem_read_transactions</p></td>
<td><p>lts__t_sectors_aperture_sysmem_op_read.sum</p></td>
</tr>
<tr class="row-even"><td><p>sysmem_read_utilization</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>sysmem_utilization</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>sysmem_write_bytes</p></td>
<td><p>lts__t_sectors_aperture_sysmem_op_write * 32</p></td>
</tr>
<tr class="row-odd"><td><p>sysmem_write_throughput</p></td>
<td><p>lts__t_sectors_aperture_sysmem_op_write.sum.per_second</p></td>
</tr>
<tr class="row-even"><td><p>sysmem_write_transactions</p></td>
<td><p>lts__t_sectors_aperture_sysmem_op_write.sum</p></td>
</tr>
<tr class="row-odd"><td><p>sysmem_write_utilization</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>tensor_precision_fu_utilization</p></td>
<td><p>sm__pipe_tensor_cycles_active.avg.pct_of_peak_sustained_active</p></td>
</tr>
<tr class="row-odd"><td><p>tex_cache_hit_rate</p></td>
<td><p>l1tex__t_sector_hit_rate.pct</p></td>
</tr>
<tr class="row-even"><td><p>tex_cache_throughput</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>tex_cache_transactions</p></td>
<td><p>l1tex__lsu_writeback_active.avg.pct_of_peak_sustained_active + l1tex__tex_writeback_active.avg.pct_of_peak_sustained_active</p></td>
</tr>
<tr class="row-even"><td><p>tex_fu_utilization</p></td>
<td><p>smsp__inst_executed_pipe_tex.avg.pct_of_peak_sustained_active</p></td>
</tr>
<tr class="row-odd"><td><p>tex_sm_tex_utilization</p></td>
<td><p>l1tex__f_tex2sm_cycles_active.avg.pct_of_peak_sustained_elapsed</p></td>
</tr>
<tr class="row-even"><td><p>tex_sm_utilization</p></td>
<td><p>sm__mio2rf_writeback_active.avg.pct_of_peak_sustained_elapsed</p></td>
</tr>
<tr class="row-odd"><td><p>tex_utilization</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>texture_load_requests</p></td>
<td><p>l1tex__t_requests_pipe_tex_mem_texture.sum</p></td>
</tr>
<tr class="row-odd"><td><p>warp_execution_efficiency</p></td>
<td><p>smsp__thread_inst_executed_per_inst_executed.ratio</p></td>
</tr>
<tr class="row-even"><td><p>warp_nonpred_execution_efficiency</p></td>
<td><p>smsp__thread_inst_executed_per_inst_executed.pct</p></td>
</tr>
</tbody>
</table>
</section>
<section id="events-mapping-table">
<span id="host-events-map-table-70"></span><h3><span class="section-number">2.8.4. </span>Events Mapping Table<a class="headerlink" href="#events-mapping-table" title="Permalink to this headline"></a></h3>
<p>The table below lists the CUPTI events for devices with compute capability 7.0. For each CUPTI event the closest equivalent Perfworks metric or formula is given. If no equivalent Perfworks metric is available the column is left blank. Note that there can be some difference in the values between the CUPTI event and the Perfworks metrics.</p>
<table class="table-no-stripes docutils align-default" id="id14">
<caption><span class="caption-text">Table 5. Events Mapping Table from CUPTI events to Perfworks metrics for Compute Capability 7.0</span><a class="headerlink" href="#id14" title="Permalink to this table"></a></caption>
<colgroup>
<col style="width: 32%" />
<col style="width: 68%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>CUPTI Event</p></th>
<th class="head"><p>Perfworks Metric or Formula</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>active_cycles</p></td>
<td><p>sm__cycles_active.sum</p></td>
</tr>
<tr class="row-odd"><td><p>active_cycles_pm</p></td>
<td><p>sm__cycles_active.sum</p></td>
</tr>
<tr class="row-even"><td><p>active_cycles_sys</p></td>
<td><p>sys__cycles_active.sum</p></td>
</tr>
<tr class="row-odd"><td><p>active_warps</p></td>
<td><p>sm__warps_active.sum</p></td>
</tr>
<tr class="row-even"><td><p>active_warps_pm</p></td>
<td><p>sm__warps_active.sum</p></td>
</tr>
<tr class="row-odd"><td><p>atom_count</p></td>
<td><p>smsp__inst_executed_op_generic_atom_dot_alu.sum</p></td>
</tr>
<tr class="row-even"><td><p>elapsed_cycles_pm</p></td>
<td><p>sm__cycles_elapsed.sum</p></td>
</tr>
<tr class="row-odd"><td><p>elapsed_cycles_sm</p></td>
<td><p>sm__cycles_elapsed.sum</p></td>
</tr>
<tr class="row-even"><td><p>elapsed_cycles_sys</p></td>
<td><p>sys__cycles_elapsed.sum</p></td>
</tr>
<tr class="row-odd"><td><p>fb_subp0_read_sectors</p></td>
<td><p>dram__sectors_read.sum</p></td>
</tr>
<tr class="row-even"><td><p>fb_subp1_read_sectors</p></td>
<td><p>dram__sectors_read.sum</p></td>
</tr>
<tr class="row-odd"><td><p>fb_subp0_write_sectors</p></td>
<td><p>dram__sectors_write.sum</p></td>
</tr>
<tr class="row-even"><td><p>fb_subp1_write_sectors</p></td>
<td><p>dram__sectors_write.sum</p></td>
</tr>
<tr class="row-odd"><td><p>global_atom_cas</p></td>
<td><p>smsp__inst_executed_op_generic_atom_dot_cas.sum</p></td>
</tr>
<tr class="row-even"><td><p>gred_count</p></td>
<td><p>smsp__inst_executed_op_global_red.sum</p></td>
</tr>
<tr class="row-odd"><td><p>inst_executed</p></td>
<td><p>sm__inst_executed.sum</p></td>
</tr>
<tr class="row-even"><td><p>inst_executed_fma_pipe_s0</p></td>
<td><p>smsp__inst_executed_pipe_fma.sum</p></td>
</tr>
<tr class="row-odd"><td><p>inst_executed_fma_pipe_s1</p></td>
<td><p>smsp__inst_executed_pipe_fma.sum</p></td>
</tr>
<tr class="row-even"><td><p>inst_executed_fma_pipe_s2</p></td>
<td><p>smsp__inst_executed_pipe_fma.sum</p></td>
</tr>
<tr class="row-odd"><td><p>inst_executed_fma_pipe_s3</p></td>
<td><p>smsp__inst_executed_pipe_fma.sum</p></td>
</tr>
<tr class="row-even"><td><p>inst_executed_fp16_pipe_s0</p></td>
<td><p>smsp__inst_executed_pipe_fp16.sum</p></td>
</tr>
<tr class="row-odd"><td><p>inst_executed_fp16_pipe_s1</p></td>
<td><p>smsp__inst_executed_pipe_fp16.sum</p></td>
</tr>
<tr class="row-even"><td><p>inst_executed_fp16_pipe_s2</p></td>
<td><p>smsp__inst_executed_pipe_fp16.sum</p></td>
</tr>
<tr class="row-odd"><td><p>inst_executed_fp16_pipe_s3</p></td>
<td><p>smsp__inst_executed_pipe_fp16.sum</p></td>
</tr>
<tr class="row-even"><td><p>inst_executed_fp64_pipe_s0</p></td>
<td><p>smsp__inst_executed_pipe_fp64.sum</p></td>
</tr>
<tr class="row-odd"><td><p>inst_executed_fp64_pipe_s1</p></td>
<td><p>smsp__inst_executed_pipe_fp64.sum</p></td>
</tr>
<tr class="row-even"><td><p>inst_executed_fp64_pipe_s2</p></td>
<td><p>smsp__inst_executed_pipe_fp64.sum</p></td>
</tr>
<tr class="row-odd"><td><p>inst_executed_fp64_pipe_s3</p></td>
<td><p>smsp__inst_executed_pipe_fp64.sum</p></td>
</tr>
<tr class="row-even"><td><p>inst_issued1</p></td>
<td><p>sm__inst_issued.sum</p></td>
</tr>
<tr class="row-odd"><td><p>l2_subp0_read_sector_misses</p></td>
<td><p>lts__t_sectors_op_read_lookup_miss.sum</p></td>
</tr>
<tr class="row-even"><td><p>l2_subp1_read_sector_misses</p></td>
<td><p>lts__t_sectors_op_read_lookup_miss.sum</p></td>
</tr>
<tr class="row-odd"><td><p>l2_subp0_read_sysmem_sector_queries</p></td>
<td><p>lts__t_sectors_aperture_sysmem_op_read.sum</p></td>
</tr>
<tr class="row-even"><td><p>l2_subp1_read_sysmem_sector_queries</p></td>
<td><p>lts__t_sectors_aperture_sysmem_op_read.sum</p></td>
</tr>
<tr class="row-odd"><td><p>l2_subp0_read_tex_hit_sectors</p></td>
<td><p>lts__t_sectors_srcunit_tex_op_read_lookup_hit.sum</p></td>
</tr>
<tr class="row-even"><td><p>l2_subp1_read_tex_hit_sectors</p></td>
<td><p>lts__t_sectors_srcunit_tex_op_read_lookup_hit.sum</p></td>
</tr>
<tr class="row-odd"><td><p>l2_subp0_read_tex_sector_queries</p></td>
<td><p>lts__t_sectors_srcunit_tex_op_read.sum</p></td>
</tr>
<tr class="row-even"><td><p>l2_subp1_read_tex_sector_queries</p></td>
<td><p>lts__t_sectors_srcunit_tex_op_read.sum</p></td>
</tr>
<tr class="row-odd"><td><p>l2_subp0_total_read_sector_queries</p></td>
<td><p>lts__t_sectors_op_read.sum + lts__t_sectors_op_atom.sum + lts__t_sectors_op_red.sum</p></td>
</tr>
<tr class="row-even"><td><p>l2_subp1_total_read_sector_queries</p></td>
<td><p>lts__t_sectors_op_read.sum + lts__t_sectors_op_atom.sum + lts__t_sectors_op_red.sum</p></td>
</tr>
<tr class="row-odd"><td><p>l2_subp0_total_write_sector_queries</p></td>
<td><p>lts__t_sectors_op_write.sum + lts__t_sectors_op_atom.sum + lts__t_sectors_op_red.sum</p></td>
</tr>
<tr class="row-even"><td><p>l2_subp1_total_write_sector_queries</p></td>
<td><p>lts__t_sectors_op_write.sum + lts__t_sectors_op_atom.sum + lts__t_sectors_op_red.sum</p></td>
</tr>
<tr class="row-odd"><td><p>l2_subp0_write_sector_misses</p></td>
<td><p>lts__t_sectors_op_write_lookup_miss.sum</p></td>
</tr>
<tr class="row-even"><td><p>l2_subp1_write_sector_misses</p></td>
<td><p>lts__t_sectors_op_write_lookup_miss.sum</p></td>
</tr>
<tr class="row-odd"><td><p>l2_subp0_write_sysmem_sector_queries</p></td>
<td><p>lts__t_sectors_aperture_sysmem_op_write.sum</p></td>
</tr>
<tr class="row-even"><td><p>l2_subp1_write_sysmem_sector_queries</p></td>
<td><p>lts__t_sectors_aperture_sysmem_op_write.sum</p></td>
</tr>
<tr class="row-odd"><td><p>l2_subp0_write_tex_hit_sectors</p></td>
<td><p>lts__t_sectors_srcunit_tex_op_write_lookup_hit.sum</p></td>
</tr>
<tr class="row-even"><td><p>l2_subp1_write_tex_hit_sectors</p></td>
<td><p>lts__t_sectors_srcunit_tex_op_write_lookup_hit.sum</p></td>
</tr>
<tr class="row-odd"><td><p>l2_subp0_write_tex_sector_queries</p></td>
<td><p>lts__t_sectors_srcunit_tex_op_write.sum</p></td>
</tr>
<tr class="row-even"><td><p>l2_subp1_write_tex_sector_queries</p></td>
<td><p>lts__t_sectors_srcunit_tex_op_write.sum</p></td>
</tr>
<tr class="row-odd"><td><p>not_predicated_off_thread_inst_executed</p></td>
<td><p>smsp__thread_inst_executed_pred_on.sum</p></td>
</tr>
<tr class="row-even"><td><p>pcie_rx_active_pulse</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>pcie_tx_active_pulse</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>prof_trigger_00</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>prof_trigger_01</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>prof_trigger_02</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>prof_trigger_03</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>prof_trigger_04</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>prof_trigger_05</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>prof_trigger_06</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>prof_trigger_07</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>inst_issued0</p></td>
<td><p>smsp__issue_inst0.sum</p></td>
</tr>
<tr class="row-odd"><td><p>sm_cta_launched</p></td>
<td><p>sm__ctas_launched.sum</p></td>
</tr>
<tr class="row-even"><td><p>shared_load</p></td>
<td><p>smsp__inst_executed_op_shared_ld.sum</p></td>
</tr>
<tr class="row-odd"><td><p>shared_store</p></td>
<td><p>smsp__inst_executed_op_shared_st.sum</p></td>
</tr>
<tr class="row-even"><td><p>generic_load</p></td>
<td><p>smsp__inst_executed_op_generic_ld.sum</p></td>
</tr>
<tr class="row-odd"><td><p>generic_store</p></td>
<td><p>smsp__inst_executed_op_generic_st.sum</p></td>
</tr>
<tr class="row-even"><td><p>global_load</p></td>
<td><p>smsp__inst_executed_op_global_ld.sum</p></td>
</tr>
<tr class="row-odd"><td><p>global_store</p></td>
<td><p>smsp__inst_executed_op_global_st.sum</p></td>
</tr>
<tr class="row-even"><td><p>local_load</p></td>
<td><p>smsp__inst_executed_op_local_ld.sum</p></td>
</tr>
<tr class="row-odd"><td><p>local_store</p></td>
<td><p>smsp__inst_executed_op_local_st.sum</p></td>
</tr>
<tr class="row-even"><td><p>shared_atom</p></td>
<td><p>smsp__inst_executed_op_shared_atom.sum</p></td>
</tr>
<tr class="row-odd"><td><p>shared_atom_cas</p></td>
<td><p>smsp__inst_executed_op_shared_atom_dot_cas.sum</p></td>
</tr>
<tr class="row-even"><td><p>shared_ld_bank_conflict</p></td>
<td><p>l1tex__data_bank_conflicts_pipe_lsu_mem_shared_op_ld.sum</p></td>
</tr>
<tr class="row-odd"><td><p>shared_st_bank_conflict</p></td>
<td><p>l1tex__data_bank_conflicts_pipe_lsu_mem_shared_op_st.sum</p></td>
</tr>
<tr class="row-even"><td><p>shared_ld_transactions</p></td>
<td><p>l1tex__data_pipe_lsu_wavefronts_mem_shared_op_ld.sum</p></td>
</tr>
<tr class="row-odd"><td><p>shared_st_transactions</p></td>
<td><p>l1tex__data_pipe_lsu_wavefronts_mem_shared_op_st.sum</p></td>
</tr>
<tr class="row-even"><td><p>tensor_pipe_active_cycles_s0</p></td>
<td><p>smsp__pipe_tensor_cycles_active.sum</p></td>
</tr>
<tr class="row-odd"><td><p>tensor_pipe_active_cycles_s1</p></td>
<td><p>smsp__pipe_tensor_cycles_active.sum</p></td>
</tr>
<tr class="row-even"><td><p>tensor_pipe_active_cycles_s2</p></td>
<td><p>smsp__pipe_tensor_cycles_active.sum</p></td>
</tr>
<tr class="row-odd"><td><p>tensor_pipe_active_cycles_s3</p></td>
<td><p>smsp__pipe_tensor_cycles_active.sum</p></td>
</tr>
<tr class="row-even"><td><p>thread_inst_executed</p></td>
<td><p>smsp__thread_inst_executed.sum</p></td>
</tr>
<tr class="row-odd"><td><p>warps_launched</p></td>
<td><p>smsp__warps_launched.sum</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="migration-to-the-profiling-api">
<span id="profiling-migration"></span><h2><span class="section-number">2.9. </span>Migration to the Profiling API<a class="headerlink" href="#migration-to-the-profiling-api" title="Permalink to this headline"></a></h2>
<p>The CUPTI <a class="reference external" href="../main/main.html#cupti-event-api">event APIs</a> from the header <code class="docutils literal notranslate"><span class="pre">cupti_events.h</span></code> and <a class="reference external" href="../main/main.html#cupti-metric-api">metric APIs</a> from the header <code class="docutils literal notranslate"><span class="pre">cupti_metrics.h</span></code> will be deprecated in a future CUDA release. The NVIDIA Volta platform is the last architecture on which these APIs are supported. These are being replaced by the <a class="reference external" href="../main/main.html#cupti-profiling-api">Profiling API</a> in the header <code class="docutils literal notranslate"><span class="pre">cupti_profiler_target.h</span></code> and <a class="reference external" href="../main/main.html#perfworks-metric-api">Perfworks Metric API</a> in the headers <code class="docutils literal notranslate"><span class="pre">nvperf_host.h</span></code> and <code class="docutils literal notranslate"><span class="pre">nvperf_target.h</span></code>. These provide low and deterministic profiling overhead on the target system. These APIs also have other significant enhancements such as:</p>
<ul class="simple">
<li><p><a class="reference external" href="../main/main.html#range-profiling">Range Profiling</a></p></li>
<li><p>Improved metrics</p></li>
<li><p>Lower overhead for PC Sampling</p></li>
</ul>
<p>GPU architectures supported by different CUPTI APIs are listed at the <a class="reference external" href="../release-notes/release-topic.html#gpu-support">table</a>. Both the event and metric APIs and the profiling APIs are supported for Volta. This is to enable transition of code to the profiling APIs. But one cannot mix the usage of the event and metric APIs and the profiling APIs.</p>
<p>The Profiling APIs are supported on all CUDA supported platforms except Android.</p>
<p>It is important to note that for support of future GPU architectures and feature improvements (such as performance overhead reduction and additional performance metrics), users should use the Profiling APIs. There are few features which are not supported by Profiling APIs, refer to the section for <a class="reference external" href="../main/main.html#differences-from-event-and-metric-apis">differences from event and metric APIs</a>.</p>
<p>However note that there are no changes to the CUPTI Activity and Callback APIs and these will continue to be supported for the current and future GPU architectures.</p>
</section>
<section id="cupti-pc-sampling-api">
<span id="pc-sampling-api"></span><h2><span class="section-number">2.10. </span>CUPTI PC Sampling API<a class="headerlink" href="#cupti-pc-sampling-api" title="Permalink to this headline"></a></h2>
<p>A new set of CUPTI APIs for PC sampling data collection are provided in the header file <code class="docutils literal notranslate"><span class="pre">cupti_pcsampling.h</span></code> which support continuous mode data collection without serializing kernel execution and have a lower runtime overhead. Along with these a utility library is provided in the header file <code class="docutils literal notranslate"><span class="pre">cupti_pcsampling_util.h</span></code> which has APIs for GPU assembly to CUDA-C source correlation and for reading and writing the PC sampling data from/to files.</p>
<p>The PC Sampling APIs are supported on all CUDA supported platforms. These are supported on Volta and later GPU architectures, i.e. devices with compute capability 7.0 and higher.</p>
<p>Overview of Features:</p>
<ul class="simple">
<li><p>Two sampling modes – Continuous (concurrent kernels) or Serialized (one kernel at a time)​.</p></li>
<li><p>Option to select stall reasons to collect.​</p></li>
<li><p>Ability to collect GPU PC sampling data for entire application duration or for specific CPU code ranges (defined by start and stop APIs).​</p></li>
<li><p>API to flush GPU PC sampling data.​</p></li>
<li><p>APIs to support Offline and Runtime correlation of GPU PC samples to CUDA C source lines and GPU assembly instructions​.</p></li>
</ul>
<p>Samples are provided to demonstrate how to write the injection library to collect the PC sampling information, and how to parse the generated files using the utility APIs to print the stall reasons counter values and associate those with the GPU assembly instructions and CUDA-C source code. Refer to the samples <a class="reference external" href="../main/main.html#sample-pc-sampling-continuous">pc_sampling_continuous</a>, <a class="reference external" href="../main/main.html#sample-pc-sampling-utility">pc_sampling_utility</a> and <a class="reference external" href="../main/main.html#sample-pc-sampling-start-stop">pc_sampling_start_stop</a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>PC Sampling APIs from the header <code class="docutils literal notranslate"><span class="pre">cupti_activity.h</span></code> would be referred as <em>PC Sampling Activity APIs</em> and APIs from the header <code class="docutils literal notranslate"><span class="pre">cupti_pcsampling.h</span></code> would be referred as <em>PC Sampling APIs</em>.</p>
</div>
<section id="configuration-attributes">
<span id="pc-sampling-api-config-attrib"></span><h3><span class="section-number">2.10.1. </span>Configuration Attributes<a class="headerlink" href="#configuration-attributes" title="Permalink to this headline"></a></h3>
<p>The following table lists the PC sampling configuration attributes which can be set using the <code class="docutils literal notranslate"><span class="pre">cuptiPCSamplingSetConfigurationAttribute()</span></code> API.</p>
<table class="table-no-stripes docutils align-default" id="id15">
<caption><span class="caption-text">Table 6. PC Sampling Configuration Attributes</span><a class="headerlink" href="#id15" title="Permalink to this table"></a></caption>
<colgroup>
<col style="width: 4%" />
<col style="width: 25%" />
<col style="width: 11%" />
<col style="width: 23%" />
<col style="width: 37%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Configuration Attribute</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Default Value</p></th>
<th class="head"><p>Comparison of PC Sampling APIs with CUPTI PC Sampling Activity APIs</p></th>
<th class="head"><p>Guideline to Tune Configuration Option</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Collection mode</p></td>
<td><p>PC Sampling collection mode - Continuous or Kernel Serialized</p></td>
<td><p>Continuous</p></td>
<td><p>Continuous mode is new.</p>
<p>Kernel Serialized mode is equivalent to the kernel level functionality provided by the CUPTI PC sampling Activity APIs.</p>
</td>
<td></td>
</tr>
<tr class="row-odd"><td><p>Sampling period</p></td>
<td><p>Sampling period for PC Sampling. Valid values for the sampling periods are between 5 to 31 both inclusive. This will set the sampling period to (2^samplingPeriod) cycles.</p>
<p>e.g. for sampling period = 5 to 31, cycles = 32, 64, 128,…, 2^31</p>
</td>
<td><p>CUPTI defined value is based on number of SMs</p></td>
<td><p>Dropped current support for 5 levels(MIN, LOW, MID, HIGH, MAX) for sampling period.</p>
<p>The new “sampling period” is equivalent to the “samplingPeriod2” field in CUpti_ActivityPCSamplingConfig.</p>
</td>
<td><p>Low sampling period means a high sampling frequency which can result in dropping of samples. Very high sampling period can cause low sampling frequency and no sample generation.</p></td>
</tr>
<tr class="row-even"><td><p>Stall reason</p></td>
<td><p>Stall reasons to collect</p>
<p>Input is a pointer to an array of the stall reason indexes to collect.</p>
</td>
<td><p>All stall reasons will be collected</p></td>
<td><p>With the CUPTI PC sampling Activity APIs there is no option to select which stall reasons to collect. Also the list of supported stall reasons has changed.</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>Scratch buffer size</p></td>
<td><p>Size of SW buffer for raw PC counter data downloaded from HW buffer.</p>
<p>Approximately it takes 16 Bytes (and some fixed size memory) to accommodate one PC with one stall reason</p>
<p>e.g. 1 PC with 1 stall reason = 32 Bytes</p>
<p>1 PC with 2 stall reason = 48 Bytes</p>
<p>1 PC with 4 stall reason = 96 Bytes</p>
</td>
<td><p>1 MB</p>
<p>(which can accommodate approximately 5500 PCs with all stall reasons)</p>
</td>
<td><p>New</p></td>
<td><p>Clients can choose scratch buffer size as per memory budget. Very small scratch buffer size can cause runtime overhead as more iterations would be required to accommodate and process more PC samples</p></td>
</tr>
<tr class="row-even"><td><p>Hardware buffer size</p></td>
<td><p>Size of HW buffer in bytes.</p>
<p>If sampling period is too less, HW buffer can overflow and drop PC data</p>
</td>
<td><p>512 MB</p></td>
<td><p>New</p></td>
<td><p>Device accessible buffer for samples. Less hardware buffer size with low sampling periods, can cause overflow and dropping of PC data. High hardware buffer size can impact application execution due to lower amount of device memory being available</p></td>
</tr>
<tr class="row-odd"><td><p>Enable start/stop control</p></td>
<td><p>Control over PC Sampling data collection range.</p>
<p>1 - Allows user to start and stop PC Sampling using APIs</p>
</td>
<td><p>0 (disabled)</p></td>
<td><p>New</p></td>
<td></td>
</tr>
</tbody>
</table>
</section>
<section id="stall-reasons-mapping-table">
<span id="pc-sampling-api-stall-reasons-mapping"></span><h3><span class="section-number">2.10.2. </span>Stall Reasons Mapping Table<a class="headerlink" href="#stall-reasons-mapping-table" title="Permalink to this headline"></a></h3>
<p>The table below lists the stall reasons mapping from PC Sampling Activity APIs to PC Sampling APIs. Note: Stall reasons with suffix _not_issued represents latency samples. These samples indicate that no instruction was issued in that cycle from the warp scheduler from where the warp was sampled.</p>
<table class="table-no-stripes docutils align-default" id="id16">
<caption><span class="caption-text">Table 7. Stall Reasons Mapping Table from PC Sampling Activity APIs to PC Sampling APIs</span><a class="headerlink" href="#id16" title="Permalink to this table"></a></caption>
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>PC Sampling Activity API Stall Reasons</p>
<p>(common prefix: CUPTI_ACTIVITY_PC_SAMPLING_STALL_)</p>
</th>
<th class="head"><p>PC Sampling API Stall Reasons</p>
<p>(common prefix: smsp__pcsamp_warps_issue_stalled_)</p>
</th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>NONE</p></td>
<td><p>selected</p>
<p>selected_not_issued</p>
</td>
</tr>
<tr class="row-odd"><td><p>INST_FETCH</p></td>
<td><p>branch_resolving</p>
<p>branch_resolving_not_issued</p>
<p>no_instructions</p>
<p>no_instructions_not_issued</p>
</td>
</tr>
<tr class="row-even"><td><p>EXEC_DEPENDENCY</p></td>
<td><p>short_scoreboard</p>
<p>short_scoreboard_not_issued</p>
<p>wait</p>
<p>wait_not_issued</p>
</td>
</tr>
<tr class="row-odd"><td><p>MEMORY_DEPENDENCY</p></td>
<td><p>long_scoreboard</p>
<p>long_scoreboard_not_issued</p>
</td>
</tr>
<tr class="row-even"><td><p>TEXTURE</p></td>
<td><p>tex_throttle</p>
<p>tex_throttle_not_issued</p>
</td>
</tr>
<tr class="row-odd"><td><p>SYNC</p></td>
<td><p>barrier</p>
<p>barrier_not_issued</p>
<p>membar</p>
<p>membar_not_issued</p>
</td>
</tr>
<tr class="row-even"><td><p>CONSTANT_MEMORY_DEPENDENCY</p></td>
<td><p>imc_miss</p>
<p>imc_miss_not_issued</p>
</td>
</tr>
<tr class="row-odd"><td><p>PIPE_BUSY</p></td>
<td><p>mio_throttle</p>
<p>mio_throttle_not_issued</p>
<p>math_pipe_throttle</p>
<p>math_pipe_throttle_not_issued</p>
</td>
</tr>
<tr class="row-even"><td><p>MEMORY_THROTTLE</p></td>
<td><p>drain</p>
<p>drain_not_issued</p>
<p>lg_throttle</p>
<p>lg_throttle_not_issued</p>
</td>
</tr>
<tr class="row-odd"><td><p>NOT_SELECTED</p></td>
<td><p>not_selected</p>
<p>not_selected_not_issued</p>
</td>
</tr>
<tr class="row-even"><td><p>OTHER</p></td>
<td><p>misc</p>
<p>misc_not_issued</p>
<p>dispatch_stall</p>
<p>dispatch_stall_not_issued</p>
</td>
</tr>
<tr class="row-odd"><td><p>SLEEPING</p></td>
<td><p>sleeping</p>
<p>sleeping_not_issued</p>
</td>
</tr>
</tbody>
</table>
<p>For PC Sampling APIs, total (smsp__pcsamp_sample_count) and dropped (smsp__pcsamp_samples_data_dropped) sample counts are collected by default.</p>
</section>
<section id="data-structure-mapping-table">
<span id="pc-sampling-api-struct-mapping"></span><h3><span class="section-number">2.10.3. </span>Data Structure Mapping Table<a class="headerlink" href="#data-structure-mapping-table" title="Permalink to this headline"></a></h3>
<p>The table below lists the data structure mapping from PC Sampling Activity APIs to PC Sampling APIs.</p>
<table class="table-no-stripes docutils align-default" id="id17">
<caption><span class="caption-text">Table 8. Data structure Mapping Table from PC Sampling Activity APIs to PC Sampling APIs</span><a class="headerlink" href="#id17" title="Permalink to this table"></a></caption>
<colgroup>
<col style="width: 28%" />
<col style="width: 72%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>PC Sampling Activity API structures</p></th>
<th class="head"><p>PC Sampling API structures</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>CUpti_ActivityPCSamplingConfig</p></td>
<td><p>CUpti_PCSamplingConfigurationInfo</p></td>
</tr>
<tr class="row-odd"><td><p>CUpti_ActivityPCSamplingStallReason</p></td>
<td><p>CUpti_PCSamplingStallReason</p>
<p>Refer <a class="reference external" href="../main/main.html#stall-reasons-mapping-table">Stall Reasons Mapping Table</a></p>
</td>
</tr>
<tr class="row-even"><td><p>CUpti_ActivityPCSampling3</p></td>
<td><p>CUpti_PCSamplingPCData</p></td>
</tr>
<tr class="row-odd"><td><p>CUpti_ActivityPCSamplingRecordInfo</p></td>
<td><p>CUpti_PCSamplingData</p></td>
</tr>
</tbody>
</table>
</section>
<section id="data-flushing">
<span id="pc-sampling-api-flush"></span><h3><span class="section-number">2.10.4. </span>Data flushing<a class="headerlink" href="#data-flushing" title="Permalink to this headline"></a></h3>
<p>CUPTI clients can periodically flush GPU PC sampling data using the API <code class="docutils literal notranslate"><span class="pre">cuptiPCSamplingGetData()</span></code>. Besides periodic flushing of GPU PC sampling data, CUPTI clients need to also flush the GPU PC sampling data at the following points to maintain the uniqueness of PCs:</p>
<ul class="simple">
<li><p>For continuous collection mode CUPTI_PC_SAMPLING_COLLECTION_MODE_CONTINUOUS - after each module load-unload-load sequence.</p></li>
<li><p>For serialized collection mode CUPTI_PC_SAMPLING_COLLECTION_MODE_KERNEL_SERIALIZED - after completion of each kernel.</p></li>
<li><p>For range profiling using the configuration option CUPTI_PC_SAMPLING_CONFIGURATION_ATTR_TYPE_ENABLE_START_STOP_CONTROL - at the end of the range i.e. after <code class="docutils literal notranslate"><span class="pre">cuptiPCSamplingStop()</span></code> API.</p></li>
</ul>
<p>If application is profiled in the continuous collection mode with range profiling disabled, and there is no module unload, CUPTI clients can collect data in two ways:</p>
<ul class="simple">
<li><p>By using <code class="docutils literal notranslate"><span class="pre">cuptiPCSamplingGetData()</span></code> API periodically.</p></li>
<li><p>By using <code class="docutils literal notranslate"><span class="pre">cuptiPCSamplingDisable()</span></code> on application exit and reading GPU PC sampling data from sampling data buffer passed during configuration.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In case, <code class="docutils literal notranslate"><span class="pre">cuptiPCSamplingGetData()</span></code> API is not called periodically, the sampling data buffer passed during configuration should be big enough to hold the data for all the PCs.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Field <code class="docutils literal notranslate"><span class="pre">remainingNumPcs</span></code> of the struct <code class="docutils literal notranslate"><span class="pre">CUpti_PCSamplingData</span></code> helps in identifying the number of PC records available with CUPTI. User can adjust the periodic flush interval based on it. Further user need to ensure that all remaining records can be accommodated in the sampling data buffer passed during configuration before disabling the PC sampling.</p>
</div>
</section>
<section id="pc-sampling-api-source-correlation">
<span id="id3"></span><h3><span class="section-number">2.10.5. </span>SASS Source Correlation<a class="headerlink" href="#pc-sampling-api-source-correlation" title="Permalink to this headline"></a></h3>
<p>Building SASS source correlation for a PC can be split into two parts:</p>
<ul class="simple">
<li><p><strong>Correlation of a PC to a SASS instruction</strong> - PC to SASS correlation is done during PC sampling at run time and the SASS data is available in the PC record. Fields <code class="docutils literal notranslate"><span class="pre">cubinCrc</span></code>, <code class="docutils literal notranslate"><span class="pre">pcOffset</span></code> and <code class="docutils literal notranslate"><span class="pre">functionName</span></code> in the PC record help in correlation of a PC with a SASS instruction. You can extract cubins from the application executable or library using the <code class="docutils literal notranslate"><span class="pre">cuobjdump</span></code> utility by executing the command <code class="docutils literal notranslate"><span class="pre">cuobjdump</span> <span class="pre">-xelf</span> <span class="pre">all</span> <span class="pre">exe/lib</span></code>. The cuobjump utility version should match with the CUDA Toolkit version used to build the CUDA application executable or library files. You can find the cubinCrc for extracted cubins using the <code class="docutils literal notranslate"><span class="pre">cuptiGetCubinCrc()</span></code> API. With the help of cubinCrc you can find out the cubin to which a PC belongs. The cubin can be disassembled using the <code class="docutils literal notranslate"><span class="pre">nvdisasm</span></code> utility that comes with the CUDA toolkit.</p></li>
<li><p><strong>Correlation of a SASS instruction to a CUDA source line</strong> - Correlation of GPU PC samples to CUDA C source lines can be done offline as well as at runtime with the help of the <code class="docutils literal notranslate"><span class="pre">cuptiGetSassToSourceCorrelation()</span></code> API.</p></li>
</ul>
<p><strong>JIT compiled cubins</strong> - In case of JIT compiled cubins, it is not possible to extract the cubin from the executable or library. For this case one can subscribe to one of the <code class="docutils literal notranslate"><span class="pre">CUPTI_CBID_RESOURCE_MODULE_LOADED</span></code> or <code class="docutils literal notranslate"><span class="pre">CUPTI_CBID_RESOURCE_MODULE_UNLOAD_STARTING</span></code> or <code class="docutils literal notranslate"><span class="pre">CUPTI_CBID_RESOURCE_MODULE_PROFILED</span></code> callbacks. It returns a <code class="docutils literal notranslate"><span class="pre">CUpti_ModuleResourceData</span></code> structure having the CUDA binary. This binary can be stored in a file and can be used for offline CUDA C source correlation.</p>
</section>
<section id="api-usage">
<span id="pc-sampling-api-usage"></span><h3><span class="section-number">2.10.6. </span>API Usage<a class="headerlink" href="#api-usage" title="Permalink to this headline"></a></h3>
<p>Here is a pseudo code which shows how to collect the PC sampling data for specific CPU code ranges:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>void Collection()
{
    // Select collection mode
    CUpti_PCSamplingConfigurationInfoParams pcSamplingConfigurationInfoParams = {};

    CUpti_PCSamplingConfigurationInfo collectionMode = {};
    collectionMode.attributeData.collectionModeData.collectionMode = CUPTI_PC_SAMPLING_COLLECTION_MODE_CONTINUOUS;

    pcSamplingConfigurationInfoParams.numAttributes = 1;
    pcSamplingConfigurationInfoParams.pPCSamplingConfigurationInfo = &amp;collectionMode;
    cuptiPCSamplingSetConfigurationAttribute(&amp;pcSamplingConfigurationInfoParams);

    // Select stall reasons to collect
    {
        // Get number of supported stall reasons
        cuptiPCSamplingGetNumStallReasons();
        // Get number of supported stall reason names and corresponding indexes
        cuptiPCSamplingGetStallReasons();
        // Set selected stall reasons
        cuptiPCSamplingSetConfigurationAttribute();
    }

    // Select code range using start/stop APIs
    // Opt-in for start and stop PC Sampling using APIs cuptiPCSamplingStart and cuptiPCSamplingStop
    CUpti_PCSamplingConfigurationInfo enableStartStop = {};
    enableStartStop.attributeType = CUPTI_PC_SAMPLING_CONFIGURATION_ATTR_TYPE_ENABLE_START_STOP_CONTROL;
    enableStartStop.attributeData.enableStartStopControlData.enableStartStopControl = true;

    pcSamplingConfigurationInfoParams.numAttributes = 1;
    pcSamplingConfigurationInfoParams.pPCSamplingConfigurationInfo = &amp;enableStartStop;
    cuptiPCSamplingSetConfigurationAttribute(&amp;pcSamplingConfigurationInfoParams);

    // Enable PC Sampling
    cuptiPCSamplingEnable();

    kernelA &lt;&lt;&lt;blocks, threads, 0, s0&gt;&gt;&gt;(...);                  // KernelA is not sampled

    // Start PC sampling collection
    cuptiPCSamplingStart();
    {
        // KernelB and KernelC might run concurrently since &#39;continuous&#39; sampling collection mode is selected
        kernelB &lt;&lt;&lt;blocks, threads, 0, s0&gt;&gt;&gt;(...);              // KernelB is sampled
        kernelC &lt;&lt;&lt;blocks, threads, 0, s1&gt;&gt;&gt;(...);              // KernelC is sampled
    }
    // Stop PC sampling collection
    cuptiPCSamplingStop();
    // Flush PC sampling data
    cuptiPCSamplingGetData();

    kernelD &lt;&lt;&lt;blocks, threads, 0, s0&gt;&gt;&gt;(...);                  // KernelD is not sampled

    // Start PC sampling collection
    cuptiPCSamplingStart();
    {
        kernelE &lt;&lt;&lt;blocks, threads, 0, s0&gt;&gt;&gt;(...);              // KernelE is sampled
    }
    // Stop PC sampling collection
    cuptiPCSamplingStop();
    // Flush PC sampling data
    cuptiPCSamplingGetData();

    // Disable PC Sampling
    cuptiPCSamplingDisable();
}
</pre></div>
</div>
</section>
<section id="limitations">
<span id="pc-sampling-api-limitations"></span><h3><span class="section-number">2.10.7. </span>Limitations<a class="headerlink" href="#limitations" title="Permalink to this headline"></a></h3>
<p>Known limitations and issues:</p>
<ul class="simple">
<li><p>PC Sampling APIs don’t support simultaneous sampling of multiple CUDA contexts on a GPU. However, simultaneous sampling of single CUDA context per GPU is supported. Before enabling and configuring the PC sampling on a different CUDA context on the same GPU, PC sampling needs to be disabled on the other context.</p></li>
</ul>
</section>
</section>
<section id="cupti-sass-metric-api">
<span id="sass-metrics-api"></span><h2><span class="section-number">2.11. </span>CUPTI SASS Metric API<a class="headerlink" href="#cupti-sass-metric-api" title="Permalink to this headline"></a></h2>
<p>The SASS metric APIs support collecting metric data at SASS assembly instruction level. These support a larger set of SASS instruction level metrics compared to the CUPTI Activity APIs. The set of sass metrics supported for each GPU architecture can be queried. These APIs are supported on Volta and later GPU architectures, i.e. devices with compute capability 7.0 and higher.</p>
<p>These APIs support SASS instruction to CUDA C source line correlation in offline mode. Hence the runtime overhead during data collection is lower.</p>
<section id="sass-metrics-usage">
<span id="id4"></span><h3><span class="section-number">2.11.1. </span>API usage<a class="headerlink" href="#sass-metrics-usage" title="Permalink to this headline"></a></h3>
<ul class="simple">
<li><p><strong>Enumerate metrics:</strong> Use the API <code class="docutils literal notranslate"><span class="pre">cuptiSassMetricsGetNumOfMetrics()</span></code> for the number of metrics supported by the chip. Then allocate the buffer of type <code class="docutils literal notranslate"><span class="pre">CUpti_SassMetrics_MetricDetails</span></code> and pass it to the API <code class="docutils literal notranslate"><span class="pre">cuptiSassMetricsGetMetrics()</span></code> where CUPTI will list out all the SASS metrics and put it in the user-allocated buffer.</p></li>
<li><p><strong>Create config image:</strong> For all the selected SASS metrics, create a list of <code class="docutils literal notranslate"><span class="pre">CUpti_SassMetrics_Config</span></code> structures. For creating the config buffer for a metric we need the metric id and the output granularity for the metric. The metric id can be queried by using the API <code class="docutils literal notranslate"><span class="pre">cuptiSassMetricsGetProperties()</span></code>. The output granularity tells at what level data will be collected. CUPTI supports collection at three levels -</p>
<ul>
<li><p>CUPTI_SASS_METRICS_OUTPUT_GRANULARITY_GPU (at GPU level),</p></li>
<li><p>CUPTI_SASS_METRICS_OUTPUT_GRANULARITY_SM (at Streaming Multiprocessor level, the metric instance count will be the number of SMs present in the chip),</p></li>
<li><p>CUPTI_SASS_METRICS_OUTPUT_GRANULARITY_SMSP (SM sub-partition level, the number of instances will be the sum of all the SMSP present in the chip i.e num of SMs * num of sub-partitions in each SM)</p></li>
</ul>
</li>
<li><p><strong>Set config for the CUDA device:</strong> API <code class="docutils literal notranslate"><span class="pre">cuptiSassMetricsSetConfig()</span></code> should be used for setting the config on the device for SASS metrics collection. This API takes the device index and list of <code class="docutils literal notranslate"><span class="pre">CUpti_SassMetrics_Config</span></code> structs as input parameters. Then set the config for the device on which the kernel is running else CUPTI will report a <code class="docutils literal notranslate"><span class="pre">CUPTI_ERROR_INVALID_OPERATION</span></code> error.</p></li>
<li><p><strong>Enable SASS metric profiling:</strong> After setting the config for the CUDA device one needs to enable SASS patching for the context on which the kernel will be launched using the API <code class="docutils literal notranslate"><span class="pre">cuptSassMetricsEnable()</span></code>.
CUPTI provides control over when the kernel will be patched. For Lazy patching mode, CUPTI will only patch the kernel at the first launch instance and then unpatch the kernel when the API <code class="docutils literal notranslate"><span class="pre">cuptiSassMetricsDisable</span></code> is called. Otherwise, CUPTI will patch all the kernels in the module for the context, regardless of whether kernels would be launched in the enable/disable range. Set the <code class="docutils literal notranslate"><span class="pre">enableLazyPatching</span></code> flag to enable the lazy patching mode for profiling. Lazy patching is suitable for applications that have a large number of kernels in the module and a small set of kernels are launched.</p></li>
<li><p><strong>Flush SASS metric profiling data:</strong> Once kernel execution is completed, metric data is stored in an internal format. One needs to query the size of the buffer to store the metrics data. API <code class="docutils literal notranslate"><span class="pre">cuptiSassMetricsGetDataProperties()</span></code> can be used to query the number of patched instructions and the number of hardware instances. Then allocate the buffer based on retrieved data, where CUPTI will flush the profiled metric data. For flushing the data, call the API <code class="docutils literal notranslate"><span class="pre">cuptiSassMetricsFlushData()</span></code>.</p></li>
<li><p><strong>Disable SASS metric profiling:</strong> Once the profiling of the kernel is done, call the API <code class="docutils literal notranslate"><span class="pre">cuptiSassMetricsDisable()</span></code> for resetting the patched kernel and remove all the profiled metric data which has been collected for the kernels.
One thing to note is that CUPTI will remove all the metric data which has been collected for kernels launched since the API <code class="docutils literal notranslate"><span class="pre">cuptiSassMetricsFlushData()</span></code> call. So it is the user’s responsibility to call flush data API for retrieving all the metric data. Calling API <code class="docutils literal notranslate"><span class="pre">cuptiSassMetricsFlushData()</span></code> after <code class="docutils literal notranslate"><span class="pre">cuptiSassMetricsDisable()</span></code> will report the error <code class="docutils literal notranslate"><span class="pre">CUPTI_ERROR_INVALID_OPERATION</span></code>.</p></li>
<li><p><strong>Unset configuration for the CUDA device:</strong> CUPTI maintains internal state for each CUDA device for which SASS metric collection is enabled. API <code class="docutils literal notranslate"><span class="pre">cuptiSassMetricsUnsetConfig()</span></code> should be called to clean-up the state. This API should be called for each device for which SASS metric collection has been configured.</p></li>
</ul>
</section>
<section id="sample-code">
<span id="sass-metrics-samples"></span><h3><span class="section-number">2.11.2. </span>Sample code<a class="headerlink" href="#sample-code" title="Permalink to this headline"></a></h3>
<p>CUPTI sample <strong>sass_metric</strong> has two core functions – function <em>ListSupportedMetrics()</em> shows how to enumerate all metrics supported by the chip and function <em>CollectSassMetrics()</em> show how to collect SASS metrics.
Code snippet for enumerating SASS metrics (refer the <em>ListSupportedMetrics()</em> function in the CUPTI sass_metric sample):</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>CUpti_Device_GetChipName_Params getChipParams{ CUpti_Device_GetChipName_Params_STRUCT_SIZE };
cuptiDeviceGetChipName(&amp;getChipParams);

CUpti_SassMetrics_GetNumOfMetrics_Params getNumOfMetricParams;
getNumOfMetricParams.pChipName = getChipParams.pChipName;
cuptiSassMetricsGetNumOfMetrics(&amp;getNumOfMetricParams);

std::vector&lt;CUpti_SassMetrics_MetricDetails&gt; supportedMetrics(getNumOfMetricParams.numOfMetrics);
CUpti_SassMetrics_GetMetrics_Params getMetricsParams {CUpti_SassMetrics_GetMetrics_Params_STRUCT_SIZE};
getMetricsParams.pChipName = getChipParams.pChipName;
getMetricsParams.pMetricsList = supportedMetrics.data();
getMetricsParams.numOfMetrics = supportedMetrics.size();
cuptiSassMetricsGetMetrics(&amp;getMetricsParams);
for (size_t i = 0; i &lt; supportedMetrics.size(); ++i)
{
    std::cout &lt;&lt; &quot;Metric Name: &quot; &lt;&lt; supportedMetrics[i].pMetricName
            &lt;&lt; &quot;, MetricID: &quot; &lt;&lt; supportedMetrics[i].metricId
            &lt;&lt; &quot;, Metric Description: &quot; &lt;&lt; supportedMetrics[i].pMetricDescription &lt;&lt; &quot;\n&quot;;
}
</pre></div>
</div>
<p>Code snippet for collecting SASS metrics (refer the <em>CollectSassMetrics()</em> function in the CUPTI sass_metric sample):</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>cuptiSassMetricsSetConfig();

// Enable SASS Patching
sassMetricsEnableParams.enableLazyPatching = 1;
cuptiSassMetricsEnable();

// As lazy patching has been enabled, VectorAdd will be patched here at the first launch instance
VectorAdd&lt;&lt;&lt;gridSize, blockSize&gt;&gt;&gt;();

cuptiSassMetricsGetDataProperties();

if (getDataPropParams.numOfInstances != 0 &amp;&amp; getDataPropParams.numOfPatchedInstructionRecords != 0)
{
    // allocate memory for getting patched data.

    flushDataParams.numOfInstances = getDataPropParams.numOfInstances;
    flushDataParams.numOfPatchedInstructionRecords = getDataPropParams.numOfPatchedInstructionRecords;
    flushDataParams.pMetricsData =
            (CUpti_SassMetrics_Data*)malloc(getDataPropParams.numOfPatchedInstructionRecords * sizeof(CUpti_SassMetrics_Data));

    for (size_t recordIndex = 0;
         recordIndex &lt; getDataPropParams.numOfPatchedInstructionRecords;
         ++recordIndex)
    {
        flushDataParams.pMetricsData[recordIndex].pInstanceValues =
            (CUpti_SassMetrics_InstanceValue*) malloc(getDataPropParams.numOfInstances * sizeof(CUpti_SassMetrics_InstanceValue));
    }

    cuptiSassMetricsFlushData();
    // Store the data for post-processing the data (e.g. SASS to source correlation)
    // Cleanup memory
}

// As this is the first VectorSub launch, the patching will be done here.
VectorSub&lt;&lt;&lt;gridSize, blockSize&gt;&gt;&gt;();

// As cuptiSassMetricsFlushData() API is not called, VectorSub SASS metric data will be discarded.
// All the kernels which were patched earlier will be reset to its original state.
cuptiSassMetricsDisable();

// VectorMultiply function will not get patched as it is called outside the enable/disable range.
VectorMultiply&lt;&lt;&lt;gridSize, blockSize&gt;&gt;&gt;();

cuptiSassMetricsUnsetConfig();
</pre></div>
</div>
</section>
</section>
<section id="cupti-pm-sampling-api">
<span id="pm-sampling-api"></span><h2><span class="section-number">2.12. </span>CUPTI PM Sampling API<a class="headerlink" href="#cupti-pm-sampling-api" title="Permalink to this headline"></a></h2>
<p>In the CUDA 12.6 release, CUPTI introduced new PM sampling APIs which are included in the header file <code class="docutils literal notranslate"><span class="pre">cupti_pmsampling.h</span></code> for collecting a set
of metrics by sampling the GPU’s performance monitors (PM) periodically at fixed intervals. Each sample is composed of metric values and the
GPU timestamp when it was collected in nanoseconds.</p>
<p>These APIs are supported on Turing and later GPU architectures, i.e. devices with compute capability 7.5 and higher.</p>
<p>PM sampling follows a similar approach to range profiling, where the process is divided into 2 types of operations i.e. host (enumeration,
configuration, evaluation) and target(collection).</p>
<section id="pm-sampling-usage">
<span id="id5"></span><h3><span class="section-number">2.12.1. </span>API usage<a class="headerlink" href="#pm-sampling-usage" title="Permalink to this headline"></a></h3>
<ul>
<li><p><strong>Enumerate metrics (enumeration):</strong></p>
<p>CUPTI released a new set of host APIs with <code class="docutils literal notranslate"><span class="pre">cuptiProfilerHost</span></code> prefix, where users need to create a profiler host object for all the host operations.
For PM sampling specific host operation, users need to set the profilerType to <code class="docutils literal notranslate"><span class="pre">CUPTI_PROFILER_TYPE_PM_SAMPLING</span></code> in the <code class="docutils literal notranslate"><span class="pre">CUpti_Profiler_Host_Initialize_Params</span></code>
object.</p>
<p>CUPTI has following host APIs for enumerating metrics and it properties:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">cuptiProfilerHostGetBaseMetrics()</span></code> for listing base metrics for a metric type (counter, throughput and ratio).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">cuptiProfilerHostGetSubMetrics()</span></code> for listing the submetric for a metric.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">cuptiProfilerHostGetMetricProperties()</span></code> for querying the details about a metric like associated hardware unit, metric type and a short description
about the metric.</p>
<p>CUPTI lists some of the useful metrics in the <a class="reference external" href="main.html#pm-sampling-metric-table">PM Sampling Metric Table</a> which can be used for initial metric selection which list out various GPU and its component
attributes like SM active cycles, GPC and SYS clock frequency and many more.</p>
</li>
</ul>
</li>
<li><p><strong>Create config image (configuration):</strong></p>
<p>Similar to range profiler, for collecting PM sampling data users need to create a config image blob which will have scheduling information for metrics
which were selected for collection. As configuration is a host operation similar to enumeration, users need to initialize the profiler host object before
calling any of the configuration APIs.</p>
<p>For creating a config image, CUPTI exposes new profiler host APIs like <code class="docutils literal notranslate"><span class="pre">cuptiProfilerHostConfigAddMetrics()</span></code> API where users will pass the list of
metrics as input and then call <code class="docutils literal notranslate"><span class="pre">cuptiProfilerHostGetConfigImageSize()</span></code> API for getting the size of config image which user need to allocate and finally
call the <code class="docutils literal notranslate"><span class="pre">cuptiProfilerHostGetConfigImage()</span></code> API where users can pass the allocated buffer for storing the scheduling information in the config image.</p>
<p>CUPTI also adds another optional API i.e. <code class="docutils literal notranslate"><span class="pre">cuptiProfilerHostGetNumOfPasses()</span></code> for checking the number of passes required for collecting the sampling data
for a given config image.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Config images which need more than one pass for collecting sampling data are not supported.</p>
</div>
</li>
<li><p><strong>Collecting Sampling Data (collection):</strong></p>
<p>This operation instructs CUPTI to begin collecting sampling data on a CUDA device at specific intervals or cycles, determined by the trigger type specified
in the <code class="docutils literal notranslate"><span class="pre">cuptiPmSamplingSetConfig()</span></code> API.</p>
<p>Collection phase can be divided into 6 subparts:</p>
<ul>
<li><p><strong>Enable PM Sampling:</strong></p>
<p>This is the entry point of the PM sampling process where the user passes the device index on which sampling data will be collected. Use the
<code class="docutils literal notranslate"><span class="pre">cuptiPmSamplingEnable()</span></code> API to create a <code class="docutils literal notranslate"><span class="pre">CUpti_PmSampling_Object</span></code> object. This stores all the intermediate data and act as an identifier for other
target APIs.</p>
</li>
<li><p><strong>Set configuration:</strong></p>
<p>CUPTI has <code class="docutils literal notranslate"><span class="pre">cuptiPmSamplingSetConfig()</span></code> API for customizing configuration to the PM sampling process like hardware buffer size where the raw sampling
data will be stored, sampling interval specifies the frequency at which sampling triggers will collect the sampling data. This will vary
depending on the trigger mode set in the config API. Along with these parameters users need to pass the config image which has the
scheduling information, which has been created earlier in the configuration phase.</p>
<p>The maximum sampling frequency without buffer overflow events depends on GPU (SM count), GPU load intensity, and overall system load. The bigger the chip
and the higher the load, the lower the maximum frequency. If you need higher frequency, you can increase it until you get the overflow event which can be
queried while decoding the pm sampling data using <code class="docutils literal notranslate"><span class="pre">cuptiPmSamplingDecodeData()</span></code> API.</p>
<p>CUPTI supports two trigger modes, <code class="docutils literal notranslate"><span class="pre">GPU_SYSCLK_INTERVAL</span></code> which is based on sys clock frequency and the sample intervals are in terms of clock cycles. And
the 2nd one is <code class="docutils literal notranslate"><span class="pre">GPU_TIME_INTERVAL</span></code> which has fixed frequency and the intervals are in terms of nanoseconds.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The <code class="docutils literal notranslate"><span class="pre">GPU_TIME_INTERVAL</span></code> trigger is not supported in Turing and GA100 chips.</p>
</div>
</li>
<li><p><strong>Start PM Sampling:</strong></p>
<p>After enabling and setting up the configuration for the PM sampling, users need to call the <code class="docutils literal notranslate"><span class="pre">cuptiPmSamplingStart()</span></code> API which signals CUPTI to start the
collection, the raw sampling data will be stored in the hardware buffer.</p>
</li>
<li><p><strong>Stop PM Sampling:</strong></p>
<p>Users need to call the <code class="docutils literal notranslate"><span class="pre">cuptiPmSamplingStop()</span></code> API for stopping the collection of sampling data.</p>
</li>
<li><p><strong>Decode PM Sampling data:</strong></p>
<p>While collection phase all the raw sampling data will be stored in the hardware buffer. CUPTI exposes <code class="docutils literal notranslate"><span class="pre">cuptiPmSamplingDecodeData()</span></code> API which decodes the
raw data and stores it in a counter data image which users need to pass into the API as input. For creating the counter data image refer to this.</p>
<p>It is users responsibility to call this decode API for freeing up the hardware buffer for allowing new raw data to get stored in the hardware buffer. This
API also outputs some attributes like hardware buffer overflow status, decode stop reasons like end of all the raw data or if the counter data image passed
is full. So for long running workload users can call this decode API between the Start and Stop API. The ideal way would be calling it in a separate thread.
Refer <strong>pm_sampling</strong> public sample which shows the decode operation running in parallel with the collection.</p>
</li>
<li><p><strong>Disable PM Sampling:</strong></p>
<p>For destroying all the resources allocated for PM sampling and ending the PM sampling users can call the <code class="docutils literal notranslate"><span class="pre">cuptiPmSamplingDisable()</span></code> API.</p>
</li>
<li><p><strong>Create Counter data image:</strong></p>
<p>For storing the decoded data and using it in the evaluation phase users need to allocate a buffer which CUPTI refer as counter data image.
Creating a counter data image is a target operation and should be done after enabling the PM sampling and before calling the decode API call.
For creating the counter buffer image, first users need to call <code class="docutils literal notranslate"><span class="pre">cuptiPmSamplingGetCounterDataSize()</span></code> API for getting the size of buffer needed
for allocation. Once users allocate the buffer the buffer needs to be in counter data format where the samples will be stored so to initialize the
buffer users have to call <code class="docutils literal notranslate"><span class="pre">cuptiPmSamplingCounterDataImageInitialize()</span></code> API. This same API can also be used to reset the counter buffer image.</p>
</li>
</ul>
</li>
<li><p><strong>Evaluating Counter Data (evaluation):</strong></p>
<p>Once the raw data is decoded to counter buffer image, users need to use profiler host APIs for evaluating the counter data for getting sample data
in readable format. Users can query the number of completed samples in the counter data using the <code class="docutils literal notranslate"><span class="pre">cuptiPmSamplingGetCounterDataInfo()</span></code> API.
For PM sampling each sample is defined by its start and end time stamps. For getting sample info like start and end timestamps CUPTI has
<code class="docutils literal notranslate"><span class="pre">cuptiPmSamplingCounterDataGetSampleInfo()</span></code> API. The timestamps reported are CPU based time stamps. Then to get the collected metrics values for
the sample, <code class="docutils literal notranslate"><span class="pre">cuptiProfilerHostEvaluateToGpuValues()</span></code> API is used.</p>
</li>
</ul>
</section>
<section id="pm-sampling-samples">
<span id="id6"></span><h3><span class="section-number">2.12.2. </span>Sample code<a class="headerlink" href="#pm-sampling-samples" title="Permalink to this headline"></a></h3>
<p>CUPTI sample <strong>pm_sampling</strong> has two core functions – function <em>PmSamplingQueryMetrics()</em> shows how to enumerate all metrics supported by the
chip and function <em>PmSamplingCollection()</em> show how to collect PM sampling data for a list of metrics while launching CUDA workloads.
Code snippet for enumerating supported PM sampling metrics (refer the <em>PmSamplingQueryMetrics()</em> function in the CUPTI pm_sampling sample):</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>CUpti_Device_GetChipName_Params getChipParams{ CUpti_Device_GetChipName_Params_STRUCT_SIZE };
cuptiDeviceGetChipName(&amp;getChipParams);

CUpti_Profiler_Host_Initialize_Params hostInitializeParams = {CUpti_Profiler_Host_Initialize_Params_STRUCT_SIZE};
hostInitializeParams.profilerType = CUPTI_PROFILER_TYPE_PM_SAMPLING;
hostInitializeParams.pChipName = m_chipName.c_str();
hostInitializeParams.pCounterAvailabilityImage = counterAvailibilityImage.data();
cuptiProfilerHostInitialize(&amp;hostInitializeParams);
m_pHostObject = hostInitializeParams.pHostObject;

for (size_t metricTypeIndex = 0; metricTypeIndex &lt; CUPTI_METRIC_TYPE__COUNT; ++metricTypeIndex)
{
    CUpti_Profiler_Host_GetBaseMetrics_Params getBaseMetricsParams {CUpti_Profiler_Host_GetBaseMetrics_Params_STRUCT_SIZE};
    getBaseMetricsParams.pHostObject = m_pHostObject;
    getBaseMetricsParams.metricType = (CUpti_MetricType)metricTypeIndex;
    cuptiProfilerHostGetBaseMetrics(&amp;getBaseMetricsParams);

    for (size_t metricIndex = 0; metricIndex &lt; getBaseMetricsParams.numMetrics; ++metricIndex) {
        metricsList.push_back(getBaseMetricsParams.ppMetricNames[metricIndex]);
    }
}

CUpti_Profiler_Host_Deinitialize_Params deinitializeParams = {CUpti_Profiler_Host_Deinitialize_Params_STRUCT_SIZE};
deinitializeParams.pHostObject = m_pHostObject;
cuptiProfilerHostDeinitialize(&amp;deinitializeParams);
</pre></div>
</div>
<p>Code snippet for collecting PM sampling data (refer the <em>PmSamplingCollection()</em> function in the CUPTI pm_sampling sample):</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>void PmSamplingCollection()
{
    // 1. Create config image
    std::vector&lt;uint8_t&gt; configImage;
    CreateConfigImage(configImage, metrics);

    // 2. Enable PM sampling and set config for the PM sampling data collection.
    EnablePmSampling(deviceIndex);
    SetConfig(configImage, hardwareBufferSize, samplingInterval);

    // 3. Create counter data image
    std::vector&lt;uint8_t&gt; counterDataImage;
    CreateCounterDataImage(maxSamples, metrics, counterDataImage);

    VectorLaunchWorkLoad vectorWorkLoad;
    vectorWorkLoad.SetUp();

    // 4. Start the PM sampling and launch the CUDA workload
    StartPmSampling();

    // 5. Launch the kernel NUM_OF_ITERATIONS times
    const size_t NUM_OF_ITERATIONS = 100000;
    for (size_t ii = 0; ii &lt; NUM_OF_ITERATIONS; ++ii)
    {
        vectorWorkLoad.LaunchKernel();
    }
    cudaDeviceSynchronize();

    // 6. Stop the PM sampling and join the decode thread
    StopPmSampling();

    // 7. Decode PM Sampling Data
    DecodeCounterData(counterDataImage);

    // 8. Print the sample ranges for the collected metrics
    PrintSampleRanges(counterDataImage);

    // 9. Disable PM Sampling
    DisablePmSampling();
}

// PrintSampleRanges function
void PrintSampleRanges(std::vector&lt;uint8_t&gt; counterDataImage)
{
    CUpti_PmSampling_GetCounterDataInfo_Params counterDataInfo {CUpti_PmSampling_GetCounterDataInfo_Params_STRUCT_SIZE};
    counterDataInfo.pCounterDataImage = counterDataImage.data();
    counterDataInfo.counterDataImageSize = counterDataImage.size();
    cuptiPmSamplingGetCounterDataInfo(&amp;counterDataInfo);

    for (size_t sampleIndex = 0; sampleIndex &lt; counterDataInfo.numCompletedSamples; ++sampleIndex)
    {
        pmSamplingHost.EvaluateCounterData(sampleIndex, metricsList, counterDataImage);
    }

    // For reusing the counter data image, reset the counter data image
    ResetCounterDataImage(counterDataImage);
}
</pre></div>
</div>
</section>
<section id="metrics-table">
<span id="pm-sampling-metric-table"></span><h3><span class="section-number">2.12.3. </span>Metrics Table<a class="headerlink" href="#metrics-table" title="Permalink to this headline"></a></h3>
<p>PM sampling supports the collection of a wide variety of metrics.
The table below lists some useful metrics that provide insights into the utilization of different units in the GPU.</p>
<table class="table-no-stripes docutils align-default" id="id18">
<caption><span class="caption-text">Table 9. PM Sampling Metrics Table</span><a class="headerlink" href="#id18" title="Permalink to this table"></a></caption>
<colgroup>
<col style="width: 49%" />
<col style="width: 51%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Metric Name</p></th>
<th class="head"><p>Metric details</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>gpc__cycles_elapsed.avg.per_second</p></td>
<td><p><strong>GPC Clock Frequency:</strong></p>
<p>The average GPC clock frequency in hertz.</p>
</td>
</tr>
<tr class="row-odd"><td><p>sys__cycles_elapsed.avg.per_second</p></td>
<td><p><strong>SYS Clock Frequency:</strong></p>
<p>The average SYS clock frequency in hertz. The GPU front end (command processor),
copy engines, and the performance monitor run at the SYS clock. On Turing and
NVIDIA GA100 GPUs the sampling frequency is based upon a period of SYS clocks
(not time) so samples per second will vary with SYS clock. On NVIDIA GA10x GPUs
the sampling frequency is based upon a fixed frequency clock. The maximum
frequency scales linearly with the SYS clock.</p>
</td>
</tr>
<tr class="row-even"><td><p>gr__cycles_active.sum.pct_of_peak_sustained_elapsed</p></td>
<td><p><strong>GR Active:</strong></p>
<p>The percentage of cycles the compute engine is active. The compute engine is
active if there is any work in the compute pipe.</p>
</td>
</tr>
<tr class="row-odd"><td><p>gr__dispatch_count.avg.pct_of_peak_sustained_elapsed</p></td>
<td><p><strong>Dispatch Started:</strong></p>
<p>The ratio of compute grid launches (dispatches) to the compute pipe to the
maximum sustained rate of the compute pipe.</p>
</td>
</tr>
<tr class="row-even"><td><p>tpc__warps_inactive_sm_active_realtime.avg.pct_of_peak_sustained_elapsed</p></td>
<td><p><strong>Active SM Unused Warp Slots:</strong></p>
<p>The ratio of inactive warp slots on the SMs to the maximum number of warps per
SM as a percentage. This is an indication of how many more warps may fit on the
SMs if occupancy is not limited by a resource such as max warps of a shader type,
shared memory, registers per thread, or thread blocks per SM.</p>
</td>
</tr>
<tr class="row-odd"><td><p>tpc__warps_inactive_sm_idle_realtime.avg.pct_of_peak_sustained_elapsed</p></td>
<td><p><strong>Idle SM Unused Warp Slots:</strong></p>
<p>The ratio of inactive warps slots due to idle SMs to the the maximum number of
warps per SM as a percentage.</p>
<p>This is an indicator that the current workload on the SM is not sufficient to
put work on all SMs. This can be due to either CPU starving the GPU, current
work is too small to saturate the GPU or current work is trailing off but
blocking next work.</p>
</td>
</tr>
<tr class="row-even"><td><p>sm__cycles_active.avg.pct_of_peak_sustained_elapsed</p></td>
<td><p><strong>SMs Active:</strong></p>
<p>The ratio of cycles SMs had at least 1 warp in flight (allocated on SM) to the
number of cycles as a percentage. A value of 0 indicates all SMs were idle
(no warps in flight). A value of 50% can indicate some gradient between all SMs
active 50% of the sample period or 50% of SMs active 100% of the sample period.</p>
</td>
</tr>
<tr class="row-odd"><td><p>sm__inst_executed_realtime.avg.pct_of_peak_sustained_elapsed</p></td>
<td><p><strong>SM Issue:</strong></p>
<p>The ratio of cycles that SM sub-partitions (warp schedulers) issued an
instruction to the number of cycles in the sample period as a percentage.</p>
</td>
</tr>
<tr class="row-even"><td><p>sm__pipe_tensor_cycles_active_realtime.avg.pct_of_peak_sustained_elapsed</p></td>
<td><p><strong>Tensor Active:</strong></p>
<p>The ratio of cycles the SM tensor pipes were active issuing tensor instructions
to the number of cycles in the sample period as a percentage.</p>
<p>This metric is not available on Turing GPUs for periodic sampling.</p>
</td>
</tr>
<tr class="row-odd"><td><p>sm__pipe_shared_cycles_active_realtime.avg.pct_of_peak_sustained_elapsed</p></td>
<td><p><strong>Tensor Active / FP16 Active:</strong></p>
<p>The ratio of cycles the SM tensor pipes or FP16x2 pipes were active issuing
tensor instructions to the number of cycles in the sample period as a percentage.</p>
<p>This metric is only available for Turing GPUs for periodic sampling.</p>
</td>
</tr>
<tr class="row-even"><td><p>dramc__read_throughput.avg.pct_of_peak_sustained_elapsed</p></td>
<td><p><strong>DRAM Read Bandwidth:</strong></p>
<p>The ratio of cycles the DRAM interface was active reading data to the elapsed
cycles in the same period as a percentage.</p>
</td>
</tr>
<tr class="row-odd"><td><p>dramc__write_throughput.avg.pct_of_peak_sustained_elapsed</p></td>
<td><p><strong>DRAM Write Bandwidth:</strong></p>
<p>The ratio of cycles the DRAM interface was active writing data to the elapsed
cycles in the same period as a percentage.</p>
</td>
</tr>
<tr class="row-even"><td><p>pcie__read_bytes.avg.pct_of_peak_sustained_elapsed</p></td>
<td><p><strong>PCIe Read Throughput:</strong></p>
<p>The ratio of bytes received on the PCIe interface to the maximum number of bytes
receivable in the sample period as a percentage. The theoretical value is
calculated based upon the PCIe generation and number of lanes.</p>
</td>
</tr>
<tr class="row-odd"><td><p>pcie__write_bytes.avg.pct_of_peak_sustained_elapsed</p></td>
<td><p><strong>PCIe Write Throughput:</strong></p>
<p>The ratio of bytes transmitted on the PCIe interface to the maximum number of
bytes receivable in the sample period as a percentage. The theoretical value is
calculated based upon the PCIe generation and number of lanes.</p>
</td>
</tr>
<tr class="row-even"><td><p>nvlrx__bytes.avg.pct_of_peak_sustained_elapsed</p></td>
<td><p><strong>NVLink bytes received:</strong></p>
<p>The ratio of bytes received on the NVLink interface to the maximum number of
bytes receivable in the sample period as a percentage.</p>
</td>
</tr>
<tr class="row-odd"><td><p>nvltx__bytes.avg.pct_of_peak_sustained_elapsed</p></td>
<td><p><strong>NVLink bytes transmitted:</strong></p>
<p>The ratio of bytes transmitted on the NVLink interface to the maximum number of
bytes transmittable in the sample period as a percentage.</p>
</td>
</tr>
<tr class="row-even"><td><p>pcie__rx_requests_aperture_bar1_op_read.sum
pcie__rx_requests_aperture_bar1_op_write.sum</p></td>
<td><p><strong>PCIe Read/Write Requests to BAR1:</strong></p>
<p>BAR1 is a PCI Express (PCIe) interface used to allow the CPU or other devices to
directly access GPU memory. The GPU normally transfers memory with its copy
engines, which would not show up as BAR1 activity. The GPU drivers on the CPU
do a small amount of BAR1 accesses, but heavier traffic is typically coming from
other technologies.</p>
</td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="cupti-checkpoint-api">
<span id="checkpoint-api"></span><h2><span class="section-number">2.13. </span>CUPTI Checkpoint API<a class="headerlink" href="#cupti-checkpoint-api" title="Permalink to this headline"></a></h2>
<p>Starting with CUDA 11.5, CUPTI ships with a new library to assist tool developers who wish to replay kernels under direct control, such as tools using the Profiling API User Replay mode. This new Checkpoint library provides support for automatically saving and restoring device state for many common uses.</p>
<p>A device checkpoint is a managed copy of device functional state - including values in memory, along with some (but not all) other user visible state of the device. When a checkpoint is saved, this state is saved to internal buffers, preferentially using free device, then host, and finally filesystem space to save the data. The user tool maintains a handle to a checkpoint, and is able to restore the checkpoint with a single call, restoring the state so a kernel may be re-executed and expect to have the same device state as when the checkpoint was saved.</p>
<p>Once saved, a checkpoint may be restored any time including after multiple kernels have been launched, though currently there are limitations on which user calls (CUDA or driver API calls) have been validated to work between a <code class="docutils literal notranslate"><span class="pre">Save</span></code> and <code class="docutils literal notranslate"><span class="pre">Restore</span></code>. It currently is known safe to launch multiple kernels on a context and to do memcpy calls before restoring a checkpoint. Future versions of CUPTI will extend this to support additional API calls between a <code class="docutils literal notranslate"><span class="pre">Save</span></code> and <code class="docutils literal notranslate"><span class="pre">Restore</span></code>.</p>
<p>Checkpoints may be saved during injected kernel launch callbacks or directly coded into a target application.</p>
<p>Certain APIs are known to not work with the version of the <code class="docutils literal notranslate"><span class="pre">Checkpoint</span></code> API shipped with CUPTI 11.5, including Stream Capture mode.</p>
<section id="id7">
<h3><span class="section-number">2.13.1. </span>Usage<a class="headerlink" href="#id7" title="Permalink to this headline"></a></h3>
<p>There is one header for the library, <code class="docutils literal notranslate"><span class="pre">cupti_checkpoint.h</span></code>, which needs to be included, and libcheckpoint needs to be linked in to the application or injection library. Though the checkpoint library doesn’t depend on cupti, the error codes returned by the API are shared with cupti, so linking libcupti in is needed in order to translate the return codes to string representations.</p>
<p>The Checkpoint API follows a similar design to other CUPTI APIs. API behavior is controlled through a structure, <code class="docutils literal notranslate"><span class="pre">CUpti_Checkpoint</span></code>, which is initialized by a tool or application, then passed to <code class="docutils literal notranslate"><span class="pre">cuptiCheckpointSave</span></code>. If the call is successful, the structure saves a handle to a checkpoint. At this point, the application may make a series of calls which modify device state (kernels which update memory, memcopies, etc), and when the device state should be restored, the tool can use the same structure in calls to <code class="docutils literal notranslate"><span class="pre">cuptiCheckpointRestore</span></code>, and finally a call to <code class="docutils literal notranslate"><span class="pre">cuptiCheckpointFree</span></code> to release the resources used by the checkpoint object.</p>
<p>Multiple checkpoints may be saved at the same time. If multiple checkpoints exist, they operate entirely independently - each checkpoint consumes the full resources needed to restore the device state at the point it was saved. Order of operations between multiple checkpoints is not enforced by the API - while a common use for multiple checkpoints may be a nested pattern, it is also possible to interleave checkpoint operations.</p>
<p>Between a <code class="docutils literal notranslate"><span class="pre">cuptiCheckpointSave</span></code> and <code class="docutils literal notranslate"><span class="pre">cuptiCheckpointRestore</span></code>, any number of standard kernel launches (or equivalent API calls such as <code class="docutils literal notranslate"><span class="pre">cuLaunchKernel</span></code>) or memcpy calls may be made. Additionally, any host (cpu) side calls may be made that do not affect device state. It is possible that other CUDA or driver API calls may be made, but have not been validated with the 11.5 release.</p>
<p>Several options exist in the <code class="docutils literal notranslate"><span class="pre">CUpti_Checkpoint</span></code> structure. They must be set prior to the initial <code class="docutils literal notranslate"><span class="pre">cuptiCheckpointSave</span></code> using that structure. Any further changes to the structure are ignored until after a call to <code class="docutils literal notranslate"><span class="pre">cuptiCheckpointFree</span></code>, at which point the structure can be re-configured and re-used.</p>
<p>Important per-checkpoint options:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">structSize</span></code> - must be set to the value of <code class="docutils literal notranslate"><span class="pre">CUpti_Checkpoint_STRUCT_SIZE</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ctx</span></code> - if NULL, the checkpoint will be of the default CUDA context, otherwise, specifies which context</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">reserveDeviceMB</span></code> - Restrict a checkpoint save from using at least this much device memory</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">reserveHostMB</span></code> - Restrict a checkpoint save from using at least this much host memory</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">allowOverwrite</span></code> - It is normally an error to call Save using an existing checkpoint handle (one which has not been Freed). When set, this option allows the Save operation to be called multiple times on a handle. Note that when using this option, the <code class="docutils literal notranslate"><span class="pre">CUpti_Checkpoint</span></code> options are not re-read on any subsequent Save. To read new options, the handle must be passed to <code class="docutils literal notranslate"><span class="pre">cuptiCheckpointFree</span></code> prior to the <code class="docutils literal notranslate"><span class="pre">cuptiCheckpointSave</span></code> call.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">optimizations</span></code> - Bitmask of options for checkpoint behavior</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">CUPTI_CHECKPOINT_OPT_TRANSFER</span></code> - Normally when restoring a checkpoint, all existing device memory at the time of the save is restored. This optimization adds a test to see whether a block of memory has changed before restoring it and caches the results for subsequent calls to Restore. Use of this option requires that all Restore calls be done at the same point in an application for a given checkpoint. As the optimization may be computationally expensive, it is most useful when there is a significant amount of data that can be skipped and there will be several calls to Restore the checkpoint.</p></li>
</ul>
</li>
</ul>
</section>
<section id="restrictions">
<span id="checkpoint-restrictions"></span><h3><span class="section-number">2.13.2. </span>Restrictions<a class="headerlink" href="#restrictions" title="Permalink to this headline"></a></h3>
<p>Checkpoints API calls may not be made during a stream capture. They also may not be inserted into a graph. Beyond kernel launches (cuLaunchKernel, standard kernel&lt;&lt;&lt;&gt;&gt;&gt; launches, etc) and memcpy calls, the remaining CUDA and driver API calls have not been validated within a Checkpoint<code class="docutils literal notranslate"><span class="pre">Save</span></code> and <code class="docutils literal notranslate"><span class="pre">Restore</span></code> region. Any other CUDA or driver API calls (example - device malloc or free) may work, or may cause undetermined behavior. Additional APIs will be validated to work with the Checkpoint API in future releases.</p>
<p>The Checkpoint API does not have visibility into which API calls have been made between <code class="docutils literal notranslate"><span class="pre">cuptiCheckpointSave</span></code> and <code class="docutils literal notranslate"><span class="pre">cuptiCheckpointRestore</span></code> calls, and may not be able to correctly detect error cases if unsupported calls have been made. In this case it is possible that device state may only be partially restored by <code class="docutils literal notranslate"><span class="pre">cuptiCheckpointRestore</span></code>, which may cause functionally incorrect behavior in subsequent device calls.</p>
<p>The Checkpoint API only restores functionally visible device state, not performance critical state. Some performance characteristics, such as state of the caches, will not be saved by a checkpoint, and saving or restoring a checkpoint may change the occupancy and alter performance for subsequent device calls.</p>
<p>The Checkpoint API makes no attempt to restore host (non-device) state, beyond freeing the resources it internally uses during a call to <code class="docutils literal notranslate"><span class="pre">cuptiCheckpointFree</span></code>.</p>
<p>The Checkpoint API by default uses device memory, host memory, and finally the filesystem to back up the device state. It is possible that addition of a <code class="docutils literal notranslate"><span class="pre">cuptiCheckpointSave</span></code> causes a later device allocation to fail due to the increased device memory usage. (Similarly, host memory is also used, and may be affected by a checkpoint). To allow the user to guarantee a certain amount of device or host memory remains available for later use, <code class="docutils literal notranslate"><span class="pre">reserveDeviceMB</span></code> and <code class="docutils literal notranslate"><span class="pre">reserveHostMB</span></code> fields in the <code class="docutils literal notranslate"><span class="pre">CUpti_Checkpoint</span></code> struct may be set. Use of these fields will guarantee that the device or host memory will leave that much memory free during a <code class="docutils literal notranslate"><span class="pre">cuptiCheckpointSave</span></code> call, but may cause the Checkpoint API call performance to degrade due to increased use of slower storage spaces.</p>
</section>
<section id="examples">
<span id="checkpoint-samples"></span><h3><span class="section-number">2.13.3. </span>Examples<a class="headerlink" href="#examples" title="Permalink to this headline"></a></h3>
<p>The Checkpoint API does not require any other CUPTI calls. A simple use case could be to compare the output of three different implementations of a kernel. Pseudocode for this could look like:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">CUpti_Checkpoint</span><span class="w"> </span><span class="n">cp</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="n">CUpti_Checkpoint_STRUCT_SIZE</span><span class="w"> </span><span class="p">};</span><span class="w"></span>

<span class="kt">int</span><span class="w"> </span><span class="n">kernel</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"></span>
<span class="k">do</span><span class="w"></span>
<span class="p">{</span><span class="w"></span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">kernel</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"></span>
<span class="w">    </span><span class="n">cuptiCheckpointSave</span><span class="p">(</span><span class="o">&amp;</span><span class="n">cp</span><span class="p">);</span><span class="w"></span>
<span class="w">  </span><span class="k">else</span><span class="w"></span>
<span class="w">    </span><span class="n">cuptiCheckpointRestore</span><span class="p">(</span><span class="o">&amp;</span><span class="n">cp</span><span class="p">);</span><span class="w"></span>

<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">kernel</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"></span>
<span class="w">    </span><span class="n">kernel_1</span><span class="o">&lt;&lt;&lt;&gt;&gt;&gt;</span><span class="p">(...);</span><span class="w"></span>
<span class="w">  </span><span class="k">else</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">kernel</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"></span>
<span class="w">    </span><span class="n">kernel_2</span><span class="o">&lt;&lt;&lt;&gt;&gt;&gt;</span><span class="p">(...);</span><span class="w"></span>
<span class="w">  </span><span class="k">else</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">kernel</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"></span>
<span class="w">    </span><span class="n">kernel_3</span><span class="o">&lt;&lt;&lt;&gt;&gt;&gt;</span><span class="p">(...);</span><span class="w"></span>
<span class="p">}</span><span class="w"> </span><span class="k">while</span><span class="w"> </span><span class="p">(</span><span class="n">kernel</span><span class="o">++</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">3</span><span class="p">);</span><span class="w"></span>

<span class="n">cuptiCheckpointFree</span><span class="p">(</span><span class="o">&amp;</span><span class="n">cp</span><span class="p">);</span><span class="w"></span>
</pre></div>
</div>
<p>In this example, even if any of the kernels modify their own input data, the subsequent passes through the loop will still run correctly - the modified input data would be restored by each call to <code class="docutils literal notranslate"><span class="pre">cuptiCheckpointRestore</span></code> before the next kernel runs. This is particularly useful when a programmer does not know the exact state of the device prior to a kernel call - the Checkpoint API ensures that all needed data is saved and restored, which would not otherwise be practical or perhaps even possible in some complex cases.</p>
<p>Another possible use case could be for fuzzing - randomly modifying input to a kernel, and ensuring it performs as expected. Instead of manually restoring device state to a known good point, the Checkpoint API and initialize a good state, and the fuzzer can modify only what is needed.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">CUpti_Checkpoint</span><span class="w"> </span><span class="n">cp</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="n">CUpti_Checkpoint_STRUCT_SIZE</span><span class="w"> </span><span class="p">};</span><span class="w"></span>

<span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"></span>
<span class="k">do</span><span class="w"></span>
<span class="p">{</span><span class="w"></span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"></span>
<span class="w">    </span><span class="n">cuptiCheckpointSave</span><span class="p">(</span><span class="o">&amp;</span><span class="n">cp</span><span class="p">);</span><span class="w"></span>
<span class="w">  </span><span class="k">else</span><span class="w"></span>
<span class="w">    </span><span class="n">cuptiCheckpointRestore</span><span class="p">(</span><span class="o">&amp;</span><span class="n">cp</span><span class="p">);</span><span class="w"></span>

<span class="w">  </span><span class="n">setup_test</span><span class="o">&lt;&lt;&lt;&gt;&gt;&gt;</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="p">...);</span><span class="w"></span>

<span class="w">  </span><span class="n">kernel</span><span class="o">&lt;&lt;&lt;&gt;&gt;&gt;</span><span class="p">(...);</span><span class="w"></span>

<span class="w">  </span><span class="n">validate_result</span><span class="o">&lt;&lt;&lt;&gt;&gt;&gt;</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="p">...);</span><span class="w"></span>
<span class="p">}</span><span class="w"> </span><span class="k">while</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="o">++</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">num_tests</span><span class="p">);</span><span class="w"></span>

<span class="n">cuptiCheckpointFree</span><span class="p">(</span><span class="o">&amp;</span><span class="n">cp</span><span class="p">);</span><span class="w"></span>
</pre></div>
</div>
<p>Finally, the Checkpoint API is very useful for the User Replay mode of the CUPTI Profiling API. The User Replay mode can be very desireable as it allows kernels to run concurrently, which Kernel Replay mode does not, and only replays parts of the application which are within a performance region, unlike Applicatin Replay mode. However, in this mode, a kernel potentially needs to be launched multiple times in order to gather all requested metrics. This is complicated when the kernel may modify some of its own input data, and without the Checkpoint API, would require the tool developer to handle restoring any modified input data manually. It is difficult for a tool to automatically know whether any data needs to be restored before each iteration, or even what the existing state of the device is. Using the Checkpoint API, the tool can guarantee that input data will be restored each pass.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>CUpti_Checkpoint cp = { CUpti_Checkpoint_STRUCT_SIZE };

// Pseudocode - assume all Profiling API structures are already initialized correctly
cuptiProfilerBeginSession(&amp;beginSessionParams);
cuptiProfilerSetConfig(&amp;setConfigParams);
int numPasses = 0;
bool lastPass = false;
do
{
  if (numPasses == 0)
    cuptiCheckpointSave(&amp;cp);
  else
    cuptiCheckpointRestore(&amp;cp);

  cuptiProfilerBeginPass(&amp;beginPassParams);
  cuptiProfilerEnableProfiling(&amp;enableProfilingParams);
  cuptiProfilerPushRange(&amp;pushRangeParams);

  // Kernel launch on N separate streams - will be profiled while running concurrently
  kernel&lt;&lt;&lt;..., stream0&gt;&gt;&gt;(...);
  kernel&lt;&lt;&lt;..., stream1&gt;&gt;&gt;(...);
  ...
  kernel&lt;&lt;&lt;..., streamN&gt;&gt;&gt;(...);

  cudaStreamSynchronize(stream0);
  cudaStreamSynchronize(stream1);
  ...
  cudaStreamSynchronize(streamN);

  cuptiProfilerPopRange(&amp;popRangeParams);
  cuptiProfilerDisableProfiling(&amp;disableProfilingParams);
  lastPass = cuptiProfilerEndPass(&amp;endPassParams);
} while (lastPass == false);
cuptiProfilerFlushCounterData(&amp;flushCounterDataParams);
cuptiProfilerUnsetConfig(&amp;unsetConfigParams);
cuptiProfilerEndSession(&amp;endSessionParams);
</pre></div>
</div>
<p>In this example, the Profiler range will span all concurrently running kernels, which may modify their own input data - each pass through the loop will restore the initial values.</p>
</section>
</section>
<section id="cupti-overhead">
<span id="overhead"></span><h2><span class="section-number">2.14. </span>CUPTI overhead<a class="headerlink" href="#cupti-overhead" title="Permalink to this headline"></a></h2>
<p>CUPTI incurs overhead when used for tracing or profiling of the CUDA application. Overhead can vary significantly from one application to another. It largely depends on the density of the CUDA activities in the application; lesser the CUDA activities, less the CUPTI overhead. In general overhead of tracing i.e. activity APIs is much lesser than the profiling i.e. event and metric APIs.</p>
<section id="tracing-overhead">
<span id="overhead-tracing"></span><h3><span class="section-number">2.14.1. </span>Tracing Overhead<a class="headerlink" href="#tracing-overhead" title="Permalink to this headline"></a></h3>
<p>One of the goal of the tracing APIs is to provide a non-invasive collection of the timing information of the CUDA activities. Tracing is a low-overhead mechanism for collecting fine-grained runtime information.</p>
<section id="execution-overhead">
<span id="overhead-tracing-execution"></span><h4><span class="section-number">2.14.1.1. </span>Execution overhead<a class="headerlink" href="#execution-overhead" title="Permalink to this headline"></a></h4>
<p>Consider below points which can affect the execution overhead of the application:</p>
<ul class="simple">
<li><p>Enable only the activities and callbacks which are of interest.</p></li>
<li><p>Return from the callbacks as early as possible. Callbacks are issued from the host, these can block the work submission on the GPU if not returned early since CUPTI and thus the CUDA driver can’t make the forward progress on the host thread which issues the callback.</p></li>
<li><p>APIs <code class="docutils literal notranslate"><span class="pre">cuptiActivityEnableDriverApi</span></code> and <code class="docutils literal notranslate"><span class="pre">cuptiActivityEnableRuntimeApi</span></code> can be used to limit the tracing of CUDA APIs that are of interest.</p></li>
<li><p>For CUDA Graphs, if node level visibility is not desired, switching to the graph-level tracing from node-level tracing can help in reducing the collection overhead significantly. Use activity kind <code class="docutils literal notranslate"><span class="pre">CUPTI_ACTIVITY_KIND_GRAPH_TRACE</span></code> to enable graph-level tracing.</p></li>
<li><p>For activity buffer requested callback, the client should return the buffer as quickly as possible as this callback is issued from the application thread. Client can pre-allocate a pool of activity buffers and return an empty buffer from the pool when requested by CUPTI.</p></li>
<li><p>CUPTI initializes the new activity buffer with zero values using the memset call before using it. This operation can be skipped if user provides the zero value buffer and sets the attribute <code class="docutils literal notranslate"><span class="pre">CUPTI_ACTIVITY_ATTR_ZEROED_OUT_ACTIVITY_BUFFER</span></code> of the enum <code class="docutils literal notranslate"><span class="pre">CUpti_ActivityAttribute</span></code>.</p></li>
<li><p>Client can request CUPTI to maintain the activity buffers at the thread level instead of global buffers. This can be achieved by setting the option <code class="docutils literal notranslate"><span class="pre">CUPTI_ACTIVITY_ATTR_PER_THREAD_ACTIVITY_BUFFER</span></code> of the enum <code class="docutils literal notranslate"><span class="pre">CUpti_ActivityAttribute</span></code>. This can help in reducing the collection overhead for applications which launch CUDA activities from multiple host threads.</p></li>
<li><p>Reduce the frequency of buffer flushing as it can be an expensive operation. This can be achieved by setting a high flush period using the API <code class="docutils literal notranslate"><span class="pre">cuptiActivityFlushPeriod</span></code> to avoid internal flushing done by CUPTI and by reducing the frequency of the API <code class="docutils literal notranslate"><span class="pre">cuptiActivityFlushAll</span></code>. This approach might result in increased memory footprint on host and device.</p></li>
<li><p>For device buffers, CUPTI allocates a new buffer when it runs out of the buffers from the pool, and this happens in the main application thread, which might result in stalls in the critical path. This can be avoided by either pre-allocating more device buffers or increasing the size of the device buffer using the attributes <code class="docutils literal notranslate"><span class="pre">CUPTI_ACTIVITY_ATTR_DEVICE_BUFFER_POOL_LIMIT</span></code> and <code class="docutils literal notranslate"><span class="pre">CUPTI_ACTIVITY_ATTR_DEVICE_BUFFER_SIZE</span></code> respectively from the enum <code class="docutils literal notranslate"><span class="pre">CUpti_ActivityAttribute</span></code>.</p></li>
<li><p>Serial kernel trace enabled using the activity kind <code class="docutils literal notranslate"><span class="pre">CUPTI_ACTIVITY_KIND_KERNEL</span></code> can significantly change the overall performance characteristics of the application because all kernel executions are serialized on the GPU. For applications which use only a single CUDA stream and therefore cannot have concurrent kernel execution, this mode can be useful as it usually (not always) incurs less profiling overhead compared to the concurrent kernel mode.</p></li>
<li><p>Concurrent kernel trace enabled using the activity kind <code class="docutils literal notranslate"><span class="pre">CUPTI_ACTIVITY_KIND_CONCURRENT_KERNEL</span></code> doesn’t affect the concurrency of the kernels in the application. In this mode, CUPTI instruments the kernel code to collect the timing information. A single instrumentation code is generated at the time of loading the CUDA module and applied to each kernel during the kernel execution. Instrumentation code generation overhead is attributed as <code class="docutils literal notranslate"><span class="pre">CUPTI_ACTIVITY_OVERHEAD_CUPTI_INSTRUMENTATION</span></code> in the activity record <code class="docutils literal notranslate"><span class="pre">CUpti_ActivityOverhead2</span></code>.</p></li>
<li><p>Due to the code instrumentation, concurrent kernel mode can add significant runtime overhead if used on kernels that execute a large number of blocks and that have short execution duration.</p></li>
</ul>
</section>
<section id="memory-overhead">
<span id="overhead-tracing-memory"></span><h4><span class="section-number">2.14.1.2. </span>Memory overhead<a class="headerlink" href="#memory-overhead" title="Permalink to this headline"></a></h4>
<p>CUPTI allocates device and pinned system memory for storing the tracing information:</p>
<ul class="simple">
<li><p><strong>Static memory allocation:</strong> CUPTI allocates 3 buffers of 3 MB each in the pinned system memory for each CUDA context by default during the context creation phase. This is used for storing the concurrent kernel, serial kernel, memcopy and memset tracing information and these buffers are sufficient for storing information for about 300K such activities. The number of buffers is controlled using the attribute <code class="docutils literal notranslate"><span class="pre">CUPTI_ACTIVITY_ATTR_DEVICE_BUFFER_PRE_ALLOCATE_VALUE</span></code> and the size of the buffer is determined by the attribute <code class="docutils literal notranslate"><span class="pre">CUPTI_ACTIVITY_ATTR_DEVICE_BUFFER_SIZE</span></code>. User can change the buffer size at any time during the profiling session, but this setting takes effect only for new buffer allocations. It is recommended to adjust the buffer size before the creation of any CUDA context to make sure that all the pre-allocated buffers are of the adjusted size.</p></li>
<li><p><strong>Dynamic memory allocation:</strong> Once profiling buffers to store the tracing information are exhausted, CUPTI allocates another buffer of the same size. Note that memory footprint will not always scale with the kernel, memcopy, memset count because CUPTI reuses the buffer after processing all the records in the buffer. For applications with a high density of these activities CUPTI may allocate more buffers.</p></li>
</ul>
<p>All of the CUPTI allocated memory associated with a context is freed when the context is destroyed. Memory allocation overhead is attributed as <code class="docutils literal notranslate"><span class="pre">CUPTI_ACTIVITY_OVERHEAD_CUPTI_RESOURCE</span></code> in the activity record <code class="docutils literal notranslate"><span class="pre">CUpti_ActivityOverhead2</span></code>. If there are no CUDA contexts created then CUPTI will not allocate corresponding buffers.</p>
<p>CUPTI allocates memory to store unique kernel names, NVTX ranges, CUDA module cubin:</p>
<ul class="simple">
<li><p><strong>Kernel trace:</strong> For kernel tracing enabled using the activity kind <code class="docutils literal notranslate"><span class="pre">CUPTI_ACTIVITY_KIND_KERNEL</span></code> or <code class="docutils literal notranslate"><span class="pre">CUPTI_ACTIVITY_KIND_CONCURRENT_KERNEL</span></code> CUPTI allocates memory to store the kernel name in the records. It is recommended to not free the memory allocated for the kernel name in the kernel activity record as the kernel name memory space might be common across all kernel records having the same kernel name.</p></li>
<li><p><strong>NVTX ranges:</strong> For NVTX enabled using the activity kind <code class="docutils literal notranslate"><span class="pre">CUPTI_ACTIVITY_KIND_MARKER</span></code> CUPTI allocates memory to store the range name in the records. It is recommended to not free the memory allocated for the NVTX range name in the marker activity record as the NVTX range name memory space will be common across all NVTX range records having the same name.</p></li>
<li><p><strong>CUDA module cubin:</strong> CUPTI caches copies of cubin images at the time of loading CUDA modules. This is done only for the profiling features that need it are enabled. All of the CUPTI allocated memory associated with the cubin image of the module is freed when the module is unloaded.</p></li>
</ul>
</section>
</section>
<section id="profiling-overhead">
<span id="overhead-profiling"></span><h3><span class="section-number">2.14.2. </span>Profiling Overhead<a class="headerlink" href="#profiling-overhead" title="Permalink to this headline"></a></h3>
<p>Events and metrics collection using CUPTI incurs runtime overhead. This overhead depends on the number and type of events and metrics selected. Since each metric is computed from one or more events, metric overhead depends on the number and type of underlying events. The overhead includes time spent in configuration of hardware events and reading of hardware event values.</p>
<p>Factors affecting the execution overhead under profiling are:</p>
<ul class="simple">
<li><p>Overhead is less for hardware provided events and metrics.</p>
<ul>
<li><p>For event and metric APIs, events which are collected using the collection method <code class="docutils literal notranslate"><span class="pre">CUPTI_EVENT_COLLECTION_METHOD_PM</span></code> or <code class="docutils literal notranslate"><span class="pre">CUPTI_EVENT_COLLECTION_METHOD_SM</span></code> fall in this category.</p></li>
<li><p>For Profiling APIs, metrics which don’t have string “sass” in the name fall in this category.</p></li>
</ul>
</li>
<li><p>Software instrumented events and metrics are expensive as CUPTI needs to instrument the kernel to collect these. Further these events and metrics cannot be combined with any other event or metric in the same pass as otherwise instrumented code will also contribute to the event value.</p>
<ul>
<li><p>For event and metric APIs, the collection method <code class="docutils literal notranslate"><span class="pre">CUPTI_EVENT_COLLECTION_METHOD_INSTRUMENTED</span></code> fall in this category.</p></li>
<li><p>For Profiling APIs, metrics which have string “sass” in the name fall in this category.</p></li>
</ul>
</li>
<li><p>In the serial mode, profiling may significantly change the overall performance characteristics of the application because all kernel executions are serialized on the GPU. This is done to enable tight event or metric collection around each kernel.</p>
<ul>
<li><p>For event and metric APIs, the collection mode <code class="docutils literal notranslate"><span class="pre">CUPTI_EVENT_COLLECTION_MODE_KERNEL</span></code>, serializes all kernel executions on the GPU that occur between the APIs <code class="docutils literal notranslate"><span class="pre">cuptiEventGroupEnable</span></code> and <code class="docutils literal notranslate"><span class="pre">cuptiEventGroupDisable</span></code>. On the other hand, kernel concurrency can be maintained by using the collection mode <code class="docutils literal notranslate"><span class="pre">CUPTI_EVENT_COLLECTION_MODE_CONTINUOUS</span></code> and restricting profiling to events and metrics that can be collected in a single pass.</p></li>
<li><p>For Profiling APIs, auto range mode serializes all kernel executions on the GPU. On the other hand, kernel concurrency can be maintained by using the user range mode.</p></li>
</ul>
</li>
<li><p>When all the requested events or metrics cannot be collected in the single pass due to hardware or software limitations, one needs to replay the exact same set of GPU workloads multiple times. This can be achieved at the kernel granularity by replaying kernel multiple times or by launching the entire application multiple times. CUPTI provides support for kernel replay only. Application replay can be done by the CUPTI client.</p></li>
<li><p>When kernel replay is used the overhead to save and restore kernel state for each replay pass depends on the amount of device memory used by the kernel. Application replay is expected to perform better than kernel replay for the case when the size of device memory used by the kernel is high.</p></li>
</ul>
</section>
</section>
<section id="reproducibility">
<span id="id8"></span><h2><span class="section-number">2.15. </span>Reproducibility<a class="headerlink" href="#reproducibility" title="Permalink to this headline"></a></h2>
<p>Some CUPTI APIs are not guaranteed to return perfectly reproducible results between runs.  Numerous factors introduce measurable run-to-run variation in software and hardware performance.  There are several suggestions for users who want more reproducible results.</p>
<section id="fixed-clock-rate">
<span id="reproducibility-fixed-clock"></span><h3><span class="section-number">2.15.1. </span>Fixed Clock Rate<a class="headerlink" href="#fixed-clock-rate" title="Permalink to this headline"></a></h3>
<p>Many metrics are directly affected by GPU SM and memory clock frequencies.  By default, the GPU keeps clock rates low until work is launched, but clock rates do not boost to full speed immediately, so initial work launched after an idle period may run at low clock speed.  Additionally, the target clock rates may vary based on power, thermal, and other factors.  Complex interactions between different part of the system mean that these dynamic clock rates may not be reproducible between runs.</p>
<p>To reduce the effect of dynamic clock rates, it is possible to set a fixed clock rate.  The GPU will no longer opportunistically boost clock rates above this rate, but it will eliminate the variability after GPU idle and effects of power and thermal variation.  Several different methods exist to fix the SM or memory clock rates.  The simplest may be nvidia-smi, but see <a class="reference external" href="https://developer.nvidia.com/blog/advanced-api-performance-setstablepowerstate">this NVIDIA blog entry</a> for more suggestions.</p>
</section>
<section id="serialization">
<span id="reproducibility-serialization"></span><h3><span class="section-number">2.15.2. </span>Serialization<a class="headerlink" href="#serialization" title="Permalink to this headline"></a></h3>
<p>Work may be submitted to the GPU which can run asynchronously and concurrently. This improves performance by using more of the GPU resources at once, but complicates profiling in two ways - first, kernels running concurrently can impact each other through contention for shared resources.  Measurements of these shared resources will include the impact of any concurrently kernels, and it may not be possible to determine the particular impact of any given kernel.  Second, by contending for resources with other kernels that are running without precisely guaranteed timing, the timing for a given kernel may be impacted in irreproducible ways.</p>
<p>When <code class="docutils literal notranslate"><span class="pre">CUPTI_ACTIVITY_KIND_CONCURRENT_KERNEL</span></code> is used to measure kernel timing, kernels are allowed to run concurrently on device.  <code class="docutils literal notranslate"><span class="pre">CUPTI_ACTIVITY_KIND_KERNEL</span></code>  may be used instead to measure serialized kernel timing. This will eliminate GPU concurrency within this process, and should provide better run-to-run reproducibility, but the timing may not be as realistic in this mode - kernels will not have to contend for shared resources, which can impact their performance.</p>
</section>
<section id="other-issues">
<span id="reproducibility-other"></span><h3><span class="section-number">2.15.3. </span>Other Issues<a class="headerlink" href="#other-issues" title="Permalink to this headline"></a></h3>
<p>Beyond variable clock rates and concurrent kernel execution, several other factors can affect application and kernel performance.</p>
<p>The driver normally does not stay loaded when not in use.  It takes some time to load and initialize the driver, which may affect performance in noticeable and somewhat irreproducible ways.  It is possible to keep the driver persistently loaded which will eliminate this initialization overhead. <code class="docutils literal notranslate"><span class="pre">nvidia-persistenced</span></code> is one tool to configure this; it can also be configured through <code class="docutils literal notranslate"><span class="pre">nvidia-smi</span></code>.</p>
</section>
</section>
<section id="samples">
<span id="id9"></span><h2><span class="section-number">2.16. </span>Samples<a class="headerlink" href="#samples" title="Permalink to this headline"></a></h2>
<p>The CUPTI installation includes several samples that demonstrate the use of the CUPTI APIs. These samples can be referred to for the usage of different APIs supported by CUPTI. A sample might not be supported on all GPU architectures, please refer to the section <a class="reference external" href="../release-notes/release-topic.html#gpu-support">GPU Support</a> for the GPU architectures supported by different CUPTI APIs used in the sample. The samples are:</p>
<p class="rubric-h3 rubric">Activity API</p>
<dl class="simple" id="sample-activity-trace-async">
<dt>activity_trace_async</dt><dd><p>This sample shows how to collect a trace of CPU and GPU activity using the new asynchronous activity buffer APIs.</p>
</dd>
<dt>callback_timestamp</dt><dd><p>This sample shows how to use the callback API to record a trace of API start and stop times.</p>
</dd>
</dl>
<dl class="simple" id="sample-cuda-graphs-trace">
<dt>cuda_graphs_trace</dt><dd><p>This sample shows how to collect the trace of CUDA graphs and correlate the graph node launch to the node creation API using CUPTI callbacks.</p>
</dd>
<dt>cuda_memory_trace</dt><dd><p>This sample shows how to collect the trace of CUDA memory operations. The sample also traces CUDA memory operations done via default memory pool.</p>
</dd>
</dl>
<dl class="simple" id="sample-cupti-correlation">
<dt>cupti_correlation</dt><dd><p>This sample shows how to do the correlation between CUDA APIs and corresponding GPU activities.</p>
</dd>
</dl>
<dl class="simple" id="sample-cupti-external-correlation">
<dt>cupti_external_correlation</dt><dd><p>This sample shows how to do the correlation of CUDA API activity records with external APIs.</p>
</dd>
</dl>
<dl class="simple" id="sample-cupti-finalize">
<dt>cupti_finalize</dt><dd><p>This sample shows how to use API <code class="docutils literal notranslate"><span class="pre">cuptiFinalize()</span></code> to dynamically detach and attach CUPTI.</p>
</dd>
</dl>
<dl class="simple" id="sample-cupti-nvtx">
<dt>cupti_nvtx</dt><dd><p>This sample shows how to receive NVTX callbacks and collect NVTX records in CUPTI.</p>
</dd>
</dl>
<dl class="simple" id="sample-cupti-trace-injection">
<dt>cupti_trace_injection</dt><dd><p>This sample shows how to build an injection library using the CUPTI activity and callback APIs. It can be used to trace CUDA APIs and GPU activities for any CUDA application. It does not require the CUDA application to be modified.</p>
</dd>
</dl>
<dl class="simple" id="sample-nvlink-bandwidth">
<dt>nvlink_bandwidth</dt><dd><p>This sample shows how to collect NVLink topology and NVLink throughput metrics in continuous mode.</p>
</dd>
</dl>
<dl class="simple" id="sample-openacc-trace">
<dt>openacc_trace</dt><dd><p>This sample shows how to use CUPTI APIs for OpenACC data collection.</p>
</dd>
</dl>
<dl class="simple" id="sample-pc-sampling">
<dt>pc_sampling</dt><dd><p>This sample shows how to collect PC Sampling profiling information for a kernel using the PC Sampling Activity APIs.</p>
</dd>
</dl>
<dl class="simple" id="sample-sass-source-map">
<dt>sass_source_map</dt><dd><p>This sample shows how to generate CUpti_ActivityInstructionExecution records and how to map SASS assembly instructions to CUDA C source.</p>
</dd>
<dt>unified_memory</dt><dd><p>This sample shows how to collect information about page transfers for unified memory.</p>
</dd>
</dl>
<p class="rubric-h3 rubric">Event and Metric APIs</p>
<dl class="simple">
<dt>callback_event</dt><dd><p>This sample shows how to use both the callback and event APIs to record the events that occur during the execution of a simple kernel. The sample shows the required ordering for synchronization, and for event group enabling, disabling, and reading.</p>
</dd>
<dt>callback_metric</dt><dd><p>This sample shows how to use both the callback and metric APIs to record the metric’s events during the execution of a simple kernel, and then use those events to calculate the metric value.</p>
</dd>
<dt>cupti_query</dt><dd><p>This sample shows how to query CUDA-enabled devices for their event domains, events, and metrics.</p>
</dd>
</dl>
<dl class="simple" id="sample-event-multi-gpu">
<dt>event_multi_gpu</dt><dd><p>This sample shows how to use the CUPTI event and CUDA APIs to sample events on a setup with multiple GPUs. The sample shows the required ordering for synchronization, and for event group enabling, disabling, and reading.</p>
</dd>
<dt>event_sampling</dt><dd><p>This sample shows how to use the event APIs to sample events using a separate host thread.</p>
</dd>
</dl>
<p class="rubric-h3 rubric">Profiling API</p>
<dl class="simple" id="sample-extensions">
<dt>extensions</dt><dd><p>This includes utilities used in some of the samples.</p>
</dd>
</dl>
<dl class="simple" id="sample-autorange-profiling">
<dt>autorange_profiling</dt><dd><p>This sample shows how to use profiling APIs to collect metrics in autorange mode.</p>
</dd>
<dt>callback_profiling</dt><dd><p>This sample shows how to use callback and profiling APIs to collect the metrics during the execution of a kernel. It shows how to use different phases of profiling i.e. enumeration, configuration, collection and evaluation in the appropriate callbacks.</p>
</dd>
</dl>
<dl class="simple" id="sample-concurrent-profiling">
<dt>concurrent_profiling</dt><dd><p>This sample shows how to use the profiling API to record metrics from concurrent kernels launched in two different ways - using multiple streams on a single device, and using multiple threads with multiple devices.</p>
</dd>
</dl>
<dl class="simple" id="sample-cupti-metric-properties">
<dt>cupti_metric_properties</dt><dd><p>This sample shows how to query various properties of metrics using the Profiling APIs. The sample shows collection method (hardware or software) and number of passes required to collect a list of metrics.</p>
</dd>
<dt>nested_range_profiling</dt><dd><p>This sample shows how to profile nested ranges using the Profiling APIs.</p>
</dd>
</dl>
<dl class="simple" id="sample-profiling-injection">
<dt>profiling_injection</dt><dd><p>This sample for Linux systems shows how to build an injection library which can automatically enable CUPTI’s Profiling API using Auto Ranges with Kernel Replay mode. It can attach to an application which was not instrumented using CUPTI and profile any kernel launches.</p>
</dd>
</dl>
<dl class="simple" id="sample-userrange-profiling">
<dt>userrange_profiling</dt><dd><p>This sample shows how to use profiling APIs to collect metrics in user specified range mode.</p>
</dd>
</dl>
<p class="rubric-h3 rubric">PC Sampling API</p>
<dl class="simple" id="sample-pc-sampling-continuous">
<dt>pc_sampling_continuous</dt><dd><p>This injection sample shows how to collect PC Sampling profiling information using the PC Sampling APIs. A perl script libpc_sampling_continuous.pl is provided to run the CUDA application with different PC sampling options. Use the command <cite>./libpc_sampling_continuous.pl –help</cite> to list all the options. The CUDA application code does not need to be modified. Refer the README.txt file shipped with the sample for instructions to build and use the injection library.</p>
</dd>
</dl>
<dl class="simple" id="sample-pc-sampling-start-stop">
<dt>pc_sampling_start_stop</dt><dd><p>This sample shows how to collect PC Sampling profiling information for kernels within a range using the PC Sampling start/stop APIs.</p>
</dd>
</dl>
<dl class="simple" id="sample-pc-sampling-utility">
<dt>pc_sampling_utility</dt><dd><p>This utility takes the pc sampling data file generated by the pc_sampling_continuous injection library as input. It prints the stall reason counter values at the GPU assembly instruction level. It also does GPU assembly to CUDA-C source correlation and shows the CUDA-C source file name and line number. Refer the README.txt file shipped with the sample for instructions to build and run the utility.</p>
</dd>
</dl>
<p class="rubric-h3 rubric">PM Sampling API</p>
<dl class="simple">
<dt>pm_sampling</dt><dd><p>This sample shows the usage of the PM sampling APIs for collecting sampling data for a list of metrics for kernels launched within a range using the PM sampling start/stop APIs.</p>
</dd>
</dl>
<p class="rubric-h3 rubric">SASS Metric API</p>
<dl class="simple">
<dt>sass_metric</dt><dd><p>This sample shows how to use the SASS metric API to enumerate metrics supported by a device and how to collect metrics at the source level using SASS patching.</p>
</dd>
</dl>
<p class="rubric-h3 rubric">Checkpoint API</p>
<dl class="simple">
<dt>checkpoint_kernels</dt><dd><p>This sample shows how to use the Checkpoint API to restore device memory, allowing a kernel to be replayed, even if it modifies its input data.</p>
</dd>
</dl>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
<img src="../_static/NVIDIA-LogoBlack.svg" class="only-light"/>
<img src="../_static/NVIDIA-LogoWhite.svg" class="only-dark"/>

<p class="notices">
<a href="https://www.nvidia.com/en-us/about-nvidia/privacy-policy/" target="_blank">Privacy Policy</a>
|
<a href="https://www.nvidia.com/en-us/about-nvidia/privacy-center/" target="_blank">Manage My Privacy</a>
|
<a href="https://www.nvidia.com/en-us/preferences/start/" target="_blank">Do Not Sell or Share My Data</a>
|
<a href="https://www.nvidia.com/en-us/about-nvidia/terms-of-service/" target="_blank">Terms of Service</a>
|
<a href="https://www.nvidia.com/en-us/about-nvidia/accessibility/" target="_blank">Accessibility</a>
|
<a href="https://www.nvidia.com/en-us/about-nvidia/company-policies/" target="_blank">Corporate Policies</a>
|
<a href="https://www.nvidia.com/en-us/product-security/" target="_blank">Product Security</a>
|
<a href="https://www.nvidia.com/en-us/contact/" target="_blank">Contact</a>
</p>

<p>
  Copyright &#169; 2018-2024, NVIDIA Corporation &amp; Affiliates. All rights reserved.
</p>

    <p>
      <span class="lastupdated">Last updated on Sep 19, 2024.
      </span></p>

  </div>

   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 



</body>
</html>